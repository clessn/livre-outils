[
  {
    "objectID": "chapitre_6.html",
    "href": "chapitre_6.html",
    "title": "6  Outils de visualisation graphique",
    "section": "",
    "text": "6.1 Point d’observation: historique de la visualisation graphique\nUne fois les données collectées, nettoyées, traitées et analysées, une partie centrale du travail d’un scientifique de données est de faire parler les résultats de ses tests empiriques. Il s’agit alors de trouver la meilleure manière de rendre l’information digeste pour les experts et initiés de votre discipline académique ou pour le grand public. La visualisation graphique des données est donc centrale afin de vulgariser les résultats d’une recherche empirique.\nCette volonté de vulgariser des données à l’aide d’image ne date pas d’hier. En effet, le\nMilestones Project.\nA History of Data Visualization and Graphic Communication\nLéger retour en arrière pour comprendre l’évolution de la visualisation graphique.\nPremier âge d’or de la visualisation graphique: 18e siècle",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Outils de visualisation graphique</span>"
    ]
  },
  {
    "objectID": "chapitre_6.html#arpentage-et-choix-éditorial",
    "href": "chapitre_6.html#arpentage-et-choix-éditorial",
    "title": "6  Outils de visualisation graphique",
    "section": "6.2 Arpentage et choix éditorial:",
    "text": "6.2 Arpentage et choix éditorial:\nIl existe plusieurs outils de visualisation qui répondent à des besoins différents.\nNous nous concentrerons sur les outils respectant au mieux les critères de sélections établis au chapitre 1.\nBien entendu, les logiciels tels que Tableau, Stata, SPSS, SAS ou encore Excel peuvent s’avérer très pertinents selon vos exigences spécifiques. Ils sont souvent dotés d’une interface utilisateur intuitive, facilitant ainsi leur utilisation pour une variété de tâches. Toutefois, ils pourraient présenter certaines limites en matière de personnalisation des analyses et des visualisations. Par ailleurs, bien que certains de ces outils offrent une grande flexibilité, leur coût peut être considérable. Si votre institution possède une licence pour ces logiciels, il demeure judicieux de les utiliser.\nIl existe des outils gratuits et offrant un plus grand contrôle et offre plus de flexibilité que les logiciels de visualisation de données. Les logiciels. Programmation possible de personnaliser les graphiques à l’infini.\nBien que ce livre prend position en faveur de R comme présenté au chapitre 2, il est important de reconnaître les capacités de Python dans le domaine de la visualisation graphique. Python est un langage de programmation généraliste et est répandu dans la majorité des universités et sur le marché du travail (ozgurMatLabVsPython2017?). Matplotlib, Seaborn et Plotly sont des packages de\nR est spécialisé en statistiques et scientific research and academia, analytical power of R is virtually unmatched.(ozgurMatLabVsPython2017?).\nhttps://www.r-project.org/about.html",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Outils de visualisation graphique</span>"
    ]
  },
  {
    "objectID": "chapitre_6.html#manuel-dinstruction-la-visualisation-graphique-avec-r",
    "href": "chapitre_6.html#manuel-dinstruction-la-visualisation-graphique-avec-r",
    "title": "6  Outils de visualisation graphique",
    "section": "6.3 Manuel d’instruction: La visualisation graphique avec R",
    "text": "6.3 Manuel d’instruction: La visualisation graphique avec R\nLorsque vous souhaitez créer des graphiques en R, les options abondent. De multiples packages ont été développés dans le but de visualiser des données. Heureusement, les choix diminuent lorsque l’on regarde ce qui est le plus utilisé dans la communauté. L’objectif n’est pas simplement de présenter les packages les plus courrants parce qu’ils sont les plus communs. Les packages les plus utilisés représentent des outils qui ont été grandement vérifiés et améliorés par la communauté en ligne, dont la documentation est abondante et pour lesquels les ressources d’aide en ligne sont innombrables.\n\n6.3.1 Pour les analyses descriptives\n\n6.3.1.1 Base R\nLe Base R est le langage de base de R et il permet de faire de nombreuses manipulations statistiques sans avoir à installer de packages au préalable. Le Base R permet notamment de produire des graphiques rapidement. Cela peut être utile pour visualiser la distribution d’une variable ou pour regarder la relation entre deux d’entre elles, par exemple. Pour produire un graphique avec le langage de base R, il suffit de faire appel à la fonction plot(). Avec la fonction plot(), le codeur peut visualiser la distribution d’une variable seule en spécifiant l’axe des x dans cette dernière. Le codeur peut également visualiser la relation entre deux variables en spécifiant à l’intérieur de la fonction celles qui composeront les axes des x et des y du graphique. Les fonctions barplot(), hist() ou boxplot() disponibles dans le Base R permettent de spécifier le style de graphique souhaité, qu’on veuille représenter nos données sous forme de diagramme à barre, d’histogramme ou de diagramme en boîtes (Kabacoff, 2022, p. 119‑132).\nAlors qu’un peu tout peut être fait avec le Base R, ce langage demeure élémentaire; il est difficile d’innover dans la visualisation ou même de produire des graphiques plus sophistiqués. Le Base R peut sembler plus simple pour l’exploration de données ou pour produire des graphiques de base rapidement, mais ce langage devient rapidement complexe lorsqu’on cherche à améliorer l’esthétique de son graphique ou à visualiser des relations entre plusieurs variables, ce que lattice et ggplot2 permettent plus facilement(Wickham, 2009, p. 3‑4).\n\n\n6.3.1.2 Lattice\nDéveloppé par Deepayan Sarkar, lattice cherche à faciliter la visualisation de graphique en facettes. Plus précisément, ce package vise à améliorer les graphiques du Base R en fournissant de meilleures options de graphisme par défaut pour visualiser des relations multivariées. Ce package est donc intéressant pour les chercheurs et les codeurs voulant présenter graphiquement la relation entre plus de deux variables (Kabacoff, 2022, p. 373‑377; Sarkar, 2008, 2023). Pour produire un graphique de base avec Lattice, le package lattice doit préalablement être installé dans la bibliothèque de packages du codeur et chargé dans sa session au début de son code (voir annexe). Par la suite, le codeur doit spécifier le type de graphique souhaité avec la fonction appropriée3. Une fois la fonction choisie, il doit spécifier par une formule les variables x et y ainsi que la troisième variable à contrôler et à visualiser en facettes (graph_type(formula | variable en facettes, data=)).\nCependant, le package lattice a pour désavantage d’avoir un modèle formel (une grammaire de graphique) moins compréhensible et intuitif que celui de ggplot2 lorsque vient le temps d’améliorer l’esthétisme des graphiques. De plus, sa plus faible popularité fait en sorte que ce package demeure moins développé par la communauté de codeurs de R que ne l’est ggplot2. Nous examinons plus en détail la grammaire de graphique de ce dernier package ainsi que ses avantages et inconvénients dans la prochaine section (Kabacoff, 2022, p. 373‑377 et 390; Wickham, 2009, p. 6).\n\n\n6.3.1.3 Ggplot 2\nDéveloppé principalement par Hadley Wickham, ggplot2 est un package R faisant partie de la collection de packages de tidyverse. Ainsi, Ggplot2 peut être utilisé avec les autres packages centraux de tidyverse ce qui limite de potentiels conflits entre les fonctions de packages qui puissent être incompatibles avec ggplot2. Par exemple, le package dplyr de tidyverse est très utile pour analyser, organiser et préparer vos données à visualiser avec ggplot2 (Wickham et al., 2019; Wickham et al., 2023, p. 30).\nLe principal avantage de ggplot2 reste sa grammaire qui permet à l’utilisateur de rendre ses graphiques beaucoup plus visuellement attrayants en facilitant la personnalisation esthétique. Ceci permet de pousser l’esthétisme de vos graphiques à un très haut niveau par rapport aux autres packages de visualisation graphique disponibles en R. Les graphiques ggplot2 se construisent couche par couche, soit par l’ajout des différents éléments du graphique au fur et à mesure dans le code du graphique à construire.\n\n\n\n6.3.2 Pour visualiser les régressions\nLorsque l’on veut aller plus loin que les analyses descriptives on peut faire des modèles de régression. Alors qu’il est très simple de visualiser un résumé d’un modèle avec la fonction summary(model), on peut rapidement arriver à bout de ces fonctionnalités lorsqu’on veut visualiser et comparer plusieurs modèles, présenter les modèles à son équipe, inclure les modèles dans une publication, etc. La prochaine section du chapitre présente les différents outils qui nous permettent de rapidement visualiser et présenter nos modèles de régression.\n\n6.3.2.1 stargazer (Hlavac, 2022)\n\n\n6.3.2.2 modelsummary\n(Arel-Bundock, 2022)\n\n\n6.3.2.3 ggplot2 et marginaleffects\n\n\n\n6.3.3 Aller plus loin: La visualisation interactive des données\nSi jusqu’à présent la visualisation des données a été présentée comme une étape permettant de présenter les résultats de recherches, il est également possible de considérer la visualisation comme une utile au processus d’exploration des données comportants de nombreuses dimensions (autres façons de le dire peut-être?). En effet, les formes de visualisations dites interactives permettant d’explorer et même d’analyser les données à même notre graphique ou notre tableau. Cela contribue à mieux comprendre la structures des données, à inspecter plus rapidement ces dernières et même susciter des questions de recherches peut-être omises autrement (citer Sievert, 2020).\n\nggplotly et plotly\nTableaux interactifs? fonctions kable() et kableExtra du package knitr\nShiny Apps\n\n\n\n\n\n\nArel-Bundock, V. (2022). Modelsummary: Data and Model Summaries in R. https://www.jstatsoft.org/article/view/v103i01\n\n\nHlavac, M. (2022). Stargazer: Beautiful LATEX, HTML and ASCII Tables from R Statistical Output.\n\n\nKabacoff, R. (2022). R in Action: Data Analysis and Graphics with R and Tidyverse (Third edition). Manning Publications.\n\n\nWickham, H. (2009). Ggplot2: Elegant Graphics for Data Analysis. Springer New York. https://doi.org/10.1007/978-0-387-98141-3\n\n\nWickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L., François, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen, T., Miller, E., Bache, S., Müller, K., Ooms, J., Robinson, D., Seidel, D., Spinu, V., … Yutani, H. (2019). Welcome to the Tidyverse. Journal of Open Source Software, 4(43), 1686. https://doi.org/10.21105/joss.01686\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for Data Science: Import, Tidy, Transform, Visualize, and Model Data (Second edition). O’Reilly.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Outils de visualisation graphique</span>"
    ]
  },
  {
    "objectID": "chapitre_2.html",
    "href": "chapitre_2.html",
    "title": "\n2  Langages de programmation\n",
    "section": "",
    "text": "2.1 Point d’observation: Histoire des langages de programmation pour l’analyse de données\nL’histoire des langages de programmation dédiés à l’analyse de données s’inscrit dans une évolution constante des besoins et des méthodes en sciences sociales. Avant l’ère numérique, l’analyse de données se faisait principalement à la main ou à l’aide de calculatrices mécaniques, avec des méthodes statistiques standardisées mais limitées par la capacité humaine à traiter des volumes massifs d’informations. Ces contraintes ont poussé les chercheurs à chercher des moyens plus efficaces de manipuler les données, ce qui a ouvert la voie à l’ère informatique et aux premiers logiciels dédiés à la statistique.\nDans les années 1960 et 1970, les premiers langages et logiciels statistiques, tels que kSPSS (1968), SAS (1976), et STATA (1985), ont vu le jour. Ces outils permettaient aux chercheurs d’automatiser les calculs statistiques complexes sur des ordinateurs de grande taille, en accélérant considérablement les analyses. Ces logiciels propriétaires ont joué un rôle crucial dans la standardisation de l’analyse statistique en sciences sociales, en offrant des plateformes robustes, mais souvent coûteuses et rigides.\nL’émergence de l’open source dans les années 1990, avec des projets tels que Linux et d’autres logiciels libres, a commencé à influencer le domaine de la statistique. C’est dans ce contexte que le langage R a été créé, en 1993, par Ross Ihaka et Robert Gentleman, à l’université d’Auckland, en Nouvelle-Zélande. R est basé sur le langage de programmation S, développé chez Bell Labs à la fin des années 1970. Contrairement à ses prédécesseurs propriétaires, R a été conçu pour être gratuit, flexible et extensible, ce qui en a fait un outil populaire parmi les chercheurs qui cherchaient à personnaliser leurs analyses tout en ayant accès à des ressources communautaires.\nR a répondu à un besoin pressant de la communauté scientifique : celui de pouvoir accéder à des outils puissants sans avoir à payer des licences onéreuses, tout en bénéficiant d’une liberté totale dans le développement de nouvelles méthodes d’analyse. Grâce à sa structure ouverte, R a rapidement évolué dû aux contributions de statisticiens et de programmeurs du monde entier, devenant l’un des langages de programmation les plus populaires pour l’analyse de données. Aujourd’hui, il est largement utilisé non seulement en sciences sociales, mais aussi en biostatistique, en économie et en science des données.\nL’évolution des langages de programmation pour l’analyse de données illustre comment les besoins des chercheurs en termes de flexibilité, d’accessibilité et de partage ont façonné les outils que nous utilisons aujourd’hui. Au fil des décennies, les langages se sont adaptés aux nouvelles méthodes et à l’augmentation des capacités de calcul, offrant des possibilités toujours plus larges pour l’exploration et l’analyse de données.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Langages de programmation</span>"
    ]
  },
  {
    "objectID": "chapitre_2.html#arpentage-et-choix-éditorial-pourquoi-r",
    "href": "chapitre_2.html#arpentage-et-choix-éditorial-pourquoi-r",
    "title": "\n2  Langages de programmation\n",
    "section": "\n2.2 Arpentage et choix éditorial: Pourquoi R?",
    "text": "2.2 Arpentage et choix éditorial: Pourquoi R?\nIl existe deux types de langages de programmation pour analyse de données. Les logiciels à licences comme SAS, STATA et SPSS, et les langages OpenSource tels que Python et Julia. R est un langage de programmation OpenSource développé par des statisticiens, pour des statisticiens, dans les années 1990 (Tippmann, 2015). Le langage de programmation R a plusieurs avantages qui font de lui un outil puissant et utile pour tout chercheur. L’un de ses grands avantages est qu’il est OpenSource. Ayant déjà abordé le sujet dans le chapitre précédent, il sera question ici de simplement rappeler les grandes lignes de l’argument, à savoir que : 1) l’OpenSource est gratuit d’utilisation; 2) l’OpenSource est développé par les utilisateurs et non par des corporations, ce qui lui procure une grande flexibilité; et 3) il permet aux utilisateurs de créer leurs propres fonctions qui répondent à leurs besoins. À l’inverse, les logiciels à licences sont coûteux, rigides et l’ajout de fonctionnalités se fait par les développeurs internes à la compagnie. Ces formalités rendent le processus plus lent et réduisent l’éventail des possibilités pour la personne chercheuse. Ceci étant dit, certains avanceront que c’est justement ce processus interne lent qui assure la validité et la fiabilité des analyses effectuées par SAS, STATA ou SPSS. Or, dans son livre dédié aux utilisateurs de SPSS et de SAS, Muenchen (2011) soulève le point que bien souvent, ce sont des individus atomisés qui développent les nouvelles fonctionnalités de ces langages et que le processus de révisions se fait ensuite par des comités internes de testeurs. Il en va de même pour le développement des packages R dans la mesure où ce dernier se voit testé et amendé par plusieurs programmeurs indépendants dans un processus itératif des plateformes telles que GitHub. De plus, bien des nouvelles techniques statistiques sont développées pour R par des chercheurs qui publient leur travail dans des journaux académiques revus par des pairs, assurant la qualité du procédé. Le fait que SAS et SPSS permettent à leur utilisateur d’intégrer des routines R à leur programme est un indicateur fort ne serait-ce que de l’utilité de R (Muenchen, 2011). Le langage de programmation R permet également de réaliser une grande quantité de tâches de recherche. En effet, les personnes programmant en R peuvent notamment manipuler et visualiser des données, faire différents types d’analyses, créer des fonctions et faire les automatiser en plus de pouvoir combiner R avec certains langages de balisages comme LaTeX, Markdown et HTML.\nD’un autre côté, l’utilisation du langage de programmation R peut être perçue comme ayant certains inconvénients. Plusieurs disent que la courbe d’apprentissage peut être plus grande que celle de programmes à licences. La véracité de cet argument est discutable. Les programmes demandant des licences ont également un coût d’entrée. De plus, les nouvelles itérations de ces logiciels amènent des changements demandant une période d’adaptation pour la personne chercheuse. D’autres disent que le développement OpenSource, spécifiquement celui du langage de programmation R, se fait de façon anarchique. Cela est davantage une question d’opinion et de conception du monde qu’une vérité. Le développement de package se fait effectivement de manière décentralisée et toute personne sachant programmer en R peut collaborer à cette communauté. Bien qu’il n’y ait pas d’autorité centrale, les packages sont regroupés sur le Comprehensive R Archive Network (CRAN) (voir le https://cran.r-project.org/ pour plus d’information). Le site a une politique de dépôt stricte, ainsi les packages doivent être suffisamment documentés. Il est également possible d’y télécharger le langage de programmation R. Ce langage, ainsi que ces différents packages, sont disponible sur Windows, macOS et Linux.\n\n\n\n\n    \n\n      \n\nRésumé des principaux outils de programmation pour l'analyse de données\n              \nCritères\n                Logiciels sous licence (SAS, SPSS, STATA)\n                Python\n                Julia\n                R\n              \n\n\n\nAccessibilité (Gratuit ou peu dispendieux)\n                  Non                          \n                  Oui           \n                  Oui          \n                  Oui                                                \n                \n\nExistence d'une communauté d'utilisateurs \n                  Modérée                      \n                  Très élevée   \n                  En croissance\n                  Très élevée                                        \n                \n\nPopularité dans le champ                  \n                  Élevée dans certains secteurs\n                  Très populaire\n                  Modérée      \n                  Très populaire en sciences sociales et statistiques\n                \n\nCompatibilité avec d'autres outils        \n                  Bonne                        \n                  Excellente    \n                  Bonne        \n                  très bonne                                         \n                \n\nTransparence et réplicabilité             \n                  Faible                       \n                  Bonne         \n                  Bonne        \n                  Très élevée                                        \n                \n\nAdaptabilité et flexibilité               \n                  Limitée                      \n                  Très flexible \n                  Très flexible\n                  Très flexible",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Langages de programmation</span>"
    ]
  },
  {
    "objectID": "chapitre_2.html#manuel-dinstruction-apprendre-à-programmer-en-r",
    "href": "chapitre_2.html#manuel-dinstruction-apprendre-à-programmer-en-r",
    "title": "\n2  Langages de programmation\n",
    "section": "\n2.3 Manuel d’instruction: Apprendre à programmer en R",
    "text": "2.3 Manuel d’instruction: Apprendre à programmer en R\n\n2.3.1 Où coder en R ?\nUn environnement de développement intégré (IDE) permet aux programmeurs de centraliser les différents aspects de l’écriture d’un programme informatique. Il permet de réaliser toutes les activités courantes d’un programmeur – l’édition du code, la construction des exécutables et le débogage – au même endroit. Les environnements de développement intégrés sont conçus pour maximiser la productivité des programmeurs. Ils fournissent de nombreuses fonctionnalités – notamment la coloration syntaxique (Le surlignage différent pour chaques éléments du code) et le contrôle de version – pour créer, modifier et compiler du code. Certains environnements de développement intégré sont dédiés à un langage de programmation spécifique. Par conséquent, ils contiennent des fonctionnalités qui sont plus adaptées aux paradigmes de programmation du langage auquel ils sont associés. Enfin, il existe de nombreux environnements de développement intégré multilingues.\nComme mentionné précédemment, R est l’un des langages de statistiques et d’exploration de données les plus populaires en sciences sociales. R est pris en charge par de nombreux environnements de programmation. Plusieurs ont été spécialement conçus pour la programmation en R – le plus notable étant RStudio – tandis que d’autres sont des environnements de programmation universels – tels que Visual Studio Code – qui prennent en charge R via des plugins. Il est également possible de coder en R à partir d’une interface en ligne de commande. Une telle méthode permet la communication entre l’utilisateur et son ordinateur. Cette communication s’effectue en mode texte : l’utilisateur tape une « ligne de commande » – c’est-à-dire du texte dans la console – pour demander à son ordinateur d’effectuer une opération précise, telle que l’exécution d’un fichier de code R.\nLa suite du chapitre présente RStudio, l’interface de développement le plus populaire pour l’utilisation de R.\n\n2.3.2 Qu’est-ce que RStudio ?\nRStudio est un projet open source destiné à regrouper les différentes composantes du langage de programmation R en un seul outil (Allaire, 2011). RStudio fonctionne sur tous les systèmes d’exploitation, y compris Windows, Mac OS et Linux. En plus de l’application de bureau, RStudio peut être déployé en tant que serveur pour permettre l’accès Web aux sessions R s’exécutant sur des systèmes distants (Allaire, 2011). RStudio facilite l’utilisation du langage de programmation R en offrant de nombreux outils permettant à l’utilisateur de réaliser aisément ses tâches. Parmi les outils les plus utiles, on retrouve notamment une fenêtre d’aide, de la documentation sur les différents packages R, un navigateur de l’environnement de travail, une visionneuse de données, ainsi que la prise en charge de la coloration syntaxique (Horton, Kleinman, 2015). De plus, RStudio permet de coder dans plusieurs langages et de gérer une grande variété de formats. Il offre également un support pour plusieurs projets ainsi qu’une interface permettant l’utilisation de systèmes de contrôle de version, tels que GitHub (Horton, Kleinman, 2015).\nRStudio présente plusieurs avantages. Son utilisation est facile à apprendre pour les débutants. Les principaux éléments d’un IDE sont intégrés dans une interface à quatre volets (Verzani, 2011). Cette disposition comprend une console, un éditeur de code source à onglets pour organiser les fichiers d’un projet, un espace dédié à l’environnement de travail, et un quatrième volet permettant d’afficher des graphiques ou de consulter la documentation sur les différents packages. Ce volet permet également d’accéder au répertoire des packages disponibles pour R et à l’arborescence des fichiers de l’utilisateur. De plus, il est possible de créer plusieurs espaces de travail – appelés projets – facilitant l’organisation des différents workflows.\nIl existe plusieurs autres aspects de RStudio que les programmeurs apprécient. Parmi eux, le fait que l’application peut être utilisée via un navigateur Web pour un accès à distance (Verzani, 2011). De plus, RStudio prend en charge plusieurs langages de programmation ainsi que différents langages de balisage. Qui plus est, de nouvelles fonctionnalités sont régulièrement ajoutées pour répondre aux besoins de la communauté scientifique. Enfin, le logiciel R lui-même est souvent mis à jour.\nParmi ce que certains considèrent comme les points faibles de RStudio, on retrouve des éléments liés à la configuration. Certains utilisateurs trouvent que le nombre de raccourcis est limité. D’autres jugent que l’organisation des différents panneaux n’est pas ergonomique, ou que la personnalisation de l’environnement de programmation est insuffisante. De plus, certains utilisateurs ont rapporté que RStudio était plus lent que d’autres alternatives pour certaines opérations, notamment celles impliquant de longs scripts.\n\n2.3.3 Comment utiliser RStudio ?\nBien que de nombreux éléments puissent être personnalisés, la disposition par défaut de RStudio est composée de quatre volets principaux (Verzani, 2011). Dans le coin supérieur gauche se trouve le volet principal. C’est dans celui-ci que l’utilisateur passera la majeure partie de son temps. On y modifie des fichiers de différents formats et il est possible d’y afficher des bases de données. Dans le coin inférieur gauche se trouvent la console et le terminal. Dans la console, on peut interagir avec R de la même manière que dans le volet principal, mais le code ne sera pas enregistré. Le terminal, quant à lui, est le point d’accès pour la communication entre l’utilisateur et son ordinateur. Bien que les différents systèmes d’exploitation soient livrés avec un terminal intégré, il est également possible d’y accéder à partir de RStudio.\nDans le coin supérieur droit, on retrouve l’espace de travail. Ce volet contient trois éléments : l’environnement global, l’historique et les connexions. L’environnement global est l’endroit où l’utilisateur peut voir les bases de données, les fonctions et les différents autres objets R actifs. Il peut cliquer sur les divers éléments actifs pour les consulter. L’onglet historique permet à l’utilisateur de consulter les derniers morceaux de code R qu’il a exécutés ainsi que les dernières commandes saisies dans la console. L’onglet connexions, quant à lui, permet de connecter l’IDE à une variété de sources de données et d’explorer les objets et données qu’elles contiennent. Il est conçu pour fonctionner avec divers outils permettant de travailler avec des bases de données en R dans RStudio.\nLe volet dans le coin inférieur droit, quant à lui, contient plusieurs outils très utiles pour les utilisateurs de RStudio. L’onglet Files permet de naviguer dans les fichiers présents sur l’ordinateur sans avoir à quitter RStudio. L’onglet Plots permet de visualiser les graphiques générés à partir de R, que ce soit en utilisant ggplot2, lattice ou base R. L’onglet Packages permet de consulter les packages installés précédemment par l’utilisateur et d’en consulter la documentation. C’est aussi un des endroits où il est possible d’installer des packages avec RStudio. L’onglet Help permet à l’utilisateur de rechercher et de consulter de la documentation sur de nombreux sujets, notamment sur les différentes fonctions en R ainsi que sur les packages. L’onglet Viewer, quant à lui, permet de visualiser du contenu web local.\nEnfin, l’utilisateur peut modifier les dimensions par défaut de chacun des quatre volets principaux. En cliquant sur la séparation entre les sections, il est possible d’ajuster la répartition horizontale de l’espace. De plus, chaque côté dispose d’une autre séparation permettant d’ajuster l’espace vertical. Qui plus est, la barre de titre de chaque volet comporte des icônes pour réduire un composant, maximiser un volet verticalement ou modifier la taille de l’espace de travail (Verzani, 2011 ; Nierhoff et Hillebrand, 2015).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Langages de programmation</span>"
    ]
  },
  {
    "objectID": "chapitre_2.html#conclusion",
    "href": "chapitre_2.html#conclusion",
    "title": "\n2  Langages de programmation\n",
    "section": "\n2.4 Conclusion",
    "text": "2.4 Conclusion\nLe langage de programmation R est un outil très utile pour toutes sortes de tâches, notamment liées aux statistiques et à la visualisation graphique. Sa maîtrise est requise pour accéder à plusieurs emplois, tant dans le monde académique que dans les secteurs public et privé. Nous espérons que le présent chapitre vous a éclairé sur son utilité et sa pertinence dans le monde du travail contemporain. Bien que le langage de programmation R ne doive pas obligatoirement être utilisé avec RStudio, nous pensons que, pour la plupart des utilisateurs, leur utilisation conjointe est bénéfique et recommandée. RStudio permet également d’utiliser différents langages de balisage compatibles avec R, facilitant ainsi l’utilisation de plusieurs outils complémentaires. L’apprentissage du langage de programmation R apparaît également comme une valeur sûre. Sa longévité dans plusieurs domaines ainsi que la forte croissance de sa base d’utilisateurs laissent présager que connaître au moins les bases de R constitue un énorme avantage pour tout le monde. Pour ceux qui sont particulièrement intéressés par le langage de programmation R et qui souhaitent s’impliquer dans sa communauté, il existe plusieurs conférences internationales et nationales sur R – notamment RConference et useR! – ainsi qu’un journal académique, The R Journal. On retrouve également différentes communautés, telles que R-Ladies, qui mettent de l’avant la diversité des genres dans la communauté du langage de programmation R. Le langage de programmation R est plus qu’un simple outil statistique, il est au centre d’une grande communauté de personnes qui ont à cœur des principes liés à l’inclusion et à l’avancement humain.\n\n\n\n\n\n\n\n\n\n\nMuenchen, R. A. (2011). R for SAS and SPSS Users (2nd ed). Springer.\n\n\nTippmann, S. (2015). Programming Tools: Adventures with R. Nature, 517(7532), 109‑110. https://doi.org/10.1038/517109a",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Langages de programmation</span>"
    ]
  },
  {
    "objectID": "chapitre_3.html",
    "href": "chapitre_3.html",
    "title": "3  À la quête de l’optimisation",
    "section": "",
    "text": "3.1 Point d’observation :",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>À la quête de l'optimisation</span>"
    ]
  },
  {
    "objectID": "chapitre_3.html#arpentage-et-choix-éditorial",
    "href": "chapitre_3.html#arpentage-et-choix-éditorial",
    "title": "3  À la quête de l’optimisation",
    "section": "3.2 Arpentage et choix éditorial :",
    "text": "3.2 Arpentage et choix éditorial :\n\n3.2.1 Gestion de tâches\nStructurer ses tâches est un processus fondamental pour mener un projet à terme. Particulièrement dans le monde académique, où les travaux s’échelonnent souvent sur plusieurs années, il est facile de perdre de vue ses objectifs ou de prendre des détours coûteux en temps si le chemin vers le produit final est mal défini. Gérer et structurer ses tâches de manière efficace facilite la mesure des progrès et permet de constamment vérifier si ceux-ci sont encore alignés avec les objectifs finaux.\n\n3.2.1.1 Comment\nGérer ses tâches de façon efficace passe par une structuration claire des objectifs du projet. Il est important de connaître la destination finale afin de choisir la meilleure direction pour y parvenir. Pour ce faire, il est utile de schématiser ou de lister la conception de la version finale du projet. Dans l’idéal, à quoi ressemble-t-il dans sa forme aboutie? Une fois cette vision clairement définie, il est possible de désagréger le projet en grandes étapes. Que faut-il accomplir, à l’échelle macro, pour atteindre les objectifs fixés?\nÀ cette étape, il est crucial de prendre en compte les ressources financières, temporelles et humaines disponibles. Cela permet de déterminer de manière réaliste ce qui est possible. Identifier ces grandes étapes contribue à la création d’un plan de projet structuré où chaque phase est clairement définie. Cela aide à anticiper les besoins en ressources et à ajuster les échéances en conséquence.\nLa révision continue est également un élément clé du processus de gestion des tâches. En réévaluant régulièrement l’état d’avancement du projet par rapport au plan initial, il est possible d’apporter des ajustements nécessaires pour rester sur la bonne voie. Cet astuce permet de répondre aux changements inévitables qui surviennent au cours de la recherche, qu’ils soient dus à des découvertes inattendues, des changements dans les directives institutionnelles ou des feedbacks des pairs.\n\n\n3.2.1.2 Quand\nAvec des objectifs bien définis et des étapes claires pour y parvenir, la structure du projet est complète. Il est donc temps de se lancer dans la gestion des tâches. En fonction des objectifs établis, certaines tâches sont plus importantes que d’autres. En effet, un projet est vraissemblablement composé de tâches qui doivent être réalisées avant que d’autres soient amorcées. Le défi est de déterminer efficacement ce qui doit être priorisé. L’agilité est un processus de travail qui facilite cette priorisation. En agilité, des objectifs sont fixés dans le temps, et sont évalués de manière constante. Les tâches sont déterminées en fonction de l’avancement et des blocants des objectifs.\nAvec des objectifs bien définis et des étapes claires pour y parvenir, la structure du projet est complète. Il est donc temps de se lancer dans la gestion des tâches. En fonction des objectifs établis, certaines tâches sont plus importantes que d’autres. Un projet est généralement composé de tâches qui doivent être réalisées dans un ordre spécifique, où certaines doivent impérativement précéder d’autres. Le défi est de déterminer efficacement ce qui doit être priorisé pour maintenir une progression fluide et efficace.\nL’agilité est un processus de travail qui facilite cette priorisation. En adoptant une approche agile, les objectifs sont fixés dans le temps et sont constamment évalués. Cela permet une adaptation rapide et une réponse aux changements sans compromettre les résultats finaux. De cette façon, les tâches sont déterminées et ajustées en fonction de l’avancement du projet et des éventuels obstacles rencontrés. Le projet avance de façon incrémentale.\nPour une mise en œuvre efficace de l’agilité, il est utile de planifier ses objectifs sur une période de quelques semaines, connues sous le nom de sprints en méthode Scrum, où on évalue le travail accompli et on redéfinit les priorités pour la prochaine période. Ces sprints permettent de s’assurer de rester concentré sur les tâches qui apportent le plus de valeur au projet et d’ajuster les plans en temps réel en fonction des résultats obtenus.\n\n\n3.2.1.3 Où\n\nToutes ces pratiques deviennent rapidement complexes si elles ne sont pas encadrées dans un environnement qui permet d’en faire le suivi. Il peut être judicieux de faire appel à des outils de gestion de projet qui supportent l’agilité, tels que Notion ou Mondays. Ces outils permettent de visualiser les tâches à faire sous forment de tableaux de bords intéractifs, dans lesquels il est possible de les déplacer en fonction de leur statut d’avancement. Ces outils permettent de structurer les tâches d’un projet et d’en faire le suivi facilement du début à la fin.\nIl est également judicieux de faire appel à des outils de gestion de projet qui supportent l’agilité, tels q. Ces outils permettent de visualiser les tâches sous forme de tableaux de bord interactifs où les tâches peuvent être déplacées, modifiées ou mises à jour en temps réel. Ils favorisent la transparence et la communication entre les membres de l’équipe, essentielles pour une gestion agile des tâches.\nEnfin, il est crucial d’intégrer des pratiques de réflexion et d’amélioration continue. Après chaque sprint, l’équipe devrait se réunir pour une rétrospective afin de discuter de ce qui a bien fonctionné et de ce qui pourrait être amélioré. Cette culture de l’amélioration continue est au cœur de l’agilité et contribue à l’efficacité et à la réussite du projet à long terme.\nPour déterminer quelles tâches accomplir et dans quel ordre, voici une court processus par étapes :\n\nÉlaborer les tâches en fonction des objectifs de sprint.\nDéterminer la linéarité des tâches, c’est-à-dire, quelle tâche doit être accomplie afin d’en début une autre.\nQuantifier le poids de chaque tâche. Certaines tâches sont plus longues que d’autres. Adopter un système qui vous permet d’identifier quelles tâches prendront quelques minutes seulement (comme l’envoi du courriel), et quelles tâches prennent plusieurs jours. Si une tâche est trop longue, c’est un signe qu’elle pourrait être désagrégée en plusieurs tâches plus petites. Cela facilite également le suivi.\nDonner une échéance réaliste à chaque tâche, en fonction des étapes précédentes. Idéalement, toutes les tâches ne sont pas dues pour la même date, pour éviter un goulot d’étranglement. Les échéances aident à prioriser les tâches.\nPrioriser les tâches qui ont l’échéance le plus sérré. Si certaines tâches accumulent un retard, c’est peut-être parce que vous devez réévaluer les échéances, les objectifs, ou encore parce qu’il y a des blocants dans vos méthodes de travail. Faire un tel suivi permet d’évaluer sa propre efficacité dans ses méthodes de travail.\n\nL’utilisation d’outils numériques pour la gestion des tâches ne signifie pas qu’il faut abandonner l’agenda papier ou le cahier de notes. Plusieurs trouvent essentiels de prendre des notes et de se faire des listes de tâches à la main. Il est tout à fait possible de combiner les méthodes. À chaque début de semaine, mettez à jour votre gestionnaire de tâches, puis faites votre liste de tâches à la main en conséquence, et planifiez votre semaine. De cette façon, vous savez chaque jour le travail à prioriser.\n\n\n\n3.2.1.4 Gestion de versions en équipe (Pull-push, pull-requests)\nLorsque l’on aborde le domaine de la recherche scientifique en sciences sociales numériques, la collaboration et la gestion efficace du code deviennent des éléments cruciaux pour progresser dans ses projets. Dans cette optique, les outils de gestion de versions décentralisés ont pris une place prépondérante. Parmi eux, Git et GitHub se démarquent tant par leur popularité que par leur efficacité.\n\n3.2.1.4.1 Avantages\nGit, développé par Linus Torvalds en 2005, s’est imposé comme le système de gestion de versions décentralisé de référence. Sa principale force réside dans sa capacité à suivre l’évolution d’un projet en enregistrant les modifications apportées au code source. Chaque modification est enregistrée sous forme de dépôts (commits), avec un message explicatif, permettant aux collaborateurs de comprendre facilement les évolutions du projet. \nGitHub, lancé en 2008, est une plateforme qui utilise Git comme base pour l’entreposage et la gestion de projets. C’est une vitrine virtuelle où les développeurs peuvent héberger leurs dépôts Git et collaborer de manière transparente. L’aspect social de GitHub, avec ses fonctionnalités de suivi des projets, de gestion des problèmes et de demandes de fusion, en fait un lieu de choix pour les projets en code source ouvert et collaboratifs.\nEn sciences sociales numériques, où le partage et la collaboration sont essentiels, Git et GitHub offrent plusieurs avantages majeurs. Tout d’abord, ils permettent de suivre les modifications apportées au code, ce qui facilite la reproductibilité des résultats. Les chercheurs peuvent revenir à n’importe quelle version précédente du code, ce qui est particulièrement utile pour corriger des erreurs ou analyser l’impact de différentes approches. \nDe plus, Git et GitHub favorisent le travail collaboratif. Plusieurs chercheurs peuvent travailler sur le même projet simultanément, chacun dans sa branche de développement. Une fois les modifications effectuées, il est possible de fusionner les branches pour intégrer les changements. Cette approche évite les conflits majeurs et facilite la répartition des tâches au sein de l’équipe.\nEnfin, l’aspect de code source ouvert de GitHub permet aux chercheurs en sciences sociales numériques de partager leurs codes avec la communauté académique et de bénéficier des contributions d’autres chercheurs. Cela favorise un environnement de partage des connaissances et de collaboration fructueuse.\n\n\n3.2.1.4.2 Inconvénients\nCependant, Git et GitHub ne sont pas sans leurs défis. La courbe d’apprentissage peut être raide pour les débutants, car ces outils impliquent des concepts spécifiques tels que les branches, les conflits de fusion et les requêtes de tirage. De plus, bien que GitHub offre un niveau de gratuité pour les projets en code source ouvert, des frais peuvent être appliqués pour des fonctionnalités avancées ou pour des projets privés.\n\n\n3.2.1.4.3 Comment les utiliser efficacement (en parallèle à Dropbox, etc.)\nPour utiliser Git et GitHub efficacement dans un contexte de recherche en sciences sociales numériques, il est recommandé de suivre quelques bonnes pratiques. Tout d’abord, il est important de structurer son dépôt Git de manière logique, en organisant les fichiers et les dossiers de manière cohérente. Les messages de commit doivent être descriptifs et clairs, pour permettre à tous les collaborateurs de comprendre les changements effectués.\nIl est également conseillé de travailler sur des branches distinctes pour chaque fonctionnalité ou modification majeure. Cela facilite la gestion des changements et minimise les conflits lors de la fusion. Les chercheurs devraient également consulter régulièrement les projets et les problèmes sur GitHub pour encourager une communication ouverte et résoudre rapidement les problèmes.\nL’utilisation de Git et de GitHub peut être complémentaire à d’autres outils d’entreposage, tels que Dropbox ou Google Drive. Ces derniers peuvent être utilisés pour entreposer des fichiers non liés au code, tels que des données brutes non sensibles ou des documents de recherche, tandis que Git et GitHub gèrent le code source et ses évolutions.\nBien qu’il existe plusieurs alternatives à l’utilisation combinée de Git et de GitHub sur le marché, ces deux plateformes liées continuent de dominer le domaine de la gestion de versions décentralisée. Parmi les alternatives notables, on peut citer Mercurial, Bitbucket, GitLab et SourceForge. Chacun de ces outils offre des fonctionnalités similaires à celles de Git et GitHub, mais il est important de comprendre pourquoi Git et GitHub restent les choix privilégiés pour les chercheurs en sciences sociales numériques.\n\n\n3.2.1.4.4 Pourquoi prioriser Git et GitHub pour les chercheurs en sciences sociales\n\nIntégration et adoption répandue : Git est devenu un standard de facto dans l’industrie du développement logiciel. Sa popularité et son adoption répandue signifient que de nombreuses ressources d’apprentissage, des tutoriels et des forums de support sont disponibles en ligne, ce qui facilite l’utilisation de cet outil pour les chercheurs en sciences sociales débutants. GitHub, en tant que plateforme principale de gestion des versions, bénéficie également d’une grande base d’utilisateurs et d’une communauté active, ce qui encourage la collaboration et le partage des connaissances.\nFacilité de collaboration : Git et GitHub sont conçus pour faciliter la collaboration entre les individus et les équipes. Les chercheurs en sciences sociales travaillent souvent ensemble sur des projets de recherche, et la capacité de suivre les modifications, de gérer les conflits et de fusionner les contributions devient essentielle. L’interface conviviale de GitHub, avec des fonctionnalités telles que les demandes de fusion et les commentaires en ligne, simplifie grandement la collaboration.\nVisibilité et partage : GitHub brille par sa fonctionnalité de projet open source, qui permet aux chercheurs en sciences sociales de partager leurs travaux avec la communauté mondiale. Les projets en code source ouvert sont visibles et accessibles à tous, favorisant ainsi la collaboration et l’examen par les pairs. Cela peut être particulièrement bénéfique pour les chercheurs souhaitant contribuer à des initiatives académiques et collaborer à des projets interdisciplinaires. \nSuivi des versions et recherche reproductible : Les chercheurs en sciences sociales doivent s’assurer que leurs travaux sont reproductibles et vérifiables. Git permet de suivre les versions du code, ce qui signifie que les chercheurs peuvent retrouver facilement des versions antérieures pour reproduire des analyses spécifiques ou corriger des erreurs. Cette fonctionnalité est cruciale pour maintenir l’intégrité des résultats de recherche.\nInfrastructure et sécurité : GitHub offre une infrastructure robuste pour l’entreposage sécurisé des dépôts Git. Les chercheurs peuvent être assurés que leurs travaux sont sauvegardés et protégés contre les pertes de données accidentelles. De plus, les contrôles d’accès et les autorisations granulaires de GitHub permettent aux chercheurs de contrôler qui peut accéder et contribuer à leurs projets.\n\nEn somme, Git et GitHub offrent aux chercheurs en sciences sociales numériques un moyen puissant de gérer leur code, de collaborer efficacement et de contribuer à la communauté académique grâce à l’open source. Bien que leur apprentissage puisse représenter un défi initial, les avantages qu’ils apportent en termes de suivi des versions, de collaboration et de partage des connaissances en font des outils essentiels dans l’arsenal de tout chercheur moderne.\n\n\n3.2.1.4.5 Pratiques à éviter sur GitHub pour les chercheurs en sciences sociales\nLorsque les chercheurs en sciences sociales utilisent GitHub pour partager leur code, collaborer sur des projets et contribuer à la communauté académique, il est essentiel de connaître les pratiques à éviter. En effet, certaines erreurs peuvent compromettre la sécurité, la confidentialité et l’efficacité de la recherche. Voici quelques éléments à éviter :\n\nEntreposer des informations sensibles : Évitez d’entreposer des données sensibles ou confidentielles sur GitHub. Cela inclut les données de sondages, les informations personnelles identifiables et tout autre contenu pouvant porter atteinte à la vie privée des individus. Assurez-vous de supprimer ou de masquer soigneusement ces informations avant de les télécharger sur la plateforme.\nInclure des mots de passe et clés d’accès : Ne jamais inclure de mots de passe, de clés d’accès ou d’informations d’identification dans votre code source. Cela peut compromettre la sécurité de vos systèmes et de vos données. Utilisez plutôt des méthodes sécurisées pour gérer ces informations, telles que les variables d’environnement ou les fichiers de configuration externes. \nEntreposer des fichiers lourds : Évitez d’entreposer des fichiers volumineux sur GitHub, notamment des fichiers binaires, des données brutes massives ou des ensembles de données volumineux. Ces fichiers peuvent ralentir les opérations de clonage et de fusion, ce qui affecte la performance globale du dépôt. Utilisez plutôt des services d’entreposage dédiés pour ces fichiers et fournissez des liens vers ces ressources dans votre dépôt.\nInclure des identifiants personnels : Évitez de publier vos propres identifiants personnels, tels que des numéros de sécurité sociale, des numéros de carte de crédit ou d’autres informations confidentielles. Ces informations pourraient être exploitées à des fins malveillantes si elles tombent entre de mauvaises mains.\nIgnorer les pratiques de branches et de fusion : Évitez de fusionner directement du code dans la branche principale (habituellement appelée main ou master). Utilisez plutôt des branches distinctes pour les fonctionnalités et les corrections, et suivez les pratiques de fusion pour intégrer proprement les changements. Ignorer ces pratiques peut entraîner des conflits et une perte de trace des modifications. \nIgnorer les commentaires des collaborateurs : Lorsque vous travaillez avec d’autres chercheurs, ne négligez pas les commentaires et les suggestions qu’ils fournissent. Les retours d’expérience et les idées des autres peuvent contribuer à améliorer la qualité de votre code et de vos analyses.\nNe pas documenter : Évitez de ne pas documenter votre code. Une documentation claire et détaillée est essentielle pour permettre à d’autres chercheurs de comprendre vos méthodes et vos résultats. Utilisez des commentaires explicatifs et fournissez des explications sur la manière d’exécuter votre code.\n\nEn suivant ces conseils et en évitant ces erreurs courantes, les chercheurs en sciences sociales peuvent garantir la sécurité, la qualité et l’efficacité de leurs projets sur GitHub. La responsabilité de préserver la confidentialité des données et de créer un environnement de travail collaboratif et respectueux repose sur les épaules de chaque contributeur.\n\n\n3.2.1.4.6 Exemple d’utilisation de Git et de GitHub pour un chercheur en sciences sociales\nDans le contexte de la recherche en sciences sociales numériques, la gestion efficace du code, la collaboration transparente et la préservation des données sensibles sont des impératifs. Imaginons que vous êtes un jeune chercheur en sciences sociales qui étudie l’impact des médias sur l’opinion publique. Vous utilisez le langage de programmation R pour analyser des données de médias et des données de sondage. Bien que vous travailliez seul, vous souhaitez rendre votre travail accessible à votre équipe pour validation et permettre à vos collègues de contribuer aux améliorations. Voici comment vous pouvez utiliser Git et GitHub pour gérer votre projet de manière structurée et collaborative.\n\n3.2.1.4.6.1 Étape 1 : Création d’un répertoire local et initialisation de Git\nOuvrez votre terminal et naviguez vers le dossier où vous souhaitez enregistrer votre projet.\ncd chemin/vers/votre/dossier\nCréez un nouveau répertoire pour votre projet et accédez-y.\nmkdir mon_projet\ncd mon_projet\nInitialisez Git dans ce répertoire.\ngit init\n\n\n3.2.1.4.6.2 Étape 2 : Ajout de votre code et de vos fichiers\nAjoutez vos fichiers R contenant le code pour l’analyse des médias et des sondages dans le répertoire. Par exemple, vous pouvez avoir des fichiers analyse_medias.R et analyse_sondages.R.\nUtilisez la commande git status pour vérifier l’état de vos fichiers.\ngit status\n\n\n3.2.1.4.6.3 Étape 3 : Ajout, validation et commit de vos modifications\nAjoutez vos fichiers pour qu’ils soient prêts à être validés.\ngit add -A\nValidez vos modifications avec un message descriptif.\ngit commit -m \"Ajout du code d'analyse des médias et des sondages\"\n\n\n3.2.1.4.6.4 Étape 4 : Création du répertoire sur GitHub et du lien avec votre répertoire local\nAllez sur GitHub et connectez-vous à votre compte. Créez un nouveau répertoire vide avec le nom mon_projet.\nDe retour dans votre terminal, ajoutez le lien GitHub à votre répertoire local.\ngit remote add origin https://github.com/votre-utilisateur/mon_projet.git\n\n\n3.2.1.4.6.5 Étape 5 : Push de votre travail sur GitHub\nEnvoyez vos commits locaux vers GitHub.\ngit push -u origin master\n\n\n3.2.1.4.6.6 Étape 6 : Collaboration avec vos collègues\nSi vos collègues souhaitent contribuer à votre projet, ils peuvent forker votre répertoire sur GitHub, ce qui créera une copie dans leur propre compte.\nLorsqu’ils ont fait des modifications dans leur copie, ils peuvent soumettre une pull request pour vous demander de fusionner leurs modifications dans votre répertoire principal.\n\n\n3.2.1.4.6.7 Étape 7 : Pull des modifications de vos collègues\nLorsque vos collègues ont soumis des modifications et vous ont demandé de les fusionner, vous pouvez mettre à jour votre répertoire local avec leurs changements.\ngit pull origin master\n\n\n3.2.1.4.6.8 Étape 8 : Répéter le processus\nRépétez les étapes 2 à 7 au fur et à mesure que vous développez votre projet, ajoutez du code, effectuez des analyses et collaborez avec vos collègues. Assurez-vous de valider et de pousser régulièrement vos modifications pour maintenir le dépôt à jour.\n\n\n\n3.2.1.4.7 GitHub Desktop\nAlors que le terminal reste une approche fondamentale pour maîtriser Git et GitHub, il existe des outils conviviaux tels que GitHub Desktop qui offrent une alternative intuitive. Cet outil simplifie le processus de gestion de versions décentralisée, en particulier pour ceux qui souhaitent commencer par une approche visuelle. Cependant, comprendre son fonctionnement et équilibrer les avantages et les inconvénients est essentiel.\n\n\n\nimage\n\n\nGitHub Desktop fournit une vue claire de vos dépôts, de vos modifications, de vos branches et de vos demandes de fusion. Il élimine la nécessité de mémoriser les commandes en ligne de terminal, ce qui peut être un défi pour certains chercheurs. L’application simplifie également la résolution des conflits lors de la fusion des branches.\nToutefois, en utilisant GitHub Desktop, il est possible de perdre la compréhension des commandes Git en ligne de commande, ce qui pourrait devenir un inconvénient si vous devez travailler dans un environnement sans interface visuelle. De plus, GitHub Desktop est spécifiquement conçu pour interagir avec GitHub. Si vous devez travailler avec d’autres plateformes de gestion de versions, cela pourrait poser des problèmes.\nLa décision entre l’utilisation du terminal et de GitHub Desktop dépend de vos préférences et de vos besoins. Pour les chercheurs qui débutent, GitHub Desktop offre une transition en douceur vers les concepts de gestion de versions. Cependant, il est important de ne pas se limiter à une interface visuelle. Comprendre les commandes Git en ligne de commande reste essentiel pour résoudre des problèmes complexes, gérer des projets avancés et collaborer avec d’autres chercheurs qui utilisent des approches basées sur le terminal.\n\n\n3.2.1.4.8 Conclusion\nEn utilisant Git et GitHub de manière stratégique, vous pouvez gérer efficacement votre projet de recherche en sciences sociales, collaborer avec vos collègues et rendre votre travail accessible tout en préservant la confidentialité des données sensibles. Ce processus contribue à un environnement de recherche collaboratif et structuré, essentiel pour mener à bien vos analyses sur l’impact des médias sur l’opinion publique.\n\n\n\n\n3.2.2 Gestion de communication\nLa communication et la collaboration sont au cœur de la recherche académique. Sur tout projet collaboratif, la communication joue un rôle essentiel, et il est crucial de la gérer efficacement pour garantir le succès d’un projet. Avec la multiplication des lieux de travail et l’essor généralisé du travail à distance, les outils de gestion de communication sont désormais incontournables. Dans le monde académique, les projets impliquent souvent des chercheurs répartis dans plusieurs universités, voire plusieurs pays. Dans ces contextes, les échanges par courriel atteignent rapidement leurs limites.\nAinsi, de nombreux milieux professionnels, y compris dans la recherche, ont adopté des outils tels que Microsoft Teams, Slack, et Mattermost pour organiser et structurer la collaboration. Ces plateformes permettent de centraliser les échanges, suivre l’évolution des tâches, et faciliter la coordination en temps réel ou de manière asynchrone.\nEn tant qu’étudiants en sciences sociales, vous serez probablement amenés à utiliser un ou plusieurs de ces outils au cours de votre parcours académique. Au-delà de simplement savoir les utiliser comme membre d’une équipe, savoir les optimiser est une compétence de plus en plus valorisée dans les milieux académiques et professionnels. Ces outils ne sont pas uniquement des espaces de discussion : ils facilitent l’organisation du travail collaboratif et d’équipes de travail, ce qui permet de mieux répondre aux défis du travail à distance et à la coordination de projets complexes.\nIl existe plusieurs outils permettant un telle coordination. Nous comparons trois de ces outils, afin d’évaluer leurs forces et leurs différences, et comment est-ce qu’ils sont utilisés dans le domaine. Teams est issue de la suite Microsoft. Il est souvent inclu dans un abonnement Microsoft 365, qui est lui même fourni par certaines institutions. Si tel est le cas, cela rend cet outil très accessible. C’est d’ailleurs une des forces de Teams : Les utilisateurs habitués aux autres outils de la suite Microsoft trouvent la compatibilité pratique. L’utilisation de Teams en parallèle avec Microsoft Word, Excel OneDrive et autres centralise tous les outils nécessaires au même endroit. Cette intégration dans la suite Microsoft peut être perçue comme un désavantage. Ceux qui n’utilisent pas les fonctionnalités Microsoft peuvent trouver Teams peu flexible et contraignant, et sa compatibilité avec d’autres outils difficile. Teams est populaire dans tous les milieus, que ce soit académique, dans le privé ou dans le public. Microsoft offre de la documentation abondante, ce qui permet d’apprendre facilement son utilisation.\nTeams est entré sur le marché afin d’entrer en compétition avec le deuxième outil présenté : Slack. Slack a été l’un des premiers outils à offrir une solution de messagerie instantanée dédiée aux équipes de travail, intégrant des fonctionnalités collaboratives avancées comme les canaux de discussion et une interface simple d’utilisation. Slack offre une version gratuite limitée dans ses fonctionnalités, ce qui joue sur son accessibilité. Sa version payante, avec un prix à l’utilisateur, est toutefois très compatible et efficace. Ses applications permettent d’intégrer d’autres outils comme Google Drive, Dropbox, Github et Notion. C’est une des plus grande force de Slack : sa compatibilité avec d’autres outils très populaire qui ne font pas partie de sa propriété, comme c’est le cas avec Microsoft Teams. Étant donné sa percée dans le monde professionnel, Slack compte une large communauté d’utilisateurs, et demeure très populaire dans le monde académique.\nMoins populaire que les deux premiers outils proposés, Mattermost, cependant, est libre d’accès. C’est donc l’option la plus accessible, et elle permet le plus grand contrôle, le plus de transparence, et la plus grande flexibilité. Cette flexibilité peut nécessité une courbe d’apprentissage plus importante, mais étant libre d’accès, toute ressource par rapport à sa conception ou à son utilisation est disponible en ligne. Mattermost est donc très compatible à d’autres outils, mais peut nécessité des compétences un peu plus pointues pour permettre ces compatibilités. Autrement dit, les utilisateurs de Mattermost se font moins prendre par la main, mais les possibilité qu’offre sa plateforme flexible sont plus grandes. La popularité de l’outil repose donc davantage parmis des groupes de développeurs, et moins dans des entreprises ou dans des groupes de recherche académiques.\nlibrary(tinytable) library(tidyverse)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>À la quête de l'optimisation</span>"
    ]
  },
  {
    "objectID": "chapitre_3.html#manuel-dinstruction",
    "href": "chapitre_3.html#manuel-dinstruction",
    "title": "3  À la quête de l’optimisation",
    "section": "5.1 Manuel d’instruction :",
    "text": "5.1 Manuel d’instruction :\n\n5.1.1 Gestion de tâches\n\n\n5.1.2 Gestion de communication\nNotre outil de communication sélectionné est Slack. Nous vous proposons quelques conseils pratiques pour bien l’utiliser en équipe, mais aussi de façon plus personnalisée. Bien structurer votre utilisation de Slack vous aidera à mieux collaborer avec vos collègues, à suivre les conversations importantes, et à éviter la confusion entre les différentes chaînes de discussion.\n\n5.1.2.0.1 Structuration\nLa structure des chaînes de discussion est cruciale pour éviter le chaos et la perte d’informations. En début de projet, réfléchissez à la manière dont vous allez organiser les discussions dans Slack. Voici quelques principes de base :\n\nChaînes par projet : Créez une chaîne pour chaque projet ou thème de recherche. Par exemple, si vous travaillez sur un projet de sondage, créez une chaîne dédiée avec un nom suffisamment précis, comme #sondage_religiosité.\nSous-chaînes pour les sujets complexes : Si une chaîne devient trop active et que les sujets abordés sont variés, envisagez de créer des sous-chaînes pour désagrégés les discussions. Cela évite de perdre le fil et de l’information importante. Une sous-chaîne pourrait porter le nom #sondage_religiosité_analyse, par exemple.\nFils de discussion : Répondez à des messages dans les fils de discussion pour permettre le roulement d’autres sujets dans la chaîne. Cela évite que les discussions s’entremêlent.\nMarques-pages et messages épinglés : Quand un message est particulièrement important, épinglez le à la chaîne. Vous pouvez également placer en marque-page des documents qui réfèrent à la chaîne. Par exemple, si une chaîne porte sur une demande de financement en rédaction, vous pourriez mettre en marque-page le document dans lequel vous rédigez, où les consignes de la demande, pour y avoir accès rapidement.\nPréfixes pour l’organisation : Utilisez des préfixes pour classer les chaînes selon des thèmes ou des projets. Cela permet de mieux s’y retrouver quand le nombre de chaînes augmente (#sondage_, #finacement_). Si vous utiliser un logiciel de gestion de tâches, alors vos noms de chaînes devraient calquer la typologie que vous utilisez avec vos autres outils. C’est un élément important pour éviter la confusion.\n\n\n\n\n5.1.2.0.2 Collaboration\nLa transparence est un des principes clés de Slack, et il est important que la majorité des discussions liées aux projets se déroulent dans les chaînes publiques et non dans des messages privés. Tentez de suivre ces lignes directrices :\n\nFavoriser les conversations dans les chaînes : Si une discussion concerne tout le monde sur un projet, évitez d’utiliser des messages privés. Cela permet à tous les membres de rester informés et de participer aux discussions importantes.\nGestion des membres : Veillez, comme équipe, à ce que les bonnes personnes soient dans les bonnes chaînes. Chaque membre d’une chaîne doit pouvoir contribuer à la conversation sans être submergé par des informations inutiles.\nChaînes dédiées aux partenaires externes : Si vous travaillez avec des partenaires externes à votre équipe de travail, créez des chaînes spécifiques pour eux. Cela vous permet de garder vos conversations internes séparées des discussions externes, tout en facilitant la collaboration avec vos partenaires.\n\n\n\n5.1.2.0.3 Optimisation personnelle\nBien qu’il soit important de structurer en équipe votre Slack pour en faciliter l’utilisation, L’organisation personnelle de votre Slack est également importante. Elle permet de vous retrouver et d’apprivoiser votre outil. Voici quelques conseils à ce propos :\n\nSections et favoris : Organisez vos chaînes en créant des sections thématiques et des favoris. Par exemple, regroupez les chaînes de projet dans une section et les chaînes de financement dans une autre. Vous pouvez aussi sélectionner les chaines que vous utilisez davantage dans une section de favoris pour y accéder plus rapidement.\nParamètres de notification : Ajustez vos notifications pour ne pas être submergé. Vous pouvez choisir d’être alerté seulement pour les chaînes prioritaires et désactiver les notifications pour les discussions moins urgentes.\nIntégrations avec d’autres outils : Slack offre des intégrations avec des outils que vous utilisez peut-être déjà, comme Google Calendar, GitHub ou Notion. Explorez ces intégrations pour recevoir des notifications directement dans Slack et automatiser certains processus.\nFonctionnalités Slack : Slack offre plusieurs fonctionnalités pour vous aider dans la gestion de vos messages. Explorez ces fonctionnalités, telles que Activité, Plus tard et À voir. Chaque personne fonctionne différemment, et ces fonctionnalités vous permettent de trouver ce qui vous convient le mieux.\n\n\n\n\n5.1.3 Gesstion de données\nPour utiliser Dropbox efficacement, organisez vos fichiers en arborescence logique. Créez des dossiers spécifiques pour chaque projet et partagez-les avec les membres de votre équipe. Pour éviter de pousser des fichiers sensibles sur GitHub, ajoutez le nom de dossier à exclure dans un fichier .gitignore.\n\n\n\nimage1\n\n\n\nDropbox offre un suivi automatique des modifications, ce qui vous permet de remonter dans le temps pour restaurer des versions antérieures de vos fichiers. Cela garantit l’intégrité de vos données et vous permet de revenir à des versions précédentes si nécessaire. De plus, l’archivage de dossiers et de projets complets peut aider à conserver une vue chronologique de votre travail au fil du temps.\nIl est également crucial de considérer la taille de vos données. Si vous traitez des fichiers volumineux tels que des images, des vidéos ou des ensembles de données massifs, il peut être judicieux d’utiliser un service cloud pour entreposer ces fichiers et les partager avec vos collaborateurs, plutôt que de les pousser sur des plateformes de gestion de versions comme GitHub.\nPour les données sensibles, les services cloud tels que Dropbox et Google Drive peuvent ne pas être suffisamment sécurisés. C’est là que des solutions comme AWS entrent en jeu. Cependant, il est important de noter que l’utilisation d’AWS peut s’avérer complexe, en particulier pour un jeune chercheur travaillant en solo ou en petite équipe.\n\n5.1.3.1 Exemple d’utilisation d’AWS pour entreposer et accéder à des données de sondages dans RStudio\nImaginez un jeune chercheur en sciences sociales qui travaille sur une analyse comparative de données de sondages recueillies sur plusieurs décennies. Pour maintenir la sécurité des données sensibles et faciliter l’accès pour les analyses dans RStudio, il décide d’utiliser AWS pour l’entreposage et la gestion de ses données.\n\n5.1.3.1.1 Étape 1 : Création d’un compte AWS et configuration\nLe chercheur crée un compte AWS et configure ses paramètres de sécurité, y compris la configuration de l’authentification à deux facteurs pour renforcer la sécurité de son compte.\n\n\n5.1.3.1.2 Étape 2 : Création d’un espace d’entreposage S3\nLe chercheur crée un compartiment Amazon S3 (Simple Storage Service) pour entreposer ses données de sondage. Il choisit une région AWS et définit les paramètres de sécurité appropriés, tels que le chiffrement des données.\n\n\n5.1.3.1.3 Étape 3 : Transfert des données vers Amazon S3\nLe chercheur transfère les données de sondage dans son compartiment Amazon S3 à l’aide de l’interface en ligne AWS ou d’outils d’importation.\n\n\n5.1.3.1.4 Étape 4 : Configuration des autorisations\nPour sécuriser davantage les données, le chercheur configure les autorisations d’accès aux données dans Amazon S3. Il attribue des rôles et des politiques d’accès spécifiques aux utilisateurs, garantissant que seules les personnes autorisées peuvent accéder aux données.\n\n\n5.1.3.1.5 Étape 5 : Configuration d’accès dans RStudio\nLe chercheur installe le package aws.s3 dans RStudio pour accéder à ses données entreposées dans Amazon S3. Il configure également les informations d’identification AWS dans son environnement RStudio.\n\n\n5.1.3.1.6 Étape 6 : Accès et analyse des données dans RStudio\nÀ l’aide du package aws.s3, le chercheur peut maintenant accéder à ses données directement dans RStudio par quelques lignes de code. Il peut charger les données dans des structures de données R et effectuer des analyses statistiques, des visualisations et des croisements. \n\n\n5.1.3.1.7 Étape 7 : Sécurité et conservation des données\nAprès avoir effectué ses analyses, le chercheur peut choisir de conserver les données de sondage dans Amazon S3 en utilisant les politiques de conservation appropriées. Il peut également archiver des copies de sauvegarde pour garantir l’intégrité des données à long terme.\nDropbox se concentre principalement sur l’entreposage et la collaboration de fichiers, alors que AWS offre une gamme de services cloud, y compris l’entreposage sécurisé de données sensibles et la mise en place d’infrastructures évolutives. GitHub, d’autre part, se concentre sur la gestion de versions et la collaboration de code source. Chaque outil a son propre domaine d’expertise et peut être utilisé de manière complémentaire pour différents aspects de la recherche.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>À la quête de l'optimisation</span>"
    ]
  },
  {
    "objectID": "chapitre_3.html#limportance-dune-méthode-de-travail-efficace",
    "href": "chapitre_3.html#limportance-dune-méthode-de-travail-efficace",
    "title": "3  À la quête de l’optimisation",
    "section": "5.2 L’importance d’une méthode de travail efficace",
    "text": "5.2 L’importance d’une méthode de travail efficace\n\nAvant même de plonger dans les détails des méthodes de recherche et des analyses, il est crucial de poser les bases d’une méthode de travail efficace.  Qu’il s’agisse de travailler en solitaire ou en équipe, l’ordre et la structure sont des éléments essentiels. Des dossiers bien organisés, une arborescence claire  et un entreposage sécurisé deviennent les piliers sur lesquels repose votre productivité. Après tout, un environnement de travail organisé engendre des résultats ordonnés.\nCe chapitre vous emmènera à découvrir une gamme d’outils conçus pour répondre aux besoins spécifiques des chercheurs en sciences sociales numériques. Dans une quête pour maximiser votre temps, améliorer vos flux de travail et renforcer vos collaborations, nous explorerons trois types d’outils qui vous guideront dans cette quête d’optimisation :\n\nLogiciels de communication : La communication transparente est le cœur d’une collaboration réussie. Nous explorerons des outils tels que Slack qui facilitent les échanges en temps réel, connectant les chercheurs, même à distance, pour un partage rapide d’idées et d’informations.\nLogiciels de gestion de versions décentralisé : Nous plongerons dans le monde de Git et GitHub, des outils indispensables pour le suivi des versions et la collaboration efficace sur le code source.\nOutils d’entreposage de données : Que vous traitiez des données sensibles ou non, la conservation sécurisée de vos informations est primordiale. Des plateformes telles que Dropbox et Amazon Web Services (AWS) offrent des espaces sécurisés pour entreposer et partager vos données avec votre équipe.\n\nChacun de ces outils est une pièce du puzzle, conçue pour vous aider à gagner du temps, à collaborer de manière plus fluide et à renforcer la qualité de votre recherche en sciences sociales numériques. Plongeons dans ces outils avec un désir commun d’optimisation et d’excellence dans notre travail.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>À la quête de l'optimisation</span>"
    ]
  },
  {
    "objectID": "chapitre_4.html",
    "href": "chapitre_4.html",
    "title": "4  Outils de gestion de la littérature et des références",
    "section": "",
    "text": "4.1 Point d’observation: La littérature et les références\nLa gestion de la littérature scientifique ainsi que la gestion des références ont longtemps été des processus fastidieux, nécessitant une organisation rigoureuse des références, des notes de lecture et des articles accumulés au fil du temps. Avant l’avènement des outils numériques, les chercheurs dépendaient de méthodes manuelles pour organiser leur documentation. Les bibliographies étaient construites à la main ou à l’aide de logiciels de traitement de texte et les articles scientifiques étaient souvent archivés en version papier dans des classeurs ou des boîtes de rangement. Cette gestion physique de la littérature et des références était laborieuse, sujette aux erreurs et difficile à partager avec d’autres chercheurs ou collaborateurs.\nLe développement des technologies de l’information et la montée en puissance des bases de données en ligne ont ouvert la voie à l’émergence d’outils numériques de gestion de la littérature et de références. À mesure que les ordinateurs devenaient plus accessibles et que l’informatique évoluait, de nouvelles possibilités se sont offertes pour organiser et gérer de manière plus efficace et moins chronophage. C’est dans ce contexte que les premiers outils numériques de gestion de la littérature et des références ont vu le jour.\nCes logiciels de première génération, tels que EndNote (1988) et Bookends (1988), répondaient à un besoin pressant : faciliter l’organisation des références ainsi que leur insertion automatique dans des documents, tout en générant des bibliographies conformes à différents standards éditoriaux. Cependant, ces outils se sont rapidement sophistiqués à travers les années. Les logiciels de gestion de références sont devenus des plateformes centralisées permettant aux chercheurs de stocker des milliers de citations, de les classer par mots-clés ou thématiques et de les retrouver facilement. Les utilisateurs pouvaient aussi importer des références directement depuis des bases de données en ligne comme PubMed ou JSTOR, automatisant encore davantage le processus. Aujourd’hui, les outils de gestion de la littérature et des références, tels que Zotero (2006), Mendeley (2008) ou Covidence (2014), permettent non seulement de gérer des bibliographies, mais également de collaborer à plusieurs sur des revues systématiques, d’annoter des articles, d’organiser des données et de générer des rapports structurés. Leurs fonctionnalités cloud facilitent également la synchronisation entre différents appareils et assurent un accès en tout lieu.\nBien que ce chapitre aborde à la fois les outils de gestion de la bibliographie et des références, il est essentiel de préciser que ces deux types d’outils ont des utilités et fonctionnalités distinctes. Les outils de gestion des références, tels que EndNote et Zotero, se concentrent sur l’organisation, l’annotation et la création de bibliographies à partir de références. En revanche, les outils de gestion de la littérature, comme Covidence, Colandr et Rayyan, sont conçus pour gérer des processus de recherche plus complexes, tels que les revues systématiques, en facilitant la sélection, l’évaluation critique et la synthèse des études.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Outils de gestion de la littérature et des références</span>"
    ]
  },
  {
    "objectID": "chapitre_4.html#arpentage-et-choix-éditorial-covidence-et-zotero",
    "href": "chapitre_4.html#arpentage-et-choix-éditorial-covidence-et-zotero",
    "title": "4  Outils de gestion de la littérature et des références",
    "section": "\n4.2 Arpentage et choix éditorial: Covidence et Zotero",
    "text": "4.2 Arpentage et choix éditorial: Covidence et Zotero\n\n4.2.1 Pourquoi Covidence ?\nL’outil de gestion de la littérature Covidence permet une avancée majeure dans la pratique des revues systématiques, en offrant des fonctionnalités qui optimisent chaque étape du processus de recherche. Sa capacité à importer et organiser efficacement les références provenant de diverses bases de données bibliographiques permet une gestion structurée des articles à inclure dans une revue. Cet outil facilite également la collaboration, en permettant à plusieurs chercheurs de travailler simultanément sur un même projet, ce qui encourage une analyse plus inclusive et diversifiée. En automatisant les premières phases de sélection des articles, il réduit la charge de travail manuel et limite les biais potentiels. De plus, ses moyens d’extraction de données et d’évaluation de la qualité assurent une analyse rigoureuse et cohérente des résultats. Enfin, son intégration avec d’autres plateformes de recherche en renforce la compatibilité et l’efficacité dans le flux de travail académique.\nBien que Covidence soit développé par une organisation à but non lucratif, il ne répond pas pleinement aux critères du logiciel libre, car son code source n’est pas accessible pour modification ou redistribution par la communauté. Cette limitation peut freiner les utilisateurs souhaitant personnaliser l’outil en fonction de besoins spécifiques. Néanmoins, Covidence propose un modèle de licence adapté à un usage académique et non commercial, rendant l’outil accessible à une large communauté de chercheurs. L’une de ses principales forces réside dans son intégration des données issues de multiples bases bibliographiques, ce qui simplifie considérablement le processus de revue systématique. Covidence est également compatible avec des outils de gestion des références comme EndNote et Zotero, facilitant l’importation et l’organisation des références. De nombreuses institutions universitaires soutiennent l’outil, offrant des licences institutionnelles pour en élargir l’accès. En outre, l’interface intuitive de Covidence réduit la courbe d’apprentissage, guidant les utilisateurs à travers les différentes phases de la revue systématique de manière structurée et simplifiée par rapport aux méthodes traditionnelles. Ses fonctionnalités de double codage, de filtrage et d’extraction de données garantissent une méthodologie rigoureuse et standardisée, indispensable pour assurer la qualité des revues systématiques. De plus, Covidence excelle dans la facilitation de la collaboration entre chercheurs. La plateforme permet à plusieurs utilisateurs de travailler simultanément sur un même projet, d’échanger sur l’inclusion ou l’exclusion d’études, et de résoudre efficacement les divergences, ce qui s’avère particulièrement précieux pour les projets de grande envergure impliquant des équipes dispersées géographiquement.\nCependant, l’utilisation de Covidence présente certaines contraintes. Le coût de l’abonnement peut constituer un frein pour certains chercheurs, limitant ainsi l’accès à cet outil pourtant utile en recherche. De plus, la plateforme requiert une période d’apprentissage, ce qui peut retarder son adoption efficace, notamment pour les utilisateurs sans expérience préalable avec des outils similaires. Bien que Covidence propose des modèles standards pour l’extraction de données et l’évaluation de la qualité, ces derniers peuvent ne pas convenir à tous les types d’études, en particulier celles nécessitant une personnalisation plus poussée. Malgré ces défis, Covidence demeure un atout précieux pour la réalisation de revues systématiques, bien qu’il soit essentiel de peser soigneusement ses avantages et inconvénients en fonction des besoins spécifiques de chaque projet de recherche.\n\n\n\n\n    \n\n      \n\nRésumé des principaux outils de gestion de la littérature\n              \nCritères\n                Covidence\n                Colandr\n                Rayyan\n              \n\n\n\nAccessibilité (Gratuit ou peu dispendieux)\n                  Non (Abonnement requis)                  \n                  Oui (Gratuit)                   \n                  Oui (Freemium)                                 \n                \n\nExistence d'une communauté d'utilisateurs \n                  Oui                                      \n                  Modérée                         \n                  Oui                                            \n                \n\nPopularité dans le champ                  \n                  Très populaire dans la revue systématique\n                  Moins connu mais en croissance  \n                  Populaire pour la revue systématique           \n                \n\nCompatibilité avec d'autres outils        \n                  Oui (Importation facile de citations)    \n                  Oui (supports RIS, BibTeX, etc.)\n                  Oui (Intégration facile avec citation managers)\n                \n\nTransparence et réplicabilité             \n                  Non (propriétaire)                       \n                  Oui (Open-source)               \n                  Partiellement (propriétaire)                   \n                \n\nAdaptabilité et flexibilité               \n                  Oui (mais limité)                        \n                  Oui (beaucoup de flexibilité)   \n                  Oui (partiellement flexible)                   \n                \n\n\n\n\n\n\n\n4.2.2 Pourquoi Zotero ?\nZotero se distingue des autres outils de gestion des références par sa gratuité et son accessibilité en tant que logiciel libre, avec un code ouvert largement soutenu par une communauté active sur GitHub, qui compte plus de 13 000 contributions. Ce logiciel propose une vaste gamme de fonctionnalités et permet l’ajout d’extensions pour enrichir son utilisation, ce qui le rend particulièrement puissant tout en restant facile à utiliser. Zotero est compatible avec diverses plateformes, notamment Windows, Mac, Linux, iOS et Android, facilitant ainsi la collaboration entre les membres d’une équipe de recherche qui utilisent différents systèmes. La bibliothèque Zotero peut être synchronisée sur plusieurs appareils via le service cloud payant de Zotero ou en configurant un espace de stockage cloud personnel. Ce logiciel s’intègre parfaitement dans les projets de recherche utilisant LaTeX ou Quarto, permettant de générer et de maintenir à jour automatiquement des fichiers .bib. De plus, Zotero fonctionne avec des logiciels de traitement de texte tels que LibreOffice et Microsoft Office, et offre la possibilité de créer des bibliographies et des citations dans plus de 9 000 styles de citation différents, répondant ainsi aux divers besoins des chercheurs. En outre, il permet d’ajouter directement les documents PDF des références et d’y prendre des notes, ce qui simplifie considérablement la centralisation de l’information pertinente pour la recherche.\nZotero offre l’avantage significatif de centraliser les sources bibliographiques et les fichiers associés, simplifiant grandement le partage de documents au sein des équipes de recherche. Avec Zotero, il est possible d’ajouter des PDF et de les synchroniser dans des groupes de travail, ce qui élimine le besoin de recourir à des dossiers partagés ou d’envoyer des documents par courriel ou via des plateformes de partage de fichiers. Cette centralisation permet également de réaliser des recherches par mot-clé à travers l’ensemble des sources d’une bibliothèque, facilitant la récupération rapide de sources spécifiques.\nCependant, Zotero présente quelques inconvénients, notamment sa gestion parfois difficile de très grandes bibliothèques contenant des milliers de fichiers, ce qui peut nécessiter l’achat d’espace de stockage supplémentaire. Bien que performant, le logiciel requiert parfois la saisie manuelle d’informations que le connecteur intégré ne détecte pas automatiquement, représentant un potentiel défis pour les utilisateurs. Ces quelques défis soulignent l’importance d’évaluer les besoins spécifiques en matière de gestion bibliographique avant de choisir Zotero comme solution.\nZotero est souvent utilisé en combinaison avec BibLaTeX via l’extension Better BibTeX pour exporter et actualiser automatiquement des bibliographies au format .bib. BibLaTeX, une extension moderne pour gérer les bibliographies dans LaTeX et Quarto, s’utilise couramment avec Biber, un outil de traitement bibliographique avancé compatible avec BibLaTeX. Biber propose des fonctionnalités telles que le tri poussé, la gestion de multiples bibliographies et le traitement de divers formats de données bibliographiques. BibLaTeX, prenant en charge de nombreuses langues, est idéal pour la rédaction de documents destinés à un public international. L’exportation de bibliothèques Zotero sous forme de fichiers .bib pour leur utilisation avec BibLaTeX est simplifiée grâce à Better BibTeX, qui assure la mise à jour automatique de ces fichiers. Il est recommandé de maintenir dans votre fichier .bib uniquement les références utilisées, organisées par ordre alphabétique, afin de faciliter la collaboration et le partage des ressources.\n\n\n\n\n    \n\n      \n\nRésumé des principaux outils\n              \nCritères\n                Zotero\n                Mendeley\n                Endnote\n              \n\n\n\nAccessibilité (Gratuit ou peu dispendieux)\n                  Oui (Gratuit)                                        \n                  Partiellement (Freemium)         \n                  Non (Payant)                  \n                \n\nExistence d'une communauté d'utilisateurs \n                  Oui                                                  \n                  Oui                              \n                  Oui                           \n                \n\nPopularité dans le champ                  \n                  Très populaire                                       \n                  Très populaire                   \n                  Populaire                     \n                \n\nCompatibilité avec d'autres outils        \n                  Oui (Intégration facile avec Word, Google Docs, etc.)\n                  Oui (Microsoft Word, LibreOffice)\n                  Oui (Intégration avec Word)   \n                \n\nTransparence et réplicabilité             \n                  Oui (Open-source)                                    \n                  Partiellement (propriétaire)     \n                  Non (propriétaire)            \n                \n\nAdaptabilité et flexibilité               \n                  Oui (personnalisable avec plugins)                   \n                  Oui (moins flexible que Zotero)  \n                  Partiellement (moins flexible)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Outils de gestion de la littérature et des références</span>"
    ]
  },
  {
    "objectID": "chapitre_4.html#manuel-dinstructions-apprendre-covidence-et-zotero",
    "href": "chapitre_4.html#manuel-dinstructions-apprendre-covidence-et-zotero",
    "title": "4  Outils de gestion de la littérature et des références",
    "section": "\n4.3 Manuel d’instructions: Apprendre Covidence et Zotero",
    "text": "4.3 Manuel d’instructions: Apprendre Covidence et Zotero\n\n4.3.1 Covidence\nReconnu pour ses trois phases méthodiques — « Title and abstract screening », « Full text review » et « Extraction » — Covidence facilite l’importation de données volumineuses depuis des bases de données bibliographiques et interroge plusieurs bibliothèques. Cela offre un accès à des milliers d’études pertinentes qui aident les chercheurs à élaborer un cadre théorique exhaustif. Comme mentionné dans la section précédente, l’utilisation de Covidence implique un double codage, ce qui signifie que l’évaluation des études est effectuée manuellement par deux codeurs, permettant ainsi une analyse rigoureuse et détaillée de la littérature recueillie.\nLa première phase, le « Title and abstract screening », consiste à examiner les titres et résumés des articles récupérés. Pour optimiser cette tâche, il est crucial de définir des critères précis afin d’évaluer la pertinence des articles relativement au sujet étudié. Durant cette étape, souvent prolongée en raison du volume conséquent de la littérature, les chercheurs doivent régulièrement se consulter pour résoudre les divergences d’opinions et parvenir à un consensus.\nSuite à la révision des titres et des résumés, vient le « Full text review ». Cette étape implique l’examen complet des textes sélectionnés lors de l’étape précédente. Les chercheurs doivent alors voter « oui », « non », ou « peut-être » afin de décider de la conservation des textes, ce qui peut inclure ou exclure un article ou le faire progresser vers l’étape suivante. Cette phase, bien qu’elle concerne moins de documents, reste exigeante et chronophage principalement en raison des délibérations nécessaires pour arbitrer les divergences de points de vue.\nLa phase finale, celle de l’extraction des données, implique la collecte d’informations pertinentes des études finalement retenues, basée sur un schéma de codification prédéfini. L’objectif est de parvenir à un consensus parmi les codeurs. L’extraction dévoile les cadres théoriques, les méthodologies employées ainsi que les conclusions principales des recherches sélectionnées.\nUne fois les étapes de la revue systématique achevées, la plateforme Covidence facilite l’exportation des données extraites sous forme de tableaux, de graphiques et de rapports, destinés à être utilisés dans des méta-analyses ou la rédaction d’articles scientifiques. Bien que Covidence soit largement utilisé et supporté par de nombreuses universités via des licences, d’autres plateformes comme DistillerSR, Archie, et Rayyan sont également populaires parmi les chercheurs, chacune répondant à des besoins et des budgets variés.\n\n4.3.2 Zotero\nL’intégration de Zotero dans le processus de recherche académique permet une gestion structurée et efficace des références bibliographiques. Pour tirer pleinement parti des fonctionnalités de cet outil, il est essentiel de suivre les étapes suivantes pour l’installation, la configuration, et l’utilisation des principales fonctionnalités de Zotero.\n\n4.3.2.1 Installation et Configuration\nL’installation de Zotero commence par le téléchargement de l’application Zotero ainsi que de son extension pour navigateur, Zotero Connector. Cette extension permet de capturer facilement des références à partir de sources en ligne. Une fois l’installation terminée, il est recommandé de créer un compte Zotero via le lien d’inscription. Ce compte facilitera la synchronisation des données entre différents appareils et permettra le partage de bibliothèques de références avec des collaborateurs.\nLa configuration initiale est essentielle pour exploiter pleinement Zotero dans un cadre de collaboration. Les chercheurs peuvent créer et rejoindre des bibliothèques partagées, ce qui permet une gestion collective des références dans des projets communs.\n\n4.3.2.2 Ajouter des références à Zotero\nZotero offre plusieurs méthodes pour ajouter des références à une bibliothèque :\n\nGlisser-déposer : L’utilisateur peut importer des documents, tels que des PDF, directement dans la bibliothèque Zotero. Zotero tentera automatiquement de récupérer les métadonnées associées. En cas d’échec, l’outil « Baguette magique » permet de saisir manuellement les informations requises.\nUtilisation de l’outil Baguette magique : Lorsque des identifiants uniques tels que DOI ou ISBN sont disponibles, Zotero extrait automatiquement les métadonnées complètes de la référence. Si les informations ne sont pas trouvées, l’utilisateur a la possibilité de compléter manuellement les champs nécessaires.\nZotero Connector : Cet outil capture les références directement depuis le navigateur, en les classant automatiquement dans les collections de la bibliothèque Zotero. Cela permet une gestion instantanée des articles scientifiques et autres ressources en ligne.\n\n4.3.2.3 Optimisation des citations avec Better BibTeX\nL’installation de l’extension Better BibTeX est cruciale pour les chercheurs qui utilisent des systèmes de gestion documentaire comme LaTeX. Cette extension facilite la gestion des citations en générant des fichiers .bib mis à jour automatiquement.\nPour installer Better BibTeX, accédez à Zotero : Outils &gt; Modules complémentaires, puis sélectionnez l’option Installer un module à partir d’un fichier et choisissez le fichier .xpi préalablement téléchargé. Une fois l’installation terminée, configurez le module via Zotero &gt; Préférences &gt; Onglet Better BibTeX.\nAfin d’assurer une cohérence dans les clés de citation utilisées au sein d’un groupe de travail, Better BibTeX permet de définir un format de clé de citation uniforme. Le format recommandé est basé sur le nom de l’auteur et l’année de publication, par exemple : authEtal2.fold.lower.replace(find=\".\",replace=_) + len + shortyear | veryshorttitle + shortyear. Cette uniformisation garantit une gestion efficace des citations dans les documents collaboratifs.\n\n4.3.2.4 Génération du fichier .bib\nUne fois Better BibTeX configuré, il est possible d’exporter une collection Zotero au format BibLaTeX. Pour cela, faites un clic droit sur la collection souhaitée et sélectionnez Exporter la collection. Choisissez le format Better BibLaTeX et cochez l’option [x] Keep updated. Ce fichier .bib sera mis à jour automatiquement chaque fois que de nouvelles références seront ajoutées à Zotero. Cette méthode est particulièrement utile pour synchroniser les références dans des projets partagés via des systèmes de versionnement comme GitHub.\nIl est important de noter que toute modification effectuée dans Zotero (ajout, suppression de références) sera automatiquement synchronisée avec les autres membres du groupe. Cela implique qu’une gestion prudente des références est nécessaire pour éviter toute suppression accidentelle.\n\n4.3.2.4.1 Utilisation de Zotero lors de la rédaction\nLors de la rédaction d’articles scientifiques, Zotero peut être intégré directement dans des éditeurs de texte compatibles avec LaTeX ou Markdown. L’insertion de références se fait simplement en utilisant la commande @ dans l’éditeur de texte, permettant de sélectionner rapidement la référence souhaitée à partir de la bibliothèque Zotero.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Outils de gestion de la littérature et des références</span>"
    ]
  },
  {
    "objectID": "chapitre_5.html",
    "href": "chapitre_5.html",
    "title": "5  Outils de collecte de données",
    "section": "",
    "text": "5.1 Point d’observation: les outils traditionnels de collecte de données numériques en sciences sociales\nLe champ d’étude de la science politique repose sur l’étude de trois types d’acteurs distincts ayant un impact sur la condition socio-économique et politique d’une société : les décideurs, les médias et les citoyens. La recherche sur les décideurs comprend entre autres l’analyse des politiques publiques, des partis politiques, de stratégies électorales ou encore l’analyse de discours de politiciens ou d’organisations. L’étude des médias repose largement sur le rôle des médias dans la formation des priorités et des jugements des citoyens quant aux enjeux politiques, de même que sur leur capacité d’influencer l’agenda des politiciens. En ce qui concerne les citoyens, le champ d’étude de l’opinion publique se consacre à l’analyse des comportements et des attitudes politiques des individus. De plus, de nombreuses recherches visant à comprendre le rôle des citoyens dans une société démocratique portent sur l’influence de la société civile de même que sur l’effet des mouvements sociaux.\nL’opinion publique est traditionnellement étudiée par le biais de données de sondages. L’émergence des technologies numériques a grandement transformé la collecte de données de sondages, qui sont désormais conceptualisés et administrés de manière beaucoup plus efficace. En effet, le numérique permet donc de créer un questionnaire, de cibler une population et de la contacter, d’entreposer les données des répondants pour ainsi les visualiser, le tout à un coût réduit et plus rapidement que s’il avait été conduit manuellement (Nayak & K. A., 2019). Ainsi, les sondages en ligne ont une portée internationale, permettent le suivi de la ligne du temps, offrent des options qui contraignent le répondant à répondre à certaines questions et permettent d’utiliser des arbres de logique avancés que les sondages manuels ne permettent pas. Parmi les plateformes web les plus reconnues de construction et d’Administration de sondage, Qualtrics figure en tête de liste. Cette plateforme est une des plus reconnues et utilisée à l’international, tant dans le milieu académique que dans le secteur privé. En plus d’offrir des outils de collecte de données et de sondages, Qualtrics est utilisé dans le marketing et dans la gestion de l’expérience client. Il est donc pertinent de se familiariser avec cet outil, car il offre des compétences pratiques pour la recherche, mais également pour obtenir des opportunités de carrière. Qualtrics offre plusieurs services pratiques pour la collecte de données, avec des options flexibles pour la programmation et l’administration des sondages. Par exemple, Qualtrics s’adapte à différents formats en fonction de l’appareil du répondant (Evans & Mathur, 2018). Son principal désavantage provient de son coût d’acquisition, qui est relativement dispendieux.\nAu niveau des médias, l’arrivée de données massives permet de nouvelles avenues de recherche pour les chercheurs.euses en sciences sociales en raison de l’importante quantité de données accessibles aux chercheurs.euses, ce qui permet une compréhension accrue des réalités médiatiques modernes, marquées par la fragmentation. L’outil Factiva offre un accès à l’ensemble des articles d’une panoplie de médias provenant d’une vaste sélection de pays. Le moteur de recherche est opéré par Dow Jones et offre également l’accès à des documents d’entreprises. En revanche, l’accès qu’il offre aux contenus médiatiques est particulièrement pertinent pour la communauté scientifique en communication et en sciences sociales. Il offre l’accès à plus de 15 000 sources médiatiques provenant de 120 pays. Il permet de télécharger une quantité illimitée de documents RTF, un format de fichier de texte, pouvant contenir jusqu’à 100 articles chacun. En outre, ils peuvent être sélectionnés automatiquement en cochant le bouton proposant de sélectionner les 100 articles de la page de résultat. Chaque page de résultat contient 100 articles à la fois. Enfin, Factiva permet également de filtrer les doublons. Ainsi, Factiva permet d’avoir accès facilement à des données utiles pour l’analyse textuelle d’articles médiatiques. Comme les textes deviennent accessibles rapidement et simplement aux chercheurs.euses, cet outil optimise considérablement l’analyse de contenu par thèmes ou par ton. Cependant, ce ne sont pas tous les médias qui sont accessibles sur Factiva. Dans l’optique ou un média recherché n’est pas trouvable sur Factiva, le logiciel Eureka représente une bonne alternative. Eureka se concentre principalement sur les médias francophones (autant au Québec qu’en Europe). La structure d’Eureka est similaire à celle de Factiva.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Outils de collecte de données</span>"
    ]
  },
  {
    "objectID": "chapitre_5.html#section",
    "href": "chapitre_5.html#section",
    "title": "5  Outils de collecte de données",
    "section": "5.2 ",
    "text": "5.2 \n\n\n\nimage3_1\n\n\n\n\n\nimage3_2\n\n\n\n5.2.1 PIÈGE: NE PAS SE RESTREINDRE AUX OUTILS TRADITIONNELS DE RECHERCHE.\nCes outils sont très utiles et relativement faciles à utiliser. Il ne faut toutefois pas tomber dans le piège de se limiter aux outils traditionnels de recherche. En effet, les récentes transformations technologiques élargissent considérablement le champ de possibilités offertes à la communauté scientifique, notamment en raison de la nature massive des données qui lui est accessible. Non seulement ces données sont nombreuses, mais elles sont accessibles par le biais de connaissances de base en programmation. La section suivante aborde un outil fondamental de la collecte de données en sciences sociales numériques, les extracteurs webs.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Outils de collecte de données</span>"
    ]
  },
  {
    "objectID": "chapitre_5.html#arpentage-et-choix-éditorial-le-web-scraping---collecter-automatiquement-des-données-provenant-de-sites-web",
    "href": "chapitre_5.html#arpentage-et-choix-éditorial-le-web-scraping---collecter-automatiquement-des-données-provenant-de-sites-web",
    "title": "5  Outils de collecte de données",
    "section": "5.3 Arpentage et choix éditorial: le web scraping - collecter automatiquement des données provenant de sites web",
    "text": "5.3 Arpentage et choix éditorial: le web scraping - collecter automatiquement des données provenant de sites web\nChacun des acteurs démocratiques énumérés précédemment peut également être étudié par le biais d’extracteurs qui offrent un accès à des données numériques massives. Les extracteurs de données numériques sont des infrastructures de code permettant d’extraire des données brutes d’une source numérique définie. La section suivante explique comment ces extracteurs peuvent être utiles dans un contexte de recherche en sciences sociales numériques.\nL’émergence du numérique représente une opportunité hors pair d’accès à un volume important de données, qui permettent ainsi une analyse approfondie des phénomènes politiques contemporains. Toutefois, l’accès à de telles données peut s’avérer complexe, non-fiable ou encore coûteux. Par exemple, des données parlementaires peuvent être accessibles sur les sites internet des parlements et institutions en questions. L’accès à ces données se voit toutefois complexifié par la nécessité d’avoir des identifiants ou encore de payer pour les dites données. De plus, la qualité de ces données n’est pas assurée, en plus du fait qu’elles peuvent être mal-structurées. Ainsi, l’accès à des données massives représente un défi considérable pour la communauté scientifique tentant d’entreprendre des recherches utilisant un volume important de données.\nC’est dans cette optique que les extracteurs de données numériques peuvent être utiles. Plus précisément, le web scraping permet l’extraction de données provenant de sites webs qui seront ensuite converties dans un format utile aux scientifiques de données. Dans un contexte de recherche en science politique, le développement de scrapers permet de récolter automatiquement les données de sites internets pertinents qui pourront ensuite être utilisées afin de mener à terme un projet de recherche. Les sites desquels les données seront extraites dépendent du sujet de recherche d’intérêt de la personne entreprenant la recherche. Par exemple, un code peut extraire de manière automatisée les débats des parlements, les communiqués de presse des gouvernants, les plateformes électorales des partis politiques, ce qui offre un accès inégalé aux chercheurs.euses aux données de décideurs. De telles données pourraient mener à des analyses poussées sur le contenu et le ton des débats parlementaires. Dans une autre optique, des extracteurs peuvent également offrir l’accès aux données provenant de médias socionumériques comme Twitter (maintenant X) ou Facebook . Un extracteur peut, par exemple, être en mesure de répertorier l’ensemble des Tweets de journalistes, de politiciens ou encore de citoyens de manière automatisée, offrant un accès inégalé aux chercheurs.euses à des données massives exclusives.\n\n5.3.1 PIÈGE: LA LÉGALITÉ DES EXTRACTEURS DE DONNÉES\nIl faut toutefois être vigilant quant à la nature des données extraites. Avant d’extraire quelconque information, il est absolument primordial de s’assurer que les données soient publiques, faute de quoi l’extraction serait illégale. Il est donc recommandé de prendre connaissance des termes et conditions des sites webs étudiés afin de s’assurer de la légalité de l’extraction de données. Il est également important de respecter toute norme de droit d’auteurs et de propriété intellectuelles ou physique des données. De plus, ce n’est pas parce que des données sont publiques qu’il est nécessairement légal de les extraire et de les utiliser en recherche. En effet, il ne faut pas faire ressortir dans les données extraites quelconque information privée qui pourrait permettre d’identifier des individus (comme des numéros de téléphone, des adresses courriels, des codes postaux, etc.)\n\n\n5.3.2 RACCOURCI: LES API.\nL’élaboration d’extracteurs est toutefois facilitée par l’existence d’API (Application programming interface) sur les plateformes exploitées. L’API d’un site ou d’une application, souvent fournie par le site, permet à un tierce partie d’avoir accès à du code expliquant le fonctionnement de la plateforme étudiée, ce qui en facilite l’extraction de données. Par exemple, Twitter possédait, avant les changements de directions récents, un API qui facilitait l’élaboration d’un extracteur. En contrepartie, Facebook ne possède pas d’API, ce qui rend l’accès à ses données beaucoup plus complexe. Un API fournit des données structurées dans un format lisible tel que JSON (JavaScript Object Notation). En raison de l’automatisation, les API réduisent les chances d’erreurs dans le processus de scraping, ils ont tendance à maintenir une interface plus stable et conviviale. C’est un grand changement comparé aux fichiers HTML, où ces derniers ont des mises en page qui changent fréquemment de structure.\nUn extracteur peut également offrir l’accès à des données médiatiques, en codant un accès à des fils RSS ou encore aux HTML des médias extraits. Les fils RSS sont des formats de données qu’il est possible de recevoir automatiquement lors de mise à jour sur un site particulier. Par exemple, La Presse change ses Unes plusieurs fois dans une même journée. En extractant l’accès aux fils RSS, il est possible de recevoir lesdites mises à jour automatiquement. Ce processus accélère grandement la collecte de données. Bien que les API aient souvent une limite de taux, restreignant le nombre de requêtes possible, cela aide à éviter la surcharge sur les serveurs et garantit en même temps une utilisation équitable des ressources.\nFinalement, les API simplifient le travail de chacun et chacune par les mises à jour et maintenances. Pour être plus précis, les API, étant maintenus par les fournisseurs de services, sont modifiés au fur et à mesure que le site évolue. Par exemple, si la structure de X est modifiée, son API sera également modifié. Cela évite à ceux demandant l’accès d’ajuster leurs scripts de scraping pour prendre en compte les changements sur le site.\nEn somme, l’utilisation d’extracteurs webs facilite grandement l’acquisition de données massives. Plutôt que d’avoir à payer pour des données dont la qualité n’est pas assurée, l’utilisation d’extracteurs permet un accès plus facile et précis à des données provenant de sites web. L’élaboration d’un extracteur est toutefois une tâche complexe qui requiert un certain nombre de connaissances en lien avec les langages de programmation. Le chapitre 2 du présent ouvrage offre un survol du langage fonctionnel R, qui est utilisé par de nombreux développeurs lors de l’écriture d’extracteurs. R est également reconnu pour ces fonctionnalités statistiques qui sont, elles aussi, abordées ultérieurement dans ce livre. L’utilisation d’extracteurs webs permettent aux chercheurs.euses de faire plusieurs coups d’une seule pierre. Non seulement le développement d’extracteurs permet de se familiariser avec le langage R, qui est un atout essentiel dans la recherche en sciences sociales numériques, mais ce même développement permet un accès inégalé à des données massives qui pourront ensuite être analysées. Le développement d’extracteurs est donc relativement simple dépendamment du site que l’on vise à extraire. Ainsi, des connaissances en R sont essentielles au développement d’extracteurs, et la complexité du code évoluera dépendamment du site qui sera extrait. La section suivante présente les outils nécessaires à l’entreprise d’extraction de données web sur R.\n\n\n5.3.3 Critères de sélection\nLe web scraping est un outil accessible, particulièrement comme il s’agit d’une méthode libre de coûts monétaires. En effet, à moins de circonstances exceptionnelles, le web scraping est gratuit. Le coût serait plutôt dans l’acquisition de connaissances préalables en code puis dans l’apprentissage de la méthode. Malgré cette nuance, l’absence de coûts monétaires liés à cet outil favorise son accessibilité à l’ensemble de la communauté scientifique.\nAdditionnellement, le web scraping jouit d’une grande communauté d’utilisateurs.ices rendant accessible leurs connaissances, ce qui favorise la diffusion des savoirs liés à l’utilisation de cet outil. De nombreux forums d’aide peuvent alors être consultés gratuitement par les chercheurs.euses voulant se familiariser avec le web scraping. De nombreux forums sont présents sur le site Stack Overflow, et certains chapitres d’ouvrages collectifs vulgarisant l’utilisation de l’outil sont également dispinible gratuitement en ligne (voir par exemple le chapitre Web scraping du livre R for Data Science d’Hadley Wickham, 2022).\nLe web scraping est un outil de recherche très en vogue dans la communauté des sciences sociales. La possibilité d’obtenir une quantité importante de données de manière efficace et gratuite représente une opportunité depuis largement exploitée par les chercheurs.euses en sciences sociales, en témoigne l’émergence de cours dédiés au web scraping dans de nombreuses écoles méthodologiques de renom (telles qu’ICPSR ou l’école d’été méthodologique du European Consortium for Political Research).\nLe web scraping avec le logiciel R permet de récolter des données qui pourront ensuite être traitées et exploiter avec R, ce qui favorise donc la compatibilité de l’outil. De plus, les données extraites peuvent être exportées dans de nombreux formats tels que des fichiers .csv, .RDS, .xlsx, et plus encore.\nTel q’explicité précédemment, la présence d’une grande communauté d’utilisateurs.ices de l’outil favorise la transparence et la réplicabilité des différents résultats produits lors de l’utilisation du web scraping.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Outils de collecte de données</span>"
    ]
  },
  {
    "objectID": "chapitre_5.html#manuel-dinstruction-extraire-des-données-avec-r",
    "href": "chapitre_5.html#manuel-dinstruction-extraire-des-données-avec-r",
    "title": "5  Outils de collecte de données",
    "section": "5.4 Manuel d’instruction: extraire des données avec R",
    "text": "5.4 Manuel d’instruction: extraire des données avec R\n\n5.4.1 L’importance de comprendre la structure du code HTML\nAfin d’être à l’aise avec les extracteurs web, il peut être un atout de se familiariser avec la structure de base du langage HTML, dont l’acronyme signifie “Hypertext Markup Language”. Il s’agit d’un langage de code qui permet la description du contenu de la page web. La structure du code HTML est hiérarchique, ce qui signifie que le code est divisé en différentes sections qui occupent différents rôles. Ces sections sont délimitées par des “tags”, qui définissent le début ou la fin d’une section du site. Ce sont ces différentes sections qui seront accessibles pour l’extraction, et le code HTML permet de comprendre ce qui se situe dans ces sections. La Figure [] représente un exemple de base de code HTML.\n\n\n\nimage3_3\n\n\nDans l’exemple ci-haut, le tag &lt;h1 représente le titre du HTML. Le signe &lt;p permet de débuter le paragraphe de texte suivant le titre, et cette section devra être terminée par le sigle p&gt;. Les sections &lt;p&gt; délimitent les paragraphes écrits dans chacunes des sections. Les sigles &lt;h2&gt; produisent une sous-section et un sous titre, qui pourra être complémenté d’un paragraphe écrit. La Figure 2 démontre le texte produit par le code HTML.\n\n\n\nimage3_4\n\n\nLa structure de base du langage HTML est somme toute simple et intuitive et tous les sites web sur internet sont fondés sur du code HTML. N’importe qui étant intéressé à extraire des données de sites webs et tirer profit de la simplicité et l’accessibilité des données qui peuvent en émerger devraient donc se familiariser avec ce langage. De nombreuses sources en ligne sont disponibles afin d’apprendre sur le fonctionnement du code HTML. Nous vous encourageons donc fortement à explorer plus en profondeur les structures du code HTML afin d’obtenir une compréhension accrue du fonctionnement des sites webs que vous allez extraire. Comme le code HTML de chaque site est accessible grâce à l’URL, les données présentes sur des sites webs sont plus que jamais accessible à la communauté scientifique.\n\n\n5.4.2 Le package rvest: son fonctionnement et ses possibilités\nCet ouvrage recommande l’utilisation du paquetage “Rvest” afin de récolter des données sur des pages web, qu’elles aient ou non un API. Rvest est construit autour des paquetages “xml2” et “httr” afin de faciliter la manipulation du HTML et XML. Rvest est principalement conçu pour scraper une seule page web alors que pour scraper de multiples pages, d’autres paquetages sont recommandés, notamment “polite”. Cet ouvrage ne rentre pas dans les détails et ne se concentrera que sur Rvest.\n\n5.4.2.1 Fonctions de base du paquetage rvest utilisant pour exemple le site de LEGISinfo\nLa première étape est l’installation et le chargement des paquetages “tidyverse” et “rvest” sur sa console Rstudio. Il est important de les charger séparément car RVEST ne fait pas partie des paquetages de base du TIDYVERSE. Nous installerons ce dernier car il amène des fonctions pratiques au scraping\ninstall.packages(\"rvest\")\n\ninstall.packages(\"tidyverse\")\n\nlibrary(rvest)\n\nlibrary(tidyverse)\nPour débuter l’extraction des données, il suffit de copier l’URL de la page web à scraper et la coller dans l’appel de la fonction read_html(). Il est important de stocker l’URL dans l’objet “html_LEGISinfo.\nhtml_LEGISinfo &lt;- read_html(\"https://www.parl.ca/legisinfo/en/bills\")\n\nhtml_LEGISinfo\nLors de l’exécution des lignes de code ci-hautes, la console retournera les éléments suivants:\n{html_document}\n&lt;html lang=\"en\" xml:lang=\"en\" xmlns=\"http://www.w3.org/1999/xhtml\"&gt;\n[1] &lt;head&gt;\\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html;         charset=UTF-8\"&gt;\\n&lt;meta  ...\n[2] &lt;body class=\"body-wrapper ce-parl vh-100\"&gt;\\r\\n    &lt;header class=\"d-print-none\"&gt;&lt;!-- ...\nUne fois que les éléments que l’on souhaite extraire sont déterminés, il faut les trouver dans le document HTML. Pour ce faire, il faut se référer au style CSS (cascading style sheets), langage définissant la forme visuelle d’un document HTML. Les éléments HTML sont identifiés avec des “sélecteurs CSS”, ayant pour but de les regrouper pour faciliter leur extraction. Pour les bases du scraping, il n’est pas primordial de comprendre les détails des sélecteurs CSS. Seule la compréhension de la structure d’un document HTML est nécessaire afin d’en faire l’extraction d’éléments. L’important est d’être en mesure d’identifier les sélecteurs CSS liés aux éléments souhaités, sans avoir à comprendre le sélecteur en question.\nD’abord, html_elements doit être utilisé en premier pour trouver toutes les observations souhaitées, car cette fonction retourne une liste de tous les noeuds qui matchent avec l’appel de fonction. Le nombre d’observations est indiqué par xml_nodeset(). Comme html_element retourne seulement le premier élément qui match, il faut l’utiliser en deuxième, après html_elements. Cette seconde fonction à pour but de trouver les éléments qui deviendront les variables à extraire. Pour l’exemple de LEGISinfo, nous commencerons par extraire tous les éléments &lt;a&gt;. Comme html_elements retourne une liste, nous voulons commencer avec cette fonction.\nhtml_LEGISinfo |&gt; html_elements(\"a\")\nQui retourne les éléments suivants:\n{xml_nodeset (180)}\n [1] &lt;a href=\"#StartOfContent\" class=\"ce-parl-skipnav sr-only sr-only-focusable\"&gt;Skip to m ...\n [2] &lt;a href=\"//www.parl.ca\" class=\"ce-parl-btn float-left text-nowrap\"&gt;Parliament of Cana ...\n [3] &lt;a href=\"https://visit.parl.ca/index-e.html\" rel=\"external\"&gt;\\n\\t\\t                    ...\nhtml_LEGISinfo |&gt; html_elements(\"a\")\nQui retourne les éléments suivants:\n{xml_nodeset (180)}\n [1] &lt;a href=\"#StartOfContent\" class=\"ce-parl-skipnav sr-only sr-only-focusable\"&gt;Skip to m ...\n [2] &lt;a href=\"//www.parl.ca\" class=\"ce-parl-btn float-left text-nowrap\"&gt;Parliament of Cana ...\n [3] &lt;a href=\"https://visit.parl.ca/index-e.html\" rel=\"external\"&gt;\\n\\t\\t                    ...\nhtml_LEGISinfo |&gt; html_elements(\"a\")\n{html_node}\n&lt;a href=\"#StartOfContent\" class=\"ce-parl-skipnav sr-only sr-only-focusable\"&gt;\nSuite à l’inspection des éléments , ceux qui nous intéressent sont ceux de classe “bill-tile-container”. Il suffit d’ajouter un point “.” avant la classe souhaitée lors de l’appel de la fonction afin de rechercher les éléments en fonction de leur classe. Les classes HTML servent à catégoriser les éléments HTML selon un style prédéterminé. Pour l’exemple de LEGISinfo, nous obtenons une liste d’éléments de classe bill-tile-container que nous allons stocker dans l’objet BillTile_LEGISinfo. Tous les éléments de cette classe auront donc tous une structure ou des comportements similaires entre eux.\nBillTile_LEGISinfo &lt;- html_LEGISinfo |&gt; html_elements(\".bill-tile-container\")\nL’exécution du bloc de code ci-haut produit le résultat suivant dans la console\n{xml_nodeset (60)}\n [1] &lt;a class=\"bill-tile-container senate\" href=\"/legisinfo/en/bill/44-1/s-1\"&gt;\\r\\n\\r\\n     ...\n [2] &lt;a class=\"bill-tile-container senate\" href=\"/legisinfo/en/bill/44-1/s-2\"&gt;\\r\\n\\r\\n     ...\n [3] &lt;a class=\"bill-tile-container senate\" href=\"/legisinfo/en/bill/44-1/s-3\"&gt;\\r\\n\\r\\n     ...\nÀ partir de la liste d’éléments de classe bill-tile-container, nous appelons la fonction html_element, qui lorsque appliqué à une liste permet d’extraire la première correspondance de tous les éléments de cette liste au lieu de seulement retourner le premier nœud correspondant du document HTML. Nous cherchons à extraire ici les éléments de classe parliament-session par le biais de la ligne de code suivante:\nBillTile_LEGISinfo |&gt; html_element(\".parliament-session\") \nCe qui produit le résultat suivant dans la console:\n{xml_nodeset (60)}\n [1] &lt;div class=\"parliament-session\"&gt;\\n&lt;span class=\"parl-session-number\"&gt;44th&lt;/span&gt; Parlia ...\n [2] &lt;div class=\"parliament-session\"&gt;\\n&lt;span class=\"parl-session-number\"&gt;44th&lt;/span&gt; Parlia ...\n [3] &lt;div class=\"parliament-session\"&gt;\\n&lt;span class=\"parl-session-number\"&gt;44th&lt;/span&gt; Parlia ...\nBien que moins utile pour la mise en situation actuelle, il est également possible d’extraire les éléments en fonction de leur “id attribute”. Pour ce faire, il faut mettre un hashtag (#) avant l’élément à extraire lors de l’appel de la fonction. Le id attribute retourne toujours un seul élément car ils sont uniques à chaque document HTML. Voici la ligne de code et le résultat produit par une telle opération\nhtml_LEGISinfo |&gt; html_elements(\"#StartOfContent\")\n{xml_nodeset (1)}\n[1] &lt;a id=\"StartOfContent\" tabindex=\"-1\"&gt;&lt;/a&gt;\nNous avons créé précédemment l’objet BillTile_LEGISinfo pour ensuite y extraire les éléments de classe parliament-session. Nous appelons cette étape l’imbrication des sélections. Lorsque la fonction html_element est appliquée à un vecteur de liste html_elements, la console retourne le premier nœud correspondant de chaque élément de la liste. Il est important d’utiliser html_element à cette étape car il retourne un NA même lorsqu’il n’y a pas d’éléments correspondants, alors que html_elements ne retournera pas la valeur manquante. Dans l’exemple de LEGISinfo, c’est exactement ce que l’on a voulu faire pour obtenir les éléments de classe parliament-session. Nous sommes maintenant arrivés à l’étape d’extraire les données souhaitées. C’est assez simple, il ne suffit que d’appliquer la fonction html_text2 sur l’appel de html_element sur l’objet à moissonner, dans ce cas ci BillTile_LEGISinfo. Il est important de prendre en compte que nous connaissons ici les éléments à extraire, car le script du document a été scruté préalablement grâce à la fonction “inspect” de Google Chrome ainsi que les diverses fonctions du package rvest. Afin d’extraire les autres informations souhaitées, nous allons également créer deux autres objets qui seront à leur tour moissonnés. Voici les différentes opérations et leurs résultats dans la console:\nCode\nBillTile_LEGISinfo |&gt; html_element(\"h4\") |&gt; html_text2()\nConsole\n[1] \"S-1\"   \"S-2\"   \"S-3\"   \"S-4\"   \"S-5\"...\nCode\nBillTile_LEGISinfo |&gt; html_element(\".parliament-session\") |&gt; html_text2().\nConsole\n[1] \"44th Parliament, 1st session\" \"44th Parliament, 1st session\"...\nCode\nBillTile_LEGISinfo |&gt; html_element(\"h5\") |&gt; html_text2()\nConsole\n[1] \"An Act relating to railways\"                                                                                                                                                                                                                                                                                  \n [2] \"An Act to amend the Parliament of Canada Act and to make consequential and related amendments to other Acts\"                                                                                                                                                                                                  \n [3] \"An Act to amend the Judges Act\"   \n...\nCode\nBillBS_LEGISinfo &lt;- html_LEGISinfo |&gt; html_elements(\".bottom-section\")\nBillBS_LEGISinfo |&gt; html_element(\"dd\") |&gt; html_text2()\nConsole\n[1] \"Introduced as pro forma bill\"                                              \"Senate bill awaiting first reading in the House of Commons\"               \n [3] \"Bill not proceeded with\"                                                   \"Royal assent received\"                                                    \n [5] \"Royal assent received\"                                                     \"At second reading in the House of Commons\"     \n...\nCode\nBill_stage &lt;- html_LEGISinfo |&gt; html_elements(\".progress-bar-description\")\nBill_stage |&gt; html_element(\"dd\") |&gt; html_text2()\nConsole\n[1] \"First reading in the Senate\"            \"Third reading in the Senate\"            \"First reading in the Senate\"            \"Royal assent\"                           \"Royal assent\"                          \n [6] \"First reading in the House of Commons\"  \"First reading in the House of Commons\"  \"Royal assent\"                           \"First reading in the House of Commons\"  \"Royal assent\"        \n...\n \nMaintenant que nous avons tous les éléments souhaités, il ne reste plus qu’à utiliser la fonction tibble du tidyverse. Ce paquetage permet de facilement créer des dataframes sur R. Voici le script à produire dans l’exemple de LEGISinfo, ainsi que son résultat, un dataframe contenant le numéro de projet de loi, sa session parlementaire, son nom, son statut et son dernier stage de réalisation :\nTable_LEGISinfo &lt;- tibble(\n  Bill = Bill_LEGISinfo |&gt; html_element(\"h4\") |&gt; html_text2(),\n  Session = Bill_LEGISinfo |&gt; html_element(\".parliament-session\") |&gt; html_text2(),\n  Name = Bill_LEGISinfo |&gt; html_element(\"h5\") |&gt; html_text2(),\n  Status = BillBS_LEGISinfo |&gt; html_element(\"dd\") |&gt; html_text2(),\n  Stage = Bill_stage |&gt; html_element(\"dd\") |&gt; html_text2()\n)\nIl est important de noter que ce chapitre ne permet que de scraper des documents html uniques. Afin de scraper plusieurs page web simultanément, il faudra utiliser d’autres paquetages ainsi que des boucles, ce qui est trop complexe pour cet ouvrage d’introduction. Maintenant que vous savez extraire des informations d’un document html pour le mettre dans une base de données, voici d’autres applications pratiques de rvest à cet effet.\nIl est possible d’extraire les éléments en fonction de leur attribut grâce à html_attr(). Un attribut est une information supplémentaire associé à une balise html. Voici l’attribut href qui permet d’extraire l’URL du projet de loi en question. De cette façon, il est possible de boucler sur les href afin de moissonner divers niveaux d’une page HTML. Lorsque l’extraction se fait sur plusieurs niveaux, la pratique passe du moissonnage pour devenir de l’indexation. Cette pratique, bien que fondamentale, ne sera pas abordée en raison de sa complexité avancée. Tel que mentionné plus haut, cet ouvrage ne se concentre que sur le moissonnage.\nBillTile_LEGISinfo |&gt; html_attr(\"href\")\nLa ligne de code ci-haut produit le résultat suivant dans la console\n1] \"/legisinfo/en/bill/44-1/s-1\"   \"/legisinfo/en/bill/44-1/s-2\"   \"/legisinfo/en/bill/44-1/s-3\"   \"/legisinfo/en/bill/44-1/s-4\"   \"/legisinfo/en/bill/44-1/s-5\"   \"/legisinfo/en/bill/44-1/s-6\"  \n [7] \"/legisinfo/en/bill/44-1/s-7\"   \"/legisinfo/en/bill/44-1/s-8\"   \"/legisinfo/en/bill/44-1/s-9\"   \"/legisinfo/en/bill/44-1/s-10\"  \"/legisinfo/en/bill/44-1/s-11\"  \"/legisinfo/en/bill/44-1/s-12\" \n[13] \"/legisinfo/en/bill/44-1/s-13\"  \"/legisinfo/en/bill/44-1/s-14\"  \"/legisinfo/en/bill/44-1/s-15\"  \"/legisinfo/en/bill/44-1/s-16\"  \"/legisinfo/en/bill/44-1/s-17\"  \"/legisinfo/en/bill/44-1/s-201\"\nIl est également possible d’extraire des tables. Pour cet exemple, le site de LEGISinfo ne comporte malheureusement pas de tables, le script de https://r4ds.hadley.nz/webscraping sera donc utilisé. Celui-ci utilise la fonction minimal_html pour créer un script html, qui n’est pas nécessaire au moissonnage, mais toutefois utilisé pour cet exemple.\nhtmltest &lt;- minimal_html(\"\n  &lt;table class='mytable'&gt;\n&lt;tr&gt;&lt;th&gt;x&lt;/th&gt;   &lt;th&gt;y&lt;/th&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td&gt;1.5&lt;/td&gt; &lt;td&gt;2.7&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td&gt;4.9&lt;/td&gt; &lt;td&gt;1.3&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td&gt;7.2&lt;/td&gt; &lt;td&gt;8.1&lt;/td&gt;&lt;/tr&gt;\n&lt;/table&gt;\n  \")\n  htmltest |&gt;\n  html_element(\".mytable\") |&gt; html_table()\nL’opération précédante produit le résultat suivant dans la console\n# A tibble: 3 × 2\n      x     y\n  &lt;dbl&gt; &lt;dbl&gt;\n1   1.5   2.7\n2   4.9   1.3\n3   7.2   8.1\nEn conclusion de cette section, lorsque l’on moissonne un document HTML, il est important de ne pas se laisser intimider par la structure du document. Il ne faut pas perdre patience afin de trouver les bons sélecteurs. Ce sont des structures peu familières au début, mais on s’y habitue rapidement. Ensuite, nous recommandons d’utiliser l’outil de développeur de votre navigateur web afin de pouvoir trouver les sélecteurs souhaités. L’interface de Chrome est particulièrement conviviale, et est recommandée. Il suffit de cliquer sur “inspect” suite à un clic droit, et il est possible de chercher les éléments souhaités dans le script. Finalement, avant de scrapper le contenu d’un site web, il est important de vérifier s’il n’offre pas déjà une option pour télécharger les données ! C’est le cas de l’exemple utilisé ici (LEGISinfo), il est possible dans certains cas de télécharger les données directement sur le site web, ce qui rend parfois le besoin de moissonner désuet.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Outils de collecte de données</span>"
    ]
  },
  {
    "objectID": "chapitre_5.html#conclusion-et-discussion",
    "href": "chapitre_5.html#conclusion-et-discussion",
    "title": "5  Outils de collecte de données",
    "section": "5.5 Conclusion et discussion:",
    "text": "5.5 Conclusion et discussion:\nCe chapitre a comme objectif de dresser un portrait des différents outils de collecte de données mis à la disposition des scientifiques s’intéressant aux sciences sociales tout en voulant exploiter le potentiel de la révolution numérique. Bien que non exhaustif, ce chapitre fait un survol d’outils traditionnels de récolte de données numériques en sciences sociales. Par exemple, les outils de sondages ou de récolte de données médiatiques sont présentés dans les paragraphes ci-haut. En revanche, ce chapitre s’ancre autour du postulat qu’il ne faut pas se limiter aux outils de récolte de données traditionnels, et que la révolution numérique engendre d’importantes opportunités d’acquisition de données massives et exclusives par le biais des extracteurs de données. Ces extracteurs ont pour but de moissonner les données présentes sur un site web afin de les rendre disponibles pour l’analyse scientifique. Une section complète de ce chapitre vise à vulgariser le processus d’extraction de données provenant de site web en utilisant l’exemple du site LégisInfo, ce qui permet aux lecteurs.ices de se familiariser avec le processus de moissonnage de données.\nToutefois, un seul chapitre ne permet pas de relever l’ensemble des outils de collecte de données disponibles pour la communauté scientifique. Néanmoins, les outils présentés permettent un aperçu à la fois d’outils plus conventionnels et répandus de collecte de données numériques, mais également de dresser un portrait du potentiel d’extraction permis par la maîtrise de R.\nBibliographie:\nSchroeder, R. (2014). Big data and the brave new world of social media research. Big Data & Society, 1(2), 2053951714563194.\nChadwick, A. (2017). The hybrid media system: Politics and power. Oxford University Press.\nConnelly, R., Playford, C. J., Gayle, V., & Dibben, C. (2016). The role of administrative data in the big data revolution in social science research. Social science research, 59, 1-12.\nManovich, L. (2011). Trending: The promises and the challenges of big social data. Debates in the digital humanities, 2(1), 460-475.\nBurrows, R., & Savage, M. (2014). After the crisis? Big Data and the methodological challenges of empirical sociology. Big data & society, 1(1), 2053951714540280.\nKramer, A. D., Guillory, J. E., & Hancock, J. T. (2014). Experimental evidence of massive-scale emotional contagion through social networks. Proceedings of the National academy of Sciences of the United States of America, 111(24), 8788.\nAndrade, C. (2020). The Limitations of Online Surveys. Indian Journal of Psychological Medicine, 42(6), 575-576. https://doi.org/10.1177/0253717620957496\n\nEvans, J. R., & Mathur, A. (2018). The value of online surveys: A look back and a look ahead. Internet Research, 28(4), 854-887. https://doi.org/10.1108/IntR-03-2018-0089\n\nNayak, M., & K A, N. (2019). Strengths and Weakness of Online Surveys. 24, 31-38. https://doi.org/10.9790/0837-2405053138",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Outils de collecte de données</span>"
    ]
  },
  {
    "objectID": "chapitre_7.html",
    "href": "chapitre_7.html",
    "title": "\n7  Langages de balisage\n",
    "section": "",
    "text": "7.1 Baliser les sciences sociales : langages et pratiques\nLorsque vous lisez un article scientifique, une page Web ou un curriculum vitæ professionnel, vous vous doutez peut-être que le texte n’est pas toujours produit à l’aide d’un logiciel de traitement de texte comme Microsoft Word, Apple Pages ou LibreOffice Writer. La mise en page complexe réglée au millimètre près, la qualité des figures et des tableaux, l’utilisation de gabarits professionnels, le style des références ou encore la présence d’éléments interactifs sont difficiles et parfois impossibles à reproduire à l’aide d’un logiciel de traitement de texte régulier. L’ajout d’extraits de code, de tableaux de régression ou encore de figures de haute qualité graphique, ainsi que leur personnalisation, nécessitent une interface particulière.\nPour ces raisons et plusieurs autres, les chercheurs en sciences sociales font souvent appel aux langages de balisage, ou markup languages. Ceux-ci permettent de produire des documents et pages Web sans les limitations des logiciels de traitement de texte. Le présent livre, par exemple, est écrit à l’aide du langage de balisage Markdown avec l’aide du système de publication Quarto. Les logiciels de traitement de texte et les langages de balisage font tous partie de la catégorie des outils de rédaction. D’entrée de jeu, vous vous demandez peut-être quelle est l’utilité d’apprendre des langages de balisage alors que les logiciels de traitement de texte sont nombreux, simples d’approche et en amélioration constante. Ce chapitre n’a pas pour objectif de décourager l’utilisation de ces logiciels, qui sont utiles et même souvent essentiels pour la production rapide de documents ainsi que pour des tâches de suivi des modifications et de travail avec des équipes multidisciplinaires. Le chapitre tentera plutôt de démontrer que la maîtrise des langages de balisage constitue un avantage pour ceux qui souhaitent s’initier au monde de la recherche académique, même si quelques difficultés initiales d’apprentissage peuvent se présenter. Il s’agira de répondre, tour à tour, aux trois grandes questions suivantes : Qu’est-ce qu’un langage de balisage? Quand et pourquoi utiliser un langage de balisage? Comment utiliser un langage de balisage? L’accent sera mis sur Quarto ainsi que sur les langages Markdown et , bien que d’autres langages soient aussi abordés.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Langages de balisage</span>"
    ]
  },
  {
    "objectID": "chapitre_7.html#quest-ce-quun-langage-de-balisage",
    "href": "chapitre_7.html#quest-ce-quun-langage-de-balisage",
    "title": "\n7  Langages de balisage\n",
    "section": "\n7.2 Qu’est-ce qu’un langage de balisage?",
    "text": "7.2 Qu’est-ce qu’un langage de balisage?\nUn langage de balisage constitue un ensemble de commandes qui peuvent être entremêlées à du texte afin de produire une action informatique. Chaque langage contient son propre ensemble de commandes cohérentes et complémentaires. De manière plus formelle, ces commandes sont nommées balises (tags en anglais) et inscrites par le chercheur ou la chercheuse au travers du texte. Les balises constituent une manière de communiquer avec le logiciel utilisé dans un langage qu’il peut comprendre. Par exemple, une balise permet d’indiquer au logiciel que vous désirez qu’une section du texte soit écrite en caractères gras, en italique, à double interligne ou encore que vous souhaitez positionner une image d’une certaine manière au travers du texte. Cette interaction est rendue possible par la standardisation des langages de balisage : chaque balise correspond à une action précise, peu importe le logiciel utilisé, la langue dans laquelle le texte est rédigé, le type d’ordinateur utilisé, etc. Dans votre document source, les balises sont entremêlées au contenu de votre document. Au moment de compiler ce dernier, les balises produisent les actions informatisées qu’elles commandent et laissent comme document final le contenu mis en page tel que vous l’avez défini via les balises utilisées. La compilation est le processus par lequel un document écrit en langage de balisage est transformé en fichier textuel, en format PDF dans le cas de par exemple. La Figure 7.1 montre un exemple d’utilisation du langage de balisage Markdown dans un fichier Quarto sur la plateforme Visual Studio Code. L’écran à droite de l’image montre le fichier PDF résultant du formatage réalisé dans la partie centrale de l’écran. Les balises utilisées sont décrites plus tard dans ce chapitre.\n\n\n\n\n\n\n\nFigure 7.1: Exemple d’utilisation du langage de balisage Markdown dans un fichier Quarto sur la plateforme VS Code Source* : Auteurs du présent chapitre.\n\n\n\n\nLe premier langage de balisage, le Generalized Markup Language (GML), a été inventé en 1969 par les chercheurs Charles F. Goldfarb, Ed Mosher et Ray Lorie pour la compagnie IBM. Goldfarb et ses collègues devaient intégrer trois applications créées avec des langages différents et avec une logique différente pour les besoins d’un bureau de droit. Même après avoir créé un programme qui permettait aux trois applications d’interagir, ces langages demeuraient différents et avaient chacun leur propre fonctionnement. Le développement de GML a permis de résoudre ce problème en standardisant et en structurant le langage : les mêmes commandes étaient utilisées pour accomplir les mêmes tâches dans chaque programme (goldfarbRootsSGMLPersonal1996?). GML a été amélioré durant les décennies suivantes et a été suivi par d’autres langages de balisage, dont (1985), Bib(1988), HTML (1993), XML (1998), Markdown (2004) et R Markdown (2012) (encyclopaediabritannica23?; hameed23?; markdownguide23?; worldwidewebconsortiumw3c98?; xie23?).\nLes langages de balisage permettent d’effectuer différentes tâches. HTML, qui est sans doute le plus connu des langages de balisage, permet de formater des sites Web. XML, quant à lui, permet de structurer de larges volumes de données. permet pour sa part de formater du texte et de créer des documents en format PDF. Markdown permet également de créer des documents en format PDF, mais aussi en format HTML ou DOCX — format utilisé pour les documents Word —, contrairement à . R Markdown permet d’ajouter des extraits de code R à un fichier en langage Markdown. Enfin, depuis 2022, le système de publication scientifique et technique multilingue Quarto permet de créer des documents qui intègrent des extraits de code R, , Python, Julia ou JavaScript, créés dans différents types d’environnements, à un fichier en langage Markdown (allaire22?). , Markdown, R Markdown et Quarto permettent aussi d’intégrer les références bibliographiques du système de traitement de références Bib. Les langages de balisage communiquent ainsi souvent les uns avec les autres au sein d’un même fichier. Le chapitre 6 explique la manière de citer les références en langage Bibpar le biais de Zotero et de Better Bib.\nLes balises constituent une manière de donner manuellement des commandes au logiciel que vous utilisez. Si vous utilisez Microsoft Word, vous avez accès à une panoplie de boutons qui vous permettent de formater votre texte. Les balises exercent les mêmes fonctions de formatage pour les fichiers produits en ou en Markdown, mais doivent être ajoutées à l’écrit par l’utilisateur. Lorsque vous appuyez sur un bouton ou utilisez une commande comme Ctrl-G ou Cmd-I dans Word, en réalité, cette commande ajoute des balises au travers de votre texte, mais rend celles-ci invisibles dans l’interface que vous utilisez. Cela permet d’avoir un texte élégant et facile à lire, mais comporte aussi plusieurs inconvénients. Le principal inconvénient est de limiter le pouvoir que vous avez sur le formatage de votre texte. En effet, si les boutons à votre disposition ne vous permettent pas de réaliser une opération, celle-ci sera éternellement impossible à réaliser pour vous. A contrario, les langages de balisage permettent un contrôle presque infini sur les opérations que vous souhaitez réaliser. Incidemment, dans la mesure où vous utilisez le langage approprié pour la tâche que vous souhaitez accomplir, vous devriez être capable de donner exactement la commande nécessaire à votre logiciel. Les langages de balisage, bien qu’ils aient un coût d’apprentissage qui peut s’avérer important et que l’interface de travail soit moins intuitive qu’un document Word, vous offrent une plus grande flexibilité.\nAfin d’utiliser un langage de balisage, il est impératif que le logiciel que vous utilisez puisse prendre en compte ce langage. Un logiciel permet rarement d’utiliser n’importe quel langage. Par exemple, le logiciel Shop permet seulement d’utiliser le langage . Il est aussi impératif de bien utiliser le langage de balisage. En effet, comme pour les langages de programmation, les langages de balisage ne peuvent pas déduire ce que vous souhaitez leur faire comprendre. Si vous souhaitez mettre du texte en gras, vous devez utiliser les bonnes balises. La moindre erreur peut être coûteuse, puisqu’une erreur dans la balise que vous utilisez risque de produire une commande incompréhensible et un message d’erreur, le logiciel ne réussissant pas à associer votre balise mal inscrite à une action informatisée. Conséquemment, il est impératif de bien vérifier les balises utilisées afin d’éviter toute erreur qui empêcherait votre document d’être compilé, c’est-à-dire d’être traduit dans son format final10. Chaque caractère dans une balise est important et il y a rarement plus d’une seule manière de commander une action. Par exemple, en , il n’y a qu’une seule manière de mettre du texte en gras. Il faut précisément utiliser cette commande: \\textbf{}. Le positionnement des balises est lui aussi critique : il délimite la portion de texte à laquelle doit être appliquée l’action commandée par la balise.\nIl est important de distinguer les langages de balisage des langages de programmation, qui sont abordés plus en détail dans le chapitre 4. En effet, ceux-ci sont similaires à certains égards, mais ont des vocations différentes. Les deux s’appuient sur un langage informatisé, mais les langages et leurs objectifs diffèrent. Un langage de programmation définit des processus informatisés alors qu’un langage de balisage permet d’encoder du contenu de manière à ce que celui-ci soit lisible tant pour l’humain que pour son ordinateur.\nDans le contexte de la recherche en sciences sociales, la programmation est généralement utilisée afin de récolter, d’analyser et de présenter visuellement des données. Une fois cartes, tableaux et graphiques produits, ceux-ci peuvent être enregistrés — par exemple en format PDF ou PNG — et inclus au sein d’un document qui sera formaté en utilisant un langage de balisage. En R Markdown et en Quarto, des extraits de langage de programmation peuvent être inclus dans des sections bien délimitées de documents écrits en langage de balisage. Plus généralement, le langage de programmation contribue à l’analyse alors que le langage de balisage est essentiellement utile afin de présenter les travaux de recherche, que ce soit dans un document écrit ou sur un site Web. C’est principalement de cette manière que sont utilisés les langages de programmation et de balisage dans le cadre de la recherche en sciences sociales.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Langages de balisage</span>"
    ]
  },
  {
    "objectID": "chapitre_7.html#comment-utiliser-un-langage-de-balisage",
    "href": "chapitre_7.html#comment-utiliser-un-langage-de-balisage",
    "title": "\n7  Langages de balisage\n",
    "section": "\n7.3 Comment utiliser un langage de balisage?",
    "text": "7.3 Comment utiliser un langage de balisage?\nEn pratique, comment utilise-t-on Markdown, et Bib? D’emblée, a une syntaxe particulière qui demande un certain temps d’adaptation. Pour écrire une phrase simple comme celle-ci, la phrase peut être écrite telle quelle. Par contre, pour mettre un mot en caractères gras, il faut utiliser la balise suivante: \\textbf{mot}. Pour mettre le en rouge, la balise est \\textcolor{red}{mot}. Pour le mettre en italique et en note de bas de page11, les balises \\footnote{\\emph{mot}} peuvent être utilisées. Ainsi, des balises peuvent contenir d’autres balises. En langage , une balise commence toujours par une barre oblique inversée. Par la suite, le nom de la fonction — emph, textbf, textcolor, etc. — est appelé. Enfin, généralement, le mot à formater est placé entre accolades ({}).\nChaque document commence par un préambule. Celui-ci présente des informations telles que la taille des caractères, le type de document, le format de mise en page, la police de caractères, l’utilisation d’en-têtes et de pieds de page, ainsi que l’utilisation de packages permettant différentes fonctionnalités de personnalisation du document. Il n’est pas nécessaire ni souhaitable d’apprendre l’ensemble des fonctions et des packages qui existent. Au contraire, il est souvent mieux de commencer par un gabarit de document qui convient au type de document que vous voulez créer et ensuite de rechercher en anglais sur Stack Overflow la manière d’ajouter des éléments de formatage que vous ne connaissez pas, par exemple en recherchant highlight latex text.\nMarkdown fonctionne de manière similaire à , mais se démarque par sa plus grande flexibilité et sa syntaxe beaucoup plus légère. Par contre, il nécessite parfois l’utilisation de balises afin de réaliser certaines tâches, comme changer la couleur du texte. Tout document Markdown débute avec un court bloc de syntaxe YAML (acronyme de Yet Another Markup Language) qui définit les paramètres généraux du document. Voici un bloc YAML typique pour un document Quarto :\n---\ntitle: \"Baliser les sciences sociales\"\nsubtitle: \"Langages et pratiques\"\ndate: today\nauthor:\n  - Alexandre Fortier-Chouinard^[University of Toronto]\n  - Étienne Proulx^[McGill University]\n  - Maxime Blanchard^[McGill University]\nformat: pdf\ntoc: true\ndate-format: \"MMMM D, YYYY\"\nbibliography: livre-outils.bib\n---\nOutre le titre, le sous-titre et le nom des auteurs, on trouve aussi dans l’en-tête YAML la présence d’une table des matières (toc), la date et son format, le format du document compilé — dans ce cas-ci, PDF — ainsi que le chemin d’arborescence afin d’accéder au document Biboù sont enregistrées les références utilisées. Il est aussi possible d’y définir la taille de la police de caractères ou encore le gabarit Word servant à définir le format d’un document DOCX à produire. De manière particulièrement importante, c’est l’endroit où sont chargés les packages qui seront utilisés. En effet, la majorité des packages et fonctions sont utilisables dans Markdown, alors que l’inverse n’est pas vrai. Il est donc possible de personnaliser un document Markdown en utilisant des packages ayant été créés pour .\nLa syntaxe à utiliser au travers du texte est somme toute plutôt simple. Pour mettre un ou plusieurs mots en gras, il suffit de les entourer de deux astérisques (**mots en gras**); pour les mettre en italique, il faut les encadrer d’une seule astérisque (*en italique*). Pour définir un titre de section ou de sous-section, il suffit de mettre des # devant le titre en question. Plus vous ajoutez de #, plus le titre sera petit et plus il sera considéré à un niveau hiérarchique inférieur dans la structure du texte. La syntaxe Markdown est donc plus légère que celle de , dans le but d’en rendre la lecture plus simple pour les utilisateurs et utilisatrices.\nBien que des gabarits Markdown soient disponibles, ceux-ci sont plus rares. Ils se trouvent pour la plupart sur GitHub et sont rendus disponibles par leur créateur. Cela étant dit, leur personnalisation peut s’avérer plutôt complexe. En somme, Markdown est particulièrement pratique pour les documents ne nécessitant pas de respecter un gabarit précis et requérant simplement un document d’allure simple et professionnelle.\nPour sa part, Biba une syntaxe relativement simple. D’emblée, les références Bibpour des articles et ouvrages scientifiques sont disponibles sur Google Scholar. Toutefois, pour citer des sites Web ou des articles de médias, la référence doit être écrite à la main selon un format précis. Une bibliographie sur Bibpeut ressembler à ceci :\n@book{darwin03,\n  address = {London},\n  author = {Darwin, Charles},\n  publisher = {John Murray},\n  title = {{On the Origin of Species by Means of Natural Selection\nor the Preservation of Favoured Races in the Struggle for Life}},\n  year = {1859}\n}\n\n@article{goldfarb96,\n  title={The Roots of SGML: A Personal Recollection},\n  author={Goldfarb, Charles F},\n  journal={Technical communication},\n  volume={46},\n  number={1},\n  pages={75},\n  year={1999},\n  publisher={Society for Technical Communication}\n}\nUn fichier Bibne contient rien de plus qu’une série de publications commençant chacune par la balise @ suivie du type d’article — article, book pour un livre, incollection pour un chapitre de livre, inproceedings pour une présentation dans une conférence, unpublished pour un article non publié et online pour un site Web sont parmi les plus connus — et des informations sur la publication mises entre accolades. La première information entre accolades est le code de la référence, par exemple goldfarb96. Dans le fichier , l’auteur doit écrire \\cite{goldfarb96} pour voir dans le document PDF compilé (goldfarbRootsSGMLPersonal1996?); le lien est automatiquement cliquable et renvoie à la notice bibliographique correspondante. L’ordre des publications dans le document Biba peu d’importance, puisque réordonne par défaut la bibliographie en ordre alphabétique.\n\n7.3.1 Environnements d’édition et de compilation\nContrairement à Microsoft Word et Apple Pages, il existe plusieurs options d’environnements d’édition et de compilation spécifiques à chaque langage. Ces environnements sont des plateformes et des logiciels conçus pour faciliter l’édition, la mise en forme et la compilation de documents dans des langages de balisage tels que et Markdown. Ils permettent également de rendre plus efficace et conviviale la production de documents tout en fournissant des fonctionnalités spécifiques aux besoins de chaque langage. Il existe une grande diversité d’environnements d’édition et de compilation, et le choix est libre pour la chercheuse ou le chercheur de trouver celui qui convient le mieux à ses besoins ou aux besoins de son groupe de recherche. Les trois options discutées ici sont parmi les plus utilisées par les chercheurs en sciences sociales et peuvent être regroupées en deux catégories : les logiciels de bureau et les éditeurs en ligne.\nD’abord, il existe plusieurs logiciels de bureau qui offrent un environnement d’édition et/ou de compilation pour les langages de balisage. Ces logiciels fournissent les programmes principaux, les extensions essentielles et des outils complémentaires de compilation et de visualisation afin de permettre la production de documents écrits en langages de balisage. Le logiciel RStudio, également abordé dans le chapitre 4, permet de produire des documents avec différents langages de balisage et programmation, ainsi que de naviguer entre eux, à partir d’une même fenêtre. Il suffit d’installer certains packages contenant les fichiers nécessaires à l’utilisation des langages de balisage. Par exemple, il est possible de produire des documents en en utilisant le code suivant dans la console pour installer le package nécessaire à l’utilisation de la distribution Tiny : install.packages(\"tinytex\"). Suivant le même principe, il est possible de produire des documents en R Markdown sur RStudio en installant le package suivant : install.packages(\"rmarkdown\"). Pour Quarto, le téléchargement se fait en ligne, directement à partir du site Web de (quarto23?).\nPour l’écriture en , il est également nécessaire d’installer l’une des nombreuses distributions en ligne afin de pouvoir compiler ces documents dans un environnement local. Il existe des distributions telles que Macpour Mac, Mikpour Windows et plusieurs autres (Just, 2013). Ces distributions se distinguent par les différents packages avec lesquelles elles sont compatibles.\nUn autre environnement régulièrement utilisé pour travailler en langage de balisage est le logiciel de bureau VS Code. VS Code prend en compte un plus grand nombre de langages de programmation et est utilisé par les programmeurs de tous domaines, tandis qu’RStudio est surtout utile pour les chercheurs en sciences sociales qui travaillent surtout en R.\nLorsque vient le temps de collaborer à plusieurs sur un document écrit en Markdown ou en , les logiciels de bureau évoqués précédemment nécessitent l’utilisation de GitHub et de Git. L’utilisation de ces éditeurs peut présenter un défi supplémentaire pour les équipes de recherche non initiées. Il existe ainsi des éditeurs en ligne qui permettent de collaborer en temps réel sans passer par Git et GitHub, de manière similaire à Google Docs12. Le plus connu de ces logiciels est Overleaf, qui permet de produire des documents en langage . Puisqu’Overleaf permet d’avoir accès à ses documents à partir de n’importe quel navigateur, il n’y a pas de dépendance à un logiciel local sur un ordinateur, ce qui constitue un avantage important. La contrepartie de cet avantage est qu’en utilisant Overleaf, l’équipe de recherche est dépendante d’une connexion à Internet. En utilisant le package rmarkdown, Overleaf peut également inclure du code Markdown. Cependant, Overleaf ne permet pas de créer des documents en format DOCX ou HTML, ce qui constitue une limite de l’application. Overleaf comporte un compteur de mots intégré, ce qui n’est pas le cas des autres logiciels et environnements présentés plus haut.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Langages de balisage</span>"
    ]
  },
  {
    "objectID": "chapitre_7.html#quand-et-pourquoi-utiliser-un-langage-de-balisage",
    "href": "chapitre_7.html#quand-et-pourquoi-utiliser-un-langage-de-balisage",
    "title": "\n7  Langages de balisage\n",
    "section": "\n7.4 Quand et pourquoi utiliser un langage de balisage?",
    "text": "7.4 Quand et pourquoi utiliser un langage de balisage?\nLa plupart des langages de balisage permettent de remplir l’une des deux fonctions suivantes, qui sont particulièrement importantes dans le contexte de la recherche en sciences sociales : produire des documents écrits et formater des pages Web. Dans les deux cas, ces actions peuvent être réalisées à partir de logiciels simples, mais ces logiciels ont des limites importantes auxquelles les langages de balisage apportent des solutions13.\nPour l’écriture de documents très simples comme une liste d’épicerie ou des notes rapides pendant une conférence, les logiciels de traitement de texte sont tout à fait convenables : ils sont simples et rapides à utiliser, un formatage professionnel du document n’est pas de mise. Utiliser un langage de balisage pour des tâches de base peut en effet rendre la tâche inutilement longue et complexe. Toutefois, plus la complexité d’un document augmente, plus il devient difficile d’obtenir un résultat satisfaisant en utilisant un logiciel de traitement de texte tel que Word, Pages ou Writer. A contrario, permet de produire des documents de tous les niveaux de complexité, tel que démontré sur la Figure 7.2. Quant à Markdown, sa courbe d’apprentissage se situerait logiquement entre celles de et de Word, puisque ses balises sont simplifiées. Plus généralement, utiliser un langage de balisage comme ou Markdown14 comporte plusieurs avantages par rapport aux logiciels de traitement de texte traditionnels. Ces avantages font tous appel à un mélange de quatre concepts principaux : automatisation, personnalisation, flexibilité et qualité graphique.\n\n\n\n\n\n\n\nFigure 7.2: Utilité relative de Word et de selon la complexité et la taille du document Source* : Yannick Dufresne (2015).\n\n\n\n\n\n7.4.1 Avantages\n\n7.4.1.1 Référencement\nPremièrement, et Markdown permettent d’intégrer une bibliographie automatique et professionnelle en utilisant Bib. Cette bibliographie peut être adaptée très facilement en différents styles bibliographiques reconnus ou en un style bibliographique personnalisé à partir d’un des nombreux gabarits professionnels disponibles. Avec Bib, il n’y a pas à vérifier si le titre de l’article est toujours en italique, si le numéro de volume est toujours entre parenthèses ou si le nom de famille des deuxièmes auteurs est toujours avant ou après le prénom puisque toutes ces opérations sont effectuées de manière automatique. Bibcomprend également les différences entre les types de sources — articles scientifiques, livres, sites Internet, etc. — et ajuste leur présentation en conséquence. De plus, si une des sources que vous citez n’est pas incluse dans la bibliographie, une erreur s’affiche, vous permettant d’identifier le problème plutôt que de vous retrouver avec une référence manquante. À l’inverse, si une source est retirée du texte, elle disparait automatiquement de la bibliographie dans le document final mais demeure présente dans le fichier où se trouvent les références bibliographiques. Cela évite les aller-retour pour vérifier que chaque source de la bibliographie se trouve au moins une fois dans le texte et que chaque source dans le texte est citée en bibliographie. Grâce aux balises, en cliquant sur les références incluses dans le document, vous vous retrouverez immédiatement plus loin dans le document, à l’endroit où se trouve l’entrée bibliographique associée. Les références Bibpour articles scientifiques peuvent être copiées-collées à partir de Google Scholar. Bibrend donc extrêmement simple et efficace l’utilisation des références bibliographiques grâce à sa capacité à personnaliser et automatiser leur présentation15.\n\n7.4.1.2 Figures et tableaux\nL’intégration de figures et de tableaux dans le texte est aussi rendue très simple et professionnelle grâce à et à Markdown. La taille de la figure ou du tableau, son positionnement et son intégration par rapport au texte environnant peuvent être réglés avec précision. Cependant, l’ajout de texte avant ou après la figure ou le tableau ne produira pas des résultats inattendus tels qu’une demi-page vide avant un graphique ou un titre de tableau complètement en bas d’une page. En définissant des paramètres pour l’ensemble du texte, la chercheuse ou le chercheur peut personnaliser entièrement la présentation des figures et des tableaux. De plus, la qualité des figures et des tableaux ne diminue pas lors de leur intégration : les figures restent aussi belles qu’elles l’étaient originalement, ce qui n’est pas toujours le cas dans les logiciels de traitement de texte. Les figures et les tableaux sont aussi numérotés automatiquement, ce qui veut dire que vous n’aurez jamais à vous préoccuper de modifier les numéros si l’ordre des figures et tableaux est modifié dans le texte. Grâce aux balises, en cliquant sur le numéro associé à la figure ou au tableau dans le texte, le document se retrouve automatiquement à l’endroit où se trouve la figure ou le tableau. De plus, les figures peuvent être intégrées en format PDF, ce qui permet au lecteur de copier-coller ou de surligner de l’information se trouvant sur le graphique directement, incluant les titres des axes et les annotations.\nSurtout, l’intégration de graphiques produits par R au texte en langage de balisage est simplifiée et automatisée. En effet, même lorsque les données ou le code pour produire un graphique changent, R resauvegarde le fichier dans le même chemin d’arborescence (path) particulier que vous avez indiqué, par exemple C:/Users/Jean/Dropbox/projet1/graphs/Figure1.pdf. Le langage de balisage peut ensuite indiquer le même chemin d’arborescence, de sorte qu’il n’est pas nécessaire de recopier-coller la figure à l’intérieur du document chaque fois que des changements y sont apportés; la figure est mise à jour automatiquement.\nL’intégration de figures et de tableaux est particulièrement simple et flexible avec Quarto. Contrairement à , qui nécessite la production de tableaux et de figures dans un document en langage de programmation (comme R), Quarto permet de créer une figure grâce à du code R et d’intégrer celle-ci au texte dans un même document. Cela se fait grâce à l’intégration de blocs de code R (code chunks) dans le document. Le code est produit dans le bloc de code et la figure ou le tableau qui en résulte apparait à la fois dans le document Quarto, où des balises supplémentaires permettent d’adapter le formatage, et sur le document fini. Cependant, certains packages R permettent de créer des tableaux de régression de grande qualité en format . Les tableaux de régression en format Markdown sont pour l’instant plus difficiles à produire au-delà d’un certain niveau de complexité, en raison des limitations du langage Markdown. Il demeure possible de produire des tableaux en langage dans un fichier Markdown ou Quarto.\n\n7.4.1.3 Équations\npermet également d’ajouter des équations mathématiques poussées. En effet, il existe des balises pour chaque symbole mathématique, et celles-ci peuvent être agencées de manière à former des équations cohérentes. Ces équations peuvent être intégrées au sein même d’une phrase ou être mises de l’avant dans un paragraphe à part centré.\n\n7.4.1.4 Table des matières et mise en page\nMarkdown et permettent aussi la gestion automatisée de la table des matières, et les références aux pages appropriées à partir de la table des matières se mettent à jour en continu. La table des matières prend en compte l’architecture du texte choisie manuellement par le chercheur, qui est définie par des balises définissant différents niveaux hiérarchiques de sections, sous-sections ou chapitres. Des manières automatiques de référencer les figures et les tableaux dans des sections distinctes de la table des matières sont également offertes, encore une fois personnalisables au goût du chercheur.\nBien que la mise en page de documents produits via Markdown et puisse être définie entièrement manuellement par les personnes plus expérimentées, les novices apprécieront les nombreux gabarits (templates) qui permettent de gérer automatiquement la mise en page clés en main. Les gabarits permettent de rendre l’apparence d’un document plus esthétique et uniforme et peuvent être utilisés tels quels ou servir de point de départ pour un chercheur ou une chercheuse souhaitant y apporter certaines modifications sans toutefois partir d’une feuille blanche. La majorité des personnes qui utilisent ces langages, même les plus expérimentées, utilisent ces gabarits comme base lorsqu’elles rédigent un document. Ceux-ci constituent une mine d’or puisqu’ils rendent accessible le code Markdown ou ayant servi à la conception du gabarit, permettant à la chercheuse ou au chercheur de comprendre comment est obtenu le résultat que lui offre le gabarit. Incidemment, il est possible d’identifier les sections de code produisant certains éléments de mise en page — positionnement des numéros de page, positionnement du nom des auteurs en début de document, etc. — et les modifier ou s’en inspirer afin de modifier d’autres gabarits. L’utilisation de ces gabarits peut s’avérer complexe au départ, mais il s’agit d’une complexité qui s’avère ultimement extrêmement productive puisqu’elle vous permettra de devenir autonome et d’ajuster les gabarits à votre convenance afin de produire exactement le résultat désiré en termes de mise en page. En comparaison, les logiciels de traitement de texte rendent souvent très ardue la mise en page uniforme d’un document, puisque cet élément ne peut pas être automatisé. La liste des gabarits disponibles est extrêmement large, et ceux-ci ont une variété de fonctions. En effet, une variété de gabarits professionnels et de haute qualité graphique sont offerts gratuitement en ligne pour des articles, des livres, des rapports, des curriculum vitæs Figure 7.3 ou encore des factures professionnelles Figure 7.4.\n\n\n\n\n\n\n\nFigure 7.3: Exemple de gabarit de curriculum vitae Source* : LianTze (2023).\n\n\n\n\n\n\n\n\n\n\n\nFigure 7.4: Exemple de gabarit de feuille de temps Source* : Roux (2013).\n\n\n\n\nLes Figure 7.3 et Figure 7.4 ne sont que quelques exemples des milliers de gabarits de documents disponible en ligne. Plusieurs d’entre eux peuvent être téléchargés à partir du site Web d’(Modèles, 2023). Vous pouvez y naviguer et voir quel gabarit convient le mieux à vos besoins. Certaines manières plutôt spécifiques de formater le texte sont présentement disponibles avec ou Markdown bien que non disponibles en Word, ce qui constitue une autre preuve de leur grande flexibilité et capacité de personnalisation. Bien qu’il soit rare que nous ayons absolument besoin de personnaliser le texte ainsi, ces possibilités peuvent s’avérer utiles lorsque vous rédigez un texte qui doit se conformer en tout point à un gabarit spécifique. En effet, certaines revues scientifiques, maisons d’édition et universités, dans le cadre de la rédaction d’articles, de mémoires et de thèses par exemple, imposent ce type de gabarit inflexible et parfois plutôt capricieux.\n\n7.4.1.5 Compatibilité entre types de documents\nUn autre avantage non négligeable de Markdown — qui le distingue à cet égard de — est la flexibilité des formats de documents qui peuvent être produits. En effet, Pandoc Markdown, une extension du langage Markdown de base, permet d’intégrer dans un seul document plusieurs langages de balisage différents tels que Markdown, et HTML. Quarto utilise Pandoc Markdown et est également habilité à travailler avec des extraits de code R ou Python. Ceci permet donc à l’utilisateur ou à l’utilisatrice de bénéficier des fonctionnalités de différents langages dans un seul document, rendant ainsi possible une variété de personnalisations qui ne seraient pas possibles autrement. Qui plus est, puisque Markdown permet de créer des fichiers Word réguliers, PDF professionnels et HTML à partir d’un même document, vous pouvez choisir à votre convenance et à tout moment de quelle manière sera compilé le document rédigé. Cette possibilité de créer des documents Word est particulièrement pratique dans le cadre de collaboration avec des chercheuses et chercheurs n’utilisant pas les langages de balisage ainsi que lors de l’envoi de manuscrits à des revues scientifiques, puisque certaines d’entre elles exigent de recevoir ceux-ci sous forme de document Word.\n\n7.4.1.6 Popularité\nLa popularité de certains langages de balisage dans le monde de la recherche confère un avantage considérable à celles et ceux qui savent les utiliser. La maîtrise de ces langages offre aux chercheurs et chercheuses une polyvalence lorsqu’ils doivent collaborer avec diverses équipes de recherche utilisant différentes méthodes de travail. Par exemple, depuis sa création a été adopté largement par le milieu de la publication de travaux scientifiques (Gaudeul, 2007). À titre indicatif, le logiciel Overleaf était utilisé en 2022 par 11 millions d’utilisateurs et utilisatrices dans 189 pays autour du globe. Plus de 2000 compagnies et 6800 universités utilisent Overleaf pour écrire en (Wow! Ten Million Users!, s. d.). La popularité des langages de balisages en fait donc un outil difficile à contourner pour une personne qui voudrait poursuivre une carrière en recherche académique. L’avantage ci-bas sur la gestion des embûches illustre également comment la popularité permet une meilleure gestion de celles-ci.\n\n7.4.1.7 Gestion des embuches\nBien que l’apprentissage de et de Markdown puisse être parsemé de nombreuses embuches, ces deux langages bénéficient d’une communauté d’utilisateurs et d’utilisatrices en ligne sur laquelle il est possible de s’appuyer afin de résoudre tout problème rencontré. Ces individus — particulièrement les plus expérimentés — sont nombreux à partager leur expérience à leurs collègues rencontrant des problèmes afin de contribuer à régler ceux-ci. Cette communauté est présente sur une multitude de sites Web, bien que le point de rencontre principal soit le forum (stackoverflowStackOverflow2023?), qui est également utilisé pour régler des problèmes de programmation et est abordé plus en détail dans le chapitre 4. Une simple recherche sur Google d’un problème rencontré avec ou Markdown vous offrira des liens vers des échanges pertinents ayant eu lieu sur Stack Overflow ou encore vers de la documentation technique. Vous pourrez donc filtrer les résultats et observer les nombreuses solutions envisageables à votre problème afin de définir laquelle est la plus appropriée dans votre situation. Il est important de noter, toutefois, que cette communauté est nettement plus développée pour les utilisateurs de que de Markdown, puisque ce dernier langage est moins répandu que le premier.\nÉgalement, avec l’émergence de l’intelligence artificielle (IA), de nombreux modèles d’IA génératifs commencent à émerger comme des ressources d’aides utiles pour les chercheuses et les chercheurs. Au moment de la rédaction du présent chapitre, le chatbot ChatGPT, développé par OpenAI et basé sur le grand modèle de langage (large language model, LLM) GPT-3.5, est une ressource d’aide en émergence en ce qui a trait aux langages de balisage. Le corpus de données sur lequel il a été formé inclut une grande variété de langages et de styles d’écriture, incluant et Markdown. Ainsi, il est possible de poser des questions en langage courant à ce chatbot lorsque des problèmes de balisage sont rencontrés. Celui-ci fournira en réponse le texte avec les balises adéquates pour régler le problème. Cela s’applique même pour des problèmes pour lesquels la réponse n’est pas directement indiquée sur Stack Overflow, lorsque la logique des langages est comprise par ces modèles basés sur l’IA. ChatGPT est toutefois plus outillé en qu’en Markdown ou en Quarto en raison de la plus grande abondance de ressources en disponibles en ligne, bien que ses capacités soient en constante amélioration. Il arrive cependant régulièrement que les réponses des modèles de langage comme ChatGPT soit erronées — tout comme certaines réponses sur Stack Overflow peuvent ne pas être adaptées à régler un problème similaire vécu sur un autre ordinateur, avec des paramètres différents. Il demeure donc important de vérifier les réponses des modèles basés sur l’IA afin de ne pas avoir de mauvaises surprises lors de la compilation du code. Ainsi, il est utile de s’appuyer autant sur la communauté d’utilisatrices et d’utilisateurs de langages de balisage qui échange des ressources en ligne que sur les modèles de langage basés sur l’IA.\n\n7.4.1.8 Philosophie du code source ouvert et du logiciel libre\nL’utilisation des langages de balisage s’inscrit bien dans la philosophie du logiciel libre. Le langage est distribué sous la license project public license (LPPL), alors que Quarto 1.4 est distribué sous la license du Massachusetts Institute of Technology (MIT). Moyennant le respect de leurs licenses respectives, ces licenses permettent ainsi aux utilisateurs de et de Quarto d’utiliser ces langages comme ils le souhaitent, de redistribuer des copies, de modifier le fonctionnement de ces langages et d’en redistribuer des versions améliorées. Bien que et Quarto ne soient pas des logiciels, leur license utilisation est cohérente avec la philosophie du logiciel libre et permet à ces langages d’être utilisés dans de nombreux logiciels.\nD’autre part, et Quarto sont deux langages à code source ouvert (open source). Ainsi, leur distribution est entièrement gratuite, il n’y a rien à payer. Leur code source est disponible et les changements à ce code doivent être indiqués. Les licences LPPL et MIT ne discriminent pas certains groupes ou personnes, et elles ne restreignent personne dans l’utilisation pour un domaine d’activité. Ces deux licences ne sont pas spécifiques pour un produit, ce qui signifie que ces deux langages peuvent être utilisés dans plusieurs logiciels et programmes. Elles sont également technologiquement neutres, rendant ainsi et Quarto accessibles aux utilisateurs de tous les systèmes d’exploitation.\n\n7.4.2 Inconvénients\nIl existe toutefois des désavantages inhérents à l’utilisation des langages de balisage. L’un des principaux désavantages de Markdown et de est le fait qu’ils ne comportent aucun système de suivi des modifications lors de travaux collaboratifs. Pour réviser un travail fait en langage de balisage, des commentaires peuvent être ajoutés sur le fichier sortant — nécessairement PDF pour un fichier sortant produit avec . Des commentaires peuvent aussi être faits directement dans le document ou Markdown, à l’aide de balises spécifiques. Ces commentaires n’apparaissent cependant pas dans le fichier sortant. Le suivi des modifications en et Markdown nécessite donc souvent l’utilisation de Git et de GitHub, qui sont abordés plus en détail dans le chapitre 8. Même avec une plateforme de gestion des versions comme GitHub, les longs paragraphes ayant fait l’objet de plusieurs modifications peuvent être longs à comparer par rapport aux logiciels de traitement de texte, qui permettent de visualiser les propositions d’ajouts et de retraits de caractères de manière plus intuitive. Le suivi des modifications en logiciel de traitement de texte permet également de distinguer les auteurs de différents commentaires par leurs noms, alors que les ajouts et retraits itératifs en GitHub peuvent rendre difficile l’identification de l’auteur d’une modification. Pour ces raisons, et aussi pour faciliter la mise en page par les éditeurs, certaines revues scientifiques refusent les fichiers PDF et demandent que les soumissions soient faites en format DOCX — ce qui pose problème pour les utilisateurs de mais pas ceux de Markdown.\nLes langages de balisage comportent également un autre désavantage important dans certains cas : l’absence d’un correcteur de fautes de français complet, en particulier pour corriger les fautes autres que celles d’orthographe en français. Parmi les principaux endroits permettant l’édition en langages de balisage, Visual Studio Code (VS Code) et Overleaf comprennent tous deux une extension LanguageTool (Lpour pour VS Code), qui permet la révision orthographique et syntaxique dans plusieurs langues. VS Code possède également une extension Antidote pour les personnes qui paient déjà pour ce logiciel. D’autres extensions linguistiques existent également pour VS Code, de même que pour les logiciels de traitement de texte comme Word. Cependant, RStudio ne possède qu’un correcteur orthographique de base, disponible en plusieurs langues. Ce correcteur ne repère pas les erreurs de syntaxe, de grammaire ou de forme, entre autres. Ces éléments sont pourtant essentiels pour la rédaction de textes académiques16, d’autant plus que les utilisateurs de ont tendance à faire davantage de fautes d’ortographe et de grammaire lors de la rédaction que les utilisateurs de Word (Knauff & Nejasmic, 2014). Nous décourageons ainsi l’utilisation de RStudio pour l’édition de fichiers et Quarto, et nous encourageons fortement les utilisateurs d’Overleaf et de VS Code d’utiliser des extensions permettant la correction grammaticale telles que LanguageTool/L.\nEnfin, les langages de balisage, contrairement aux logiciels de traitement de texte, nécessitent d’être compilés, ce qui implique que deux fichiers coexistent : le fichier où le langage de balisage est utilisé — format .tex pour , .md pour Markdown ou encore .qmd pour Quarto — ainsi que le fichier où le texte final balisé apparait — généralement .pdf, .docx ou .html. La compilation peut prendre un temps variable selon la complexité du document, mais dure typiquement une quinzaine de secondes. Le fait de devoir travailler avec deux fichiers en parallèle et de ne pas voir immédiatement l’effet des balises sur le document final constitue ainsi un autre désavantage des langages de balisage.\ncomporte aussi quelques difficultés techniques particulières qui peuvent être réglées ou diminuées en travaillent en Markdown. Premièrement, est difficile à apprendre. Certaines tâches qui peuvent sembler simples comme l’ajout d’un tableau peuvent nécessiter de nombreuses lignes de code. De plus, à la moindre erreur de frappe dans l’utilisation d’une balise, le code risque de ne pas fonctionner et de ne pas produire le document PDF souhaité. C’est ce qu’on appelle une erreur de compilation. Markdown est un langage plus simple à apprendre, avec des balises plus courtes et intuitives. Il occasionne donc moins d’erreurs de compilation.\nDeuxièmement, est peu compatible avec les logiciels de traitement de texte comme Word. Pour transférer un fichier créé à partir d’un logiciel de traitement de texte vers , les balises doivent être ajoutées manuellement une par une. À l’inverse, pour transférer un document vers un fichier de traitement de texte, le convertisseur Pandoc peut être utilisé, mais celui-ci ne repère pas toutes les balises et il est souvent nécessaire de faire des aller-retour entre le fichier original et le fichier converti en format DOCX pour s’assurer du succès de la conversion. Parfois, les balises doivent être retirées une par une et le formatage doit être refait en utilisant les boutons fournis sur le logiciel de traitement de texte. Il est aussi possible de copier le texte directement à partir du fichier PDF produit par vers un logiciel de traitement de texte, mais les fins de ligne sont interprétées par Word, Pages ou Writer comme des retours plutôt que des espaces, et les accents sont souvent mal copiés et doivent être réécrits manuellement. Encore une fois, Markdown évite ce problème en permettant d’écrire un fichier DOCX à partir du langage de balisage. Le formatage du fichier DOCX demeure un peu compliqué cependant et doit être fait à partir du modèle d’un autre document DOCX formaté tel que souhaité. De plus, les fichiers DOCX ne peuvent pas être transformés en format Markdown. Quarto permet d’écrire un texte en format Markdown et de produire un fichier DOCX à partir d’un gabarit Word. De plus, pour les fichiers Word à transformer en format Markdown, les balises plus simples en Markdown qu’en rendent la tâche plus simple.\nSomme toute, Word n’est pas à antagoniser et demeure très utile pour des tâches simples. Cependant, dans le monde académique, la production de fichiers de qualité faisant appel à des graphiques, tableaux et blocs de code personnalisés de qualité et automatisés est simplifiée en utilisant des langages de balisage. Il n’est ainsi pas anodin que ces langages soient adoptés largement dans le monde académique. Pour ces raisons, il est avantageux pour une personne poursuivant une maitrise en science sociale ou autre de passer outre la difficulté initiale d’apprentissage des langages de balisage. L’apprentissage de ces langages permettra de s’aligner sur les pratiques répandues dans le milieu académique et d’améliorer davantage la qualité de la production d’écrits scientifiques.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Langages de balisage</span>"
    ]
  },
  {
    "objectID": "chapitre_7.html#conclusion-pièges-et-astuces",
    "href": "chapitre_7.html#conclusion-pièges-et-astuces",
    "title": "\n7  Langages de balisage\n",
    "section": "\n7.5 Conclusion: Pièges et astuces",
    "text": "7.5 Conclusion: Pièges et astuces\nMaintenant que vous avez une meilleure idée de ce que sont les langages de balisage et de leur utilité, la prochaine étape consiste à expérimenter par vous-même. Le chapitre se termine donc par un résumé des étapes à suivre pour devenir expert dans les langages de balisage.\nLa première étape consiste à commencer à expérimenter dès que possible, sans se laisser freiner par l’incompréhension. Il n’est pas nécessaire de tout comprendre des langages de balisage pour produire un document de qualité. Avec cet état d’esprit, vous franchirez les difficultés initiales de la l’apprentissage des langages de balisage plus rapidement.\nEnsuite, ne pas hésiter à utiliser les ressources disponibles pour gagner du temps. Les “cheat sheets” disponibles en ligne, l’aide de LLMs (Large Language Models) qui connaissent les langages de balisage (par exemple, ChatGPT), et le recours à des sites comme Stack Overflow peuvent être très utiles. Si on ne fait pas appel à des ressources externes, il peut devenir facile de devenir fâché contre soi-même ou contre l’infrastructure informatique. Il est parfaitement normal de demander de l’aide externe, même pour un expert.\nLa troisième étape est de ne surtout pas sous-estimer l’aide de ses pairs. N’hésitez pas à poser des questions et à demander de l’aide à des personnes plus expérimentées pour résoudre des problèmes que vous ne parvenez pas à résoudre avec les ressources externes.\nAvant d’aborder la quatrième et dernière étape, il est important de mentionner quelques pièges à éviter lors de la transition de débutant à expert. Tout d’abord, faites attention aux exigences des revues lorsque vous soumettez des articles scientifiques. Certaines demandent des articles au format Word tandis que d’autres préfèrent les langages de balisage. Savoir comment convertir correctement les documents est donc un atout.\nDe plus, ne vous limitez pas à un seul langage de balisage et soyez polyvalent, car travailler en collaboration peut nécessiter de s’adapter aux pratiques des partenaires. Veillez également à éviter les erreurs lors de la compilation des documents écrits en langage de balisage en portant une attention particulière aux balises et en ne les laissant pas s’accumuler. Une bonne façon de veillez à ce que les erreurs ne s’accumulent pas est de compiler fréquemment vos documents en cours de production.\nUn des pièges qui peut sembler évident mais qui mérite d’être répété est de faire attention à la qualité de la langue écrite. Soyez ainsi à l’affut de la présence de correcteur automatique ou non dans vos environnements d’édition. Vérifiez aussi si ce correcteur automatique est dans la bonne langue (français canadien, anglais canadien, etc.).\nEnfin, évitez les conflits Git lors de la collaboration sur GitHub en coordonnant efficacement les travaux d’équipe et en utilisant Git de manière optimale pour tirer parti des langages de balisage. Il est donc important de se renseigner quant aux bonnes pratiques à suivre afin de collaborer efficacement avec Git. À cet égard, beaucoup de ressources sont à votre disposition en ligne.\nPour conclure, la dernière étape pour devenir expert en langages de balisage est d’être créatif. Explorez les différentes balises et utilisez-les de manière inventive. Les langages de balisage vous permettront d’effectuer des tâches que vous n’auriez pas pu réaliser facilement en utilisant un logiciel de traitement de texte classique. Ils vous permettront de produire des documents professionnels dans différents formats personnalisés, produits avec des processus automatisés, avec une grande qualité graphique.\n\n\n\n\n    \n\n      \n\nRésumé des critères de sélection - Langages de balisage\n              \nCritères\n                LaTeX\n                R Markdown\n                Quarto\n                Word\n              \n\n\n\na Bien que LaTeX offre une bonne transparence et réplicabilité, son utilisation via Overleaf peut être limitée sans version payante, notamment pour l'intégration avec GitHub et Dropbox. Ces limitations ne s'appliquent pas à des environnements comme RStudio ou VS Code.\n\nb Quarto est relativement récent et semble prendre de plus en plus la place de R Markdown parmis la communauté d'utilisateurs de R. Le nombre d'utilisateurs de Quarto est donc appelé à croitre dans les prochaines années.\n\n\n\nAccessibilité (Gratuit ou peu dispendieux)\n                  Oui        \n                  Oui   \n                  Oui    \n                  Non        \n                \n\nExistence d'une communauté d'utilisateurs \n                  Très grande\n                  Grande\n                  Moyenneb\n\n                  Très Grande\n                \n\nPopularité dans le champ                  \n                  Oui        \n                  Oui   \n                  Oui    \n                  Oui        \n                \n\nCompatibilité avec d'autres outils        \n                  Moyenne    \n                  Forte \n                  Forte  \n                  Faible     \n                \n\nTransparence et réplicabilité             \n                  Oui        a\n\n                  Oui   \n                  Oui    \n                  Non        \n                \n\nAdaptabilité et flexibilité               \n                  Très forte \n                  Forte \n                  Forte  \n                  Forte",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Langages de balisage</span>"
    ]
  },
  {
    "objectID": "chapitre_7.html#références",
    "href": "chapitre_7.html#références",
    "title": "\n7  Langages de balisage\n",
    "section": "\n7.6 Références",
    "text": "7.6 Références\n\n\n\n\nGaudeul, A. (2007). Do Open Source Developers Respond to Competition? The LATEX Case Study. Review of Network Economics, 6(2). https://doi.org/10.2202/1446-9022.1119\n\n\nJust, J. (2013, mars 25). Les Distributions - Groupe Francophone Des Utilisateurs de TeX, LaTeX et Logiciels Compagnons. https://www.gutenberg-asso.fr/Les-distributions\n\n\nKnauff, M., & Nejasmic, J. (2014). An Efficiency Comparison of Document Preparation Systems Used in Academic Research and Development. PLoS ONE, 9(12), e115069. https://doi.org/10.1371/journal.pone.0115069\n\n\nLianTze, L. (2023). ModèleCV. https://www.overleaf.com/latex/templates/a-customised-curve-cv/mvmbhkwsnmwv\n\n\nModèles (2023). https://fr.overleaf.com/latex/templates\n\n\nRoux, E. (2013). Yet Another Invoice Template. Overleaf. https://www.overleaf.com/latex/templates/yet-another-invoice-template/ykjwmwqqjhgh\n\n\nWow! Ten Million Users! (s. d.). Consulté 9 mars 2024, à l'adresse https://www.overleaf.com/blog/wow-ten-million-users",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Langages de balisage</span>"
    ]
  },
  {
    "objectID": "chapitre_7.html#footnotes",
    "href": "chapitre_7.html#footnotes",
    "title": "\n7  Langages de balisage\n",
    "section": "",
    "text": "University of Toronto↩︎\nUniversité Laval↩︎\nMcGill University↩︎\nUniversity of Toronto↩︎\nUniversité Laval↩︎\nMcGill University↩︎\nUniversity of Toronto↩︎\nUniversité Laval↩︎\nMcGill University↩︎\nLes logiciels permettent plus ou moins efficacement d’identifier les balises problématiques. Certains ne produisent qu’un message d’erreur sans donner d’indication sur la source du problème, alors que d’autres ciblent très spécifiquement la ligne de syntaxe où se situe la balise problématique.↩︎\nmot↩︎\nVS Code possède également une extension, Live Share, qui permet de travailler en temps réel sur un même document.↩︎\nLes langages de balisage permettent également de créer des pages Web. Bien que les pages Web puissent être créées à partir de sites Web comme WordPress, le langage HTML permet de produire des résultats plus personnalisables, plus automatisables et avec une plus grande qualité graphique. Cette question n’est pas abordée en détail dans ce chapitre.↩︎\nLes avantages et désavantages de Markdown cités dans cette section s’appliquent également à Quarto et à R Markdown, puisque ces derniers font appel au langage Markdown.↩︎\nL’utilisation d’un logiciel de traitement de texte, en particulier lorsque combiné avec une extension Zotero, peut également produire un résultat automatisé et personnalisé à un certain degré. Cependant, au moment où ce chapitre est écrit, le retrait d’une citation du texte principal en Word avec Zotero n’enlève pas immédiatement cette citation de la bibliographie, et l’ajout de liens vers la bibliographie doit se faire source par source, ce qui prend un temps important et peut occasionner des erreurs humaines.↩︎\nPour les utilisateurs de RStudio, il est souvent nécessaire de modifier le texte dans un logiciel de traitement de texte externe pour faire une révision linguistique complète, puis d’intégrer les corrections en collant le texte corrigé dans le document original en Markdown ou . Une application de bureau Grammarly peut également être intégrée sur RStudio. Cette application repère les erreurs de syntaxe, mais ne corrige que l’anglais, et certains soucis de repérage des mots aux bons endroits dans le texte en rendent présentement l’utilisation difficile.↩︎",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Langages de balisage</span>"
    ]
  },
  {
    "objectID": "chapitre_8.html",
    "href": "chapitre_8.html",
    "title": "\n8  Outils d’intelligence artificielle\n",
    "section": "",
    "text": "8.1 Définition et différents type d’IA\nQu’est-ce que l’intelligence artificielle (IA)? Est-ce quelque chose d’homogène, ou s’agit-il plutôt « des intelligences artificielles »? Dans un premier temps, il est important de préciser que l’intelligence artificielle est un champ d’études (Devedzic, 2022). Par conséquent, il s’agit d’un ensemble d’objets, relativement vaste et en constante expansion, qui s’intéressent, à sa façon, à l’intelligence artificielle. Pour préciser ce propos, prenons l’exemple de la science politique. Malgré la formulation au singulier, la science politique est un grand ensemble de différents sous-champs d’études, qui ont chacun leur propre objet d’intérêt. La philosophie politique, les relations internationales, la politique comparée et l’étude de l’opinion publique, par exemple, sont tous des sous-champs qui s’intéressent, à leur façon, au phénomène politique. Dans le même sens, et compte tenu de cette pluralité de perspectives, il est important de noter qu’il n’y a pas de consensus dans la définition de l’IA (König et al., 2022; Wang, 2019). De plus, la rapidité du développement de ce champ rend le traçage de frontières définitionnelles plutôt difficile : comment définir, d’une manière précise et consensuelle, quelque chose qui évolue constamment (Bertolini, 2020, pp. 15; Devedzic, 2022)?\nDeux définitions de l’IA peuvent tout de même être retenues. La première vient de John McCarthy (2007, pp. 2) : « Il s’agit de la science et de l’ingénierie qui consistent à créer des machines intelligentes1, en particulier des programmes informatiques intelligents. Elle est liée à la tâche similaire consistant à utiliser des ordinateurs pour comprendre l’intelligence humaine, mais l’IA ne doit pas se limiter aux méthodes qui sont biologiquement observables. » [Traduction DeepL] La seconde définition provient de la compagnie IBM (2023a) : « Dans sa forme la plus simple, l’intelligence artificielle est un domaine qui combine l’informatique et des ensembles de données robustes pour permettre la résolution de problèmes. Elle englobe également les sous-domaines de l’apprentissage automatique et de l’apprentissage profond, qui sont souvent mentionnés en conjonction avec l’intelligence artificielle. Ces disciplines sont composées d’algorithmes d’IA qui cherchent à créer des systèmes experts qui font des prédictions ou des classifications basées sur des données d’entrée. » [Traduction DeepL] Ces extraits permettent de comprendre que l’IA consiste à reproduire artificiellement certaines capacités cognitives humaines, afin de rendre les machines « intelligentes » en leur donnant la capacité de résoudre des problèmes par elles-mêmes.\nCes définitions restent toutefois à préciser, notamment dans le champ d’application de l’IA : qu’en est-il concrètement ? Comment est-ce utilisé ? Comment ça fonctionne ? Si l’IA se distingue enn plusieurs types, en faire la liste et identifier leurs différentes branches et applications possibles serait fastidieux et s’écarterait de l’objectif de ce chapitre introductif. Cependant, pour ceux désirant en savoir plus sur le sujet, les articles de McCarthy (2007) et de Hanchen et al. (2023), ainsi que le Cambridge Handbook of Artificial Intelligence (König et al., 2022) sont très riches et illustratifs sur ce qu’est l’IA ainsi que sur ses champs d’applications.\nAvant toute chose, il est important de distinguer l’IA général (strong) du précis (narrow). Le premier, et le moins populaire en nombre de recherches et d’applications, cherche à développer une machine qui aurait les mêmes capacités cognitives que l’humain, non seulement en termes de résolution de problème, d’apprentissage et de planification, mais aussi qui serait dotée d’une conscience de soi (IBM, 2023a; König et al., 2022). Le deuxième est plus restrictif, se limitant à la réalisation d’un ou de plusieurs objectifs spécifiques. De ces deux visées, il y a trois principaux champs de recherche qui se penchent sur les méthodes de fonctionnement de l’IA : l’apprentissage machine (machine learning), les réseaux neuronaux artificiel (artificial neural networks) ainsi que l’apprentissage profond (deep learning).\nL’apprentissage machine : « […] consiste à programmer des ordinateurs pour optimiser un critère de performance à l’aide de données d’exemple ou d’expériences passées. Nous avons un modèle défini jusqu’à certains paramètres, et l’apprentissage est l’exécution d’un programme informatique pour optimiser les paramètres du modèle à l’aide des données d’entraînement ou de l’expérience passée. » [Traduction DeepL] (Alpaydin et Bach 2014, 3). Le but est d’entraîner le modèle afin qu’il puisse reconnaître des tendances, et qu’il puisse décrire et/ou faire des prédictions à partir de ces tendances (Alpaydin & Bach, 2014, pp. 3). Il est le champ le plus populaire dans la recherche faite sur l’IA, notamment parce qu’il constitue une base importante pour les autres recherches dans le domaine (Devedzic, 2022).\nEnsuite, un sous-champ de l’apprentissage machine, l’apprentissage profond : « […] fait référence à un réseau neuronal composé de plus de trois couches […]. L’apprentissage en profondeur automatise une grande partie de l’extraction des caractéristiques, éliminant ainsi une partie de l’intervention humaine manuelle nécessaire et permettant l’utilisation d’ensembles de données plus importants. Il peut ingérer des données non structurées dans leur forme brute et déterminer automatiquement la hiérarchie des caractéristiques qui distinguent les différentes catégories de données les unes des autres, ne nécessitant pas d’intervention humaine. » [Traduction DeepL] (IBM, 2023a). Ainsi, l’apprentissage profond permet une certaine forme d’automatisation des tâches demandées à l’IA, en lui fournissant les capacités nécessaires d’apprendre par lui-même pour corriger et améliorer son fonctionnement. Pour ce faire, on doit développer des structures neuronales artificielles, qui s’inspirent des neurones du cerveau humain.\nC’est d’ailleurs la tâche de ceux qui s’intéressent aux réseaux neuronaux artificiels : « Les réseaux neuronaux artificiels (RNA) sont constitués d’une couche de nœuds, contenant une couche d’entrée, une ou plusieurs couches cachées et une couche de sortie. Chaque nœud, ou neurone artificiel, se connecte à un autre et possède un poids et un seuil associés. Si la sortie d’un nœud individuel est supérieure à la valeur seuil spécifiée, ce nœud est activé et envoie des données à la couche suivante du réseau. Dans le cas contraire, aucune donnée n’est transmise à la couche suivante du réseau. » [Traduction DeepL] (IBM 2023b). Ainsi, le but est de reproduire les structures cognitives humaines, afin de permettre à l’IA d’accomplir des tâches plus complexes. L’une des principales utilités de ce sous-champ est qu’il permet d’augmenter la rapidité du classement de données ; la reconnaissance vocale ou d’image, par exemple, ne prend que quelques minutes grâce à cela, contrairement à plusieurs heures lorsque fait par des humains (IBM, 2023b).",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Outils d'intelligence artificielle</span>"
    ]
  },
  {
    "objectID": "chapitre_8.html#lévolution-constante-de-lia",
    "href": "chapitre_8.html#lévolution-constante-de-lia",
    "title": "\n8  Outils d’intelligence artificielle\n",
    "section": "\n8.2 L’évolution constante de l’IA",
    "text": "8.2 L’évolution constante de l’IA\nPlusieurs chercheurs, dont le professeur Yoshua Bengio de l’Université de Montréal, ont lancé plusieurs avertissements sur le développement de l’IA, notamment à cause de la rapidité de son évolution. Dans un article paru dans The Economist, M. Bengio (2023) nous dit qu’il prévoyait le développement d’une IA avec des capacités similaires à celles de l’humain d’ici quelques décennies, peut-être un siècle. Depuis l’arrivée de ChatGPT-4, celui-ci a revu sa prédiction pour la situer entre quelques années et quelques décennies (Bengio, 2023). Dans les dix dernières années seulement, les systèmes de reconnaissance d’images et de langages en sont venus à dépasser les capacités humaines (Roser, 2022). La figure 1 présente cette évolution.\n\n\nComme on le remarque, cette évolution ne suit pas une trajectoire linéaire. Depuis 2015, la plupart de ces technologies ont évolué de manière quasi-exponentielle. Cette progression fulgurante nous permet de faire quelque constat pour appréhender l’évolution future. Ce qui est intéressant de la recherche dans ce domaine, c’est que le développement des capacités de l’IA permet, en retour, de la développer encore plus rapidement. L’IA peut rendre l’IA exponentiellement plus puissante (Harari, 2023). Elle est capable de se faire évoluer à une vitesse plus grande, grâce à ses capacités de traitement de données et d’auto-améliorassions, que si elle était uniquement dépendante de l’humain.\nEn tant que chercheur en sciences sociales, pourquoi devrait-on être préoccupé par le développement de l’IA? Tout d’abord, il est intéressant de commencer à réfléchir ainsi qu’à analyser les différents impacts que l’IA a sur nos sociétés. Les avancés dans le domaine en plus de l’accessibilité à ces technologies, tel que Large Language Model (LLM), en font de nouveaux objets d’étude actuel, et surtout sans grandes réponses. Yuval Noah Harrari (2023), historien et philosophe, explique dans un article que la capacité de l’IA à manipuler ainsi qu’à générer du langage en font des outils puissants qui ont le potentiel d’avoir de profond impact sur nos civilisations. Par conséquent, l’étude des effets de l’IA sur nos sociétés devient un nouveau sujet de recherche dont tous les champs des sciences sociales et sciences humaines ont intérêt à se pencher. Présentement, il est anticipé que cette technologie puisse être utilisée pour « générer et partager de fausses informations, érodant la confiance sociale et la démocratie; pour surveiller, manipuler et maîtriser les citoyens, nuisant aux libertés individuelles et collectives; ou pour créer de puissantes armes physiques ou digitales qui menaceraient la vie humaine. » [Traduction libre] (Bremmer & Suleyman, 2023, pp. 32). Compte tenu des conséquences potentielles que ces technologies peuvent avoir sur le monde social, tous les domaines scientifiques ont un fort incitatif à décloisonner leur savoir et leurs analyses, en plus de maximiser l’interdisciplinarité et la recherche collaborative. Une compréhension plus complète de ces changements ainsi qu’une communication de ce savoir ne pourra que générer des bénéfices pour le monde académique, social et politique.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Outils d'intelligence artificielle</span>"
    ]
  },
  {
    "objectID": "chapitre_8.html#les-différents-outils-de-lia",
    "href": "chapitre_8.html#les-différents-outils-de-lia",
    "title": "\n8  Outils d’intelligence artificielle\n",
    "section": "\n8.3 Les différents outils de l’IA",
    "text": "8.3 Les différents outils de l’IA\nCette section vise à présenter différents outils de l’intelligence artificielle aux lecteurs. Ce qui est important de comprendre ici, et pour faire suite à la section précédente, c’est que les outils présenté ici risque d’avoir changé entre le moment d’écrire ce chapitre et le moment où les lecteurs liront le chapitre. Certaines fonctionnalités pourraient toujours être les mêmes, certaines pourraient avoir été améliorées et d’autres pourraient être complètement nouvelles. Par conséquent, l’objectif ici est de présenter certaines utilités et fonctionnalités de l’IA, et surtout d’inciter les lectuers à développer leurs propres capacités réflexives quant à leur utilisation de l’IA. Cette technologie offre de nouvelles opportunités, mais elle apportea aussi son lot d’enjeux et de questions dont il vaut mieux s’y intéresser afin de développer une utilisation saine et intégre de ces outils.\nTrois catégories d’outils seront présentées: les « Large Language Models » (LLM), les assistants de traduction ainsi que les assistants de revue de littérautre.\n\n8.3.1 1. Les LLMs\n(openai19?) définissent les grands modèles linguistiques (Large language models ou LLMs en anglais) comme des modèles d’apprentissage automatique de grande échelle, formés pour prédire le mot suivant dans un texte en se basant sur les mots précédents. Ils sont entraînés sur de vastes quantités de données textuelles, telles que des articles de journaux, des livres, des pages web, des courriels, des messages de médias sociaux, etc. Cette méthode d’entraînement simple permet aux modèles de démontrer naturellement des compétences dans de nombreuses tâches et domaines divers, sans nécessiter de formation spécifique à la tâche. Il est important de noter que les GML ne sont que des algorithmes de prédiction textuelle et ne possèdent pas la faculté de réfléchir ou de comprendre.\nL’intégration des grands modèles de langage (LLMs) via l’API d’OpenAI dans la recherche en sciences sociales numériques ouvre des horizons prometteurs pour l’analyse qualitative et quantitative des données textuelles. L’utilisation de ces modèles en R permet aux chercheurs d’exploiter des capacités avancées de traitement du langage naturel pour une variété d’applications allant de la simple extraction de données à des analyses complexes de contenu et de sentiment. Elle permet aussi de générer des données pour l’analyse de biais algorithmiques en comparant l’information générée par les modèles avec des données de référence générées par des humains. Les LLMs peuvent être utilisés pour l’analyse de sentiments, l’extraction d’entités et de relations, la génération de résumés de texte, la simulation de dialogue, la traduction et la localisation, et le développement d’outils personnalisés pour des besoins spécifiques de recherche.\nVoici quelques exmples d’utilisation des LLMs en sciences sociales:\nPremièrement, les LLMs peuvent être utilisés pour l’analyse de sentiments, permettant aux chercheurs de détecter des nuances dans les opinions exprimées dans des corpus de données volumineux, tels que des commentaires sur les réseaux sociaux, des critiques de produits, ou des discours politiques. Cette analyse peut révéler des tendances de sentiment général ou être segmentée pour examiner des variations entre différents groupes démographiques ou chronologiques.\nDeuxièmement, les LLMs offrent des capacités d’extraction d’entités et de relation, ce qui est crucial pour structurer des données non structurées comme des questions de sondage ouvertes. Les chercheurs peuvent extraire des personnes, des lieux, des institutions, et même des concepts ou des événements, liant ces entités à des thèmes spécifiques ou à des contextes historiques et socio-politiques, enrichissant ainsi les bases de données pour des études plus poussées.\nTroisièmement, la génération automatique de résumés de textes par ces modèles permet de condenser de grandes quantités d’informations en résumés concis, facilitant l’analyse préliminaire de vastes archives de textes, comme des articles de presse, des mémoires juridiques, ou des écrits académiques. Cela aide les chercheurs à identifier rapidement les documents pertinents sans nécessiter la lecture intégrale des textes.\nQuatrièmement, les modèles linguistiques peuvent être utilisés pour générer des simulations de dialogue ou des réponses à des questions hypothétiques, permettant aux chercheurs en sciences sociales de modéliser des interactions entre différents acteurs sociaux ou d’explorer des scénarios hypothétiques en études de comportement sans la mise en place de coûteuses études de terrain.\nCinquièmement, l’intégration de LLMs aide à surmonter les barrières linguistiques dans la recherche globale, en offrant des capacités de traduction et de localisation qui permettent une analyse plus inclusive des textes dans différentes langues, essentielle pour les études comparatives internationales.\nsixièmement, les modèles de “speech-to-text” peuvent être utilisés pour transcrire automatiquement des enregistrements audio en texte, comme des entrevues, facilitant l’analyse de discours oraux ou de conversations enregistrées, et permettant aux chercheurs de travailler avec des données multimodales pour des études interdisciplinaires.\nSeptièmement, les modèles de vision algorithmiques permettent l’analyse de contenu visuel, en extrayant des informations à partir d’images ou de vidéos pour compléter des analyses textuelles, ou pour étudier des phénomènes visuels comme la représentation des genres dans les médias ou les tendances de la mode.\nEnfin, les chercheurs peuvent utiliser les LLMs pour développer des outils personnalisés qui s’adaptent à des besoins spécifiques de recherche, comme l’analyse de discours ou la détection de changements dans le langage au fil du temps, fournissant ainsi des insights précieux sur l’évolution des discours et pratiques culturelles.\nEn somme, l’utilisation des LLMs via l’API d’OpenAI en R représente une avancée significative pour les chercheurs en sciences sociales, leur offrant des outils puissants pour naviguer et analyser l’immense paysage des données textuelles avec une précision et une efficacité accrues.\nBien qu’il soit possible de communiquer avec l’API d’OpenAI directement, le package openai en R offre une interface conviviale pour interagir avec les modèles de langage, permettant aux chercheurs de tirer parti de ces outils avancés sans nécessiter une expertise en informatique ou en apprentissage automatique. Le package fournit des fonctions pour générer du texte, analyser des sentiments, extraire des entités, et bien plus encore, facilitant l’intégration des LLMs dans les workflows de recherche existants.\nVoici un exemple simple d’utilisation de l’API d’OpenAI :\nlibrary(openai)\n\nsystem &lt;- \"You are a helpful assistant\" # Donne un role au modèle. Doit être clair et concis\n\nprompt &lt;- \"Quelle est la capitale du Québec?\" # Le prompt\n\nchat_prompt &lt;- openai::create_chat_completion(\n        model = \"gpt-3.5-turbo-0125\",\n        messages = list(\n            list(\"role\" = \"system\",\n                 \"content\" = system\n            ),\n            list(\n                \"role\" = \"user\",\n                \"content\" = prompt)\n            )\n    )\n\noutput &lt;- chat_prompt$choices$message.content\n\nprint(output)\n\n8.3.2 2. Les Assistants de Traduction\nL’IA a aussi permis la création d’outils de nouveaux outils de traduction automatique (machine translation). Pris au sens large, le concept de traduction automatique englobe n’importe quelle tâche de traduction qui est réalisée par un algorithme, une machine, des ordinateurs, etc. sans aucune aide d’un humain (Glover, 2024; Tabsharani, 2023). Il existe différents types ou approches de traduction automatique:\n\nBasée sur des règles (rules-based): utilise des règles linguistiques et des dictionnaires pour transformer les mots et phrases d’une langue source en langue cible. Nécessite des experts pour créer et maintenir ces règles, ce qui rend le processus laborieux mais efficace pour les langues à grammaire bien définie (Glover, 2024; Tabsharani, 2023).\nStatistique (statistical): analyse de grands volumes de textes bilingues pour identifier des motifs et probabilités. Utilise des modèles statistiques plutôt que des règles linguistiques pour déterminer les traductions les plus probables à partir des données d’apprentissage. Fonctionne bien avec des données volumineuses mais peut parfois produire des traductions imprécises faute de contextualisation (Glover, 2024; Tabsharani, 2023).\nBasée sur des exemples (example-based) : repose sur une base de données de phrases ou de segments précédemment traduits pour générer des traductions, en recherchant des exemples similaires dans la base de données et en récupérant les traductions les plus pertinentes, ce qui est utile pour des domaines spécifiques ou des textes très répétitifs, mais peut être limité face à des usages linguistiques nouveaux ou créatifs (Glover, 2024; Tabsharani, 2023).\nNeuronale (neural) : utilise des modèles d’apprentissage profond pour apprendre les schémas de traduction, traitant des phrases entières et leur contexte, ce qui améliore la qualité et la fluidité des traductions, bien qu’elle ne remplace pas entièrement les traducteurs humains (Glover, 2024; Tabsharani, 2023).\nHybride : les quatres approches peuvent également être combinées (Glover, 2024; Tabsharani, 2023).\n\nC’est au sein de l’approche neuronale que les avancées en intelligence artificielle ont permis de développer de nouveaux outils de traduction automatique. En effet, les réseaux neuronaux transformeurs (transformer neural networks) ont révolutionné le domaine de la traduction automatique en traitant des phrases entières dans leur contexte global plutôt que des mots isolés, ce qui a considérablement amélioré la qualité et la fluidité des traductions (Glover, 2024; Tabsharani, 2023). En tant que forme d’IA générative, ces outils exploitent le traitement du langage naturel (natural language processing), l’apprentissage profond (deep learning) et l’auto-attention (self-attention) pour réaliser ces avancées. Ces outils de traduction automatique sont devenus de plus en plus populaires et accessibles, permettant à des personnes de traduire des textes entiers, des sites web, des documents, etc. en quelques secondes, sans avoir besoin de connaître la langue cible.\nIl est essentiel pour les chercheurs en sciences sociales numériques de connaître et d’utiliser les outils de traduction automatique car ils facilitent la recherche, la communication et la collaboration à l’échelle internationale, particulièrement dans le contexte d’un monde académique dominé par l’anglais. Toutefois, il est crucial de comprendre que ces outils ne remplacent pas complètement les traducteurs humains. Voici, d’une perspective générique, les avantages et inconvénients de ces outils par rapport à la traduction humaine (Glover, 2024):\n\n\n\n\n\n\nAvantages\nInconvénients\n\n\n\nAmélioration de la productivité : traductions rapides et de grande échelle\nDonnées biaisées : reproduction de stéréotypes et erreurs de genre\n\n\nApprentissage autonome : amélioration continue grâce à l’apprentissage non supervisé\nManque de subtilité : difficultés avec les expressions idiomatiques et le jargon spécifique\n\n\nRéduction des coûts : minimise le besoin d’intervention humaine\nDifficultés avec le contexte : erreurs de cohérence et de pertinence contextuelle\n\n\nAmélioration de l’accessibilité : accessible en plusieurs langues et adapté aux besoins spéciaux\n\n\n\n\nIl existe des milliers d’outils de traduction automatique qui utilisent l’IA d’une façon ou d’une autre. Dans les prochaines pages, nous présenterons rapidement quelques-uns de ces outils gratuits parmi les plus populaires actuellement en mettant en lumière leurs forces et leurs faiblesses. Il est important de noter que ces outils sont en constante évolution et que leur qualité peut varier en fonction de la langue, du contexte et du type de texte à traduire.\n\n\n\n\n\n\nBanques de données terminologiques\n\n\n\nBien que ces outils n’utilisent pas l’intelligence artificielle, il nous semble essentiel de mentionner des ressources telles que TERMIUM Plus et Interactive Terminology for Europe (IATE), qui sont des bases de données terminologiques de référence. Ces bases de données, gérées par des langagiers professionels, facilitent la compréhension des termes spécifiques à une discipline en fournissant des définitions claires et des équivalents dans plusieurs langues et assurent également une cohérence terminologique dans les traductions. D’ailleurs, TERMIUM Plus a été fréquemment sollicité pour la traduction de plusieurs termes présents dans ce chapitre.\n\n\n\n8.3.2.1 Google Traduction\nTrès connu, l’une des forces de Google Traduction est son support d’une large variété de langues, tant des langues globalement utilisées et des langues plus régionales et moins utilisées. Google Traduction est basé sur de la traduction automatique neuronale, prenant donc le sens et le contexte d’une phrase en considération. De plus, il supporte aussi la traduction de documents complets.\n\n8.3.2.2 DeepL\nDeepL se démarque par une qualité supérieure de traduction mais dans un nombre de langues plus restreint que d’autres outils. Il est aussi basé sur de la traduction automatique neuronale, ce qui lui permet de prendre en compte le contexte et la complexité d’une structure de phrase.\n\n8.3.2.3 Mate Translate\nMate Translate est une extension de navigateur qui permet de traduire des pages web entières, des phrases ou des mots en un seul clic. Il supporte un grand nombre de langues et offre des fonctionnalités supplémentaires telles que la prononciation des mots et des phrases traduits. Son avantage réside vraiment dans sa facilité d’utilisation et sa rapidité.\n\n8.3.2.4 ChatGPT\nÉvidemment, CHatGPT est un outil de traduction automatique basé sur des modèles de langage génératif. Il est très populaire pour sa capacité à générer du texte de manière fluide et naturelle, ce qui en fait un outil de traduction très efficace pour les textes longs et complexes. De plus, il est possible de raffiner la traduction en quelques itérations en suggérant des modifications au texte traduit.\n\n8.3.2.5 Autres outils\nComme mentionné plus haut, il existe une panoplie d’outils de traduction automatique qui utilisent l’IA et qui sont accessibles gratuitement. Cependant, considérant que ces outils sont en constante évolution, l’objectif de ce livre n’est pas d’en faire une description exhaustive mais plutôt de donner un aperçu des possibilités offertes par ces outils. Parmi les autres outils populaires, on peut citer Microsoft Translator, Pairaphrase, Amazon Translate, Smartling, Unbabel, Linguee, Yandex.Translate, HIX Translate, etc.\n\n8.3.3 3. Les Assistants de Revue de littérature\nDans cette section, deux principaux outils seront présentés: research rabbit et ellicit. Il s’agit de deux ressources gratuites en ligne qui facilite le début d’une revue des écrits, notamment lorsque l’on ne connaît pas beaucoup la littérature sur un sujet et/ou sur un champs d’étude. Ces deux outils sont d’ailleurs compatibles aves Zotero, qui fut présenté au chapitre 4 de ce livre.\nDébutons avec Ellicit. Avec l’intelligence artificielle, cet outils suggère des articles et des livres scientifiques à partir d’une question de recherche préliminaire, ou à partir de concepts. L’application offre une version gratuite, mais qui est toutefois limité dans le nombre de crédits disponibles mensuellement afin de faire des recherches. Par conséquent, il faut l’utiliser avec parcimonie. Afin de démontrer l’utilité de ce logiciel, utilision un exemple concret.\n\n\n\n\n\nFigure 8.1: Menu d’accueil d’Ellicit\n\n\nPar exemple, disons que je m’intéresse à la question suivante: Qu’est-ce que la démocratie? Cependant, je ne sais par où commencé pour me faire une tête sur le sujet. Ellicit offre une solution à ce problème. La Figure 8.1 correspond au menu d’accueil du site web. Une fois là, je n’aurais qu’à écrire ma question dans la case « Ask a research question ». Les résultats générés sont représentés dans la Figure 8.2 et Figure 8.3\n\n\n\n\n\n\n\n\n\n\n\nFigure 8.2: Court résumé du sujet\n\n\n\n\n\n\n\n\n\nFigure 8.3: Suggestions de lectures\n\n\n\n\n\nLe logiciel offre donc un moyen intéressant afin de faire un premier « filtrage » de la littérature sur un sujet, tout en fournissant un résumé des sources suggérées à partir desquelles nous pouvons juger de sa pertinence en fonction de nos besoins.\nCependant, il est fortement recommandé d’utiliser le résumé produit par le logiciel, dans la Figure 8.2, et ceux de chaque suggestion, dans la Figure 8.3, à titre indicatif et uniquement pour notre propre réflexion. En d’autres termes, ne jamais faire un copier-coller de ces résumés afin de les inclures dans notre travail de recherche. Ce logiciel doit impérativement être accompagné d’une utilisation intègre de la littérature. Une bonne utilisation de ce logiciel devrait se limiter à trouver des articles et/ou des livres scientifiques selon nos besoins, que nous consulterons par la suite pour rédiger notre revue des écrits et trouver des références supplémentaires.\nUn autre outils soffre à nous afin de trouver des références supplémentaires: Research Rabbit. Ce logiciel est gratuit, mais demande de se créer un compte afin de pouvoir utiliser ses services. Une fois que j’ai lu plusieurs articles et/ou chapitres de livre, et que j’ai incorporé les documents dans Zotero, je peux importer mon fichier contenant mes références dans Research Rabbit. La Figure 8.4 présente le menu principal du site web.\n\n\n\n\n\nFigure 8.4: Menu principal\n\n\n\n\n\n\n\nFigure 8.5: Importation manuelle de documents\n\n\n\n\n\n\n\nFigure 8.6: Présentation de la littérature similaire\n\n\n\n\n\n\n\nFigure 8.7: Vue « Timeline » des références\n\n\nAvant toute chose, Research Rabbit doit être considéré comme un outils qui m’aidera à complémenter ma revue des écrits. En d’autres termes, afin que ce logiciel soit utile, il faut déjà avoir des articles sous la main. Ellicit peut nous aider pour cette tâche, mais aussi il est pratique de consulter des handbooks2 afin de se faire une idée sur le sujet qui nous intéresse en plus de trouver des références. Au besoin, les bibliothécaires des différents départements universitaires sont aussi d’excellente ressource pour débuter une recherche.\nUtilisons un exemple concret afin d’illustrer l’utilisation de Research Rabbit. Disons que nous nous intéressons à la question suivante: quel est le rôle des normes pacifistes sur les processus politiques au Japon? Après une rapide recherche, je trouve ces articles qui semblent chaucn éclairer un aspect particulier à propos de cette question. Une fois qu’ils ont été importé dans Zotero et qu’ils ont été lu, je peux importé ma collection Zotero dans Research Rabbit en cliquant sur le bouton Import Zotero Collection, situé dans le coin supérieur gauche de la Figure 8.4. Il se peut que le logiciel ne trouve pas tous les articles que nous avons dans notre collection Zotero. Une alternative est de cliquer sur le bouton vert Add Paper situé dans la colone de notre collection. La Figure 8.5 montre la barre de recherche qui apparaitra, et dans laquelle on pourra ajouter manuellement les articles au besoin. Une fois que nous aurons ajouter les premiers articles que nous aurons lu, Research Rabbit pourra nous dresser une « cartographie » des différentes sources qui sont en lien avec les articles que j’aurai lu. La Figure 8.6 présente cette cartographie.\nNous avons trois possibilités afin de trouver des articles supplémentaires. La première, est de consulter les « Similar Word ». Cette option est intéressante afin de visualiser tous les articles qui sont près de mon sujet, et pour voir comment ils sont liés entre eux. Les points en vert sont les sources qui font parties de ma collection. Cependant, ce n’est pas l’option la plus recommandées. Comme nous pouvons le voir dans la Figure 8.6, en fonction des cinq articles que j’ai importé dans Zotero, il y a 1 501 articles similaires. Ce qui complique la tâche de ciblage. Une deuxième option est d’utiliser « Earlier Work » et « Later Work », surtout avec la vue « Timeline » comme dans la Figure 8.7.\nUne troisième option est de sélectionner une seule source à la fois, et de consulter les deux options suivantes: « All References » et « All Citations ». Elles permettent, respectivement, de visualiser tous les articles qui sont cités dans l’article que nous avons lu, et de visualiser les articles qui ont cité celui que nous avons lu. Ces options sont donc très utiles pour passer au « peigne fin » chacun de nos articles afin de dénicher des sources supplémentaires selon la méthode « boule de neige ». Cependant, il faut faire attention dans notre utilisation de cette méthode. Il y a un risque « d’effet tunnel », soit que notre revue des écrits manque de largeur et de représentativité des différentes recherche sur le sujet. C’est pourquoi il est important de diversifier ces sources et d’utiliser ces deux options d’une façon complémentaire avec plusieurs articles différents. Il est donc utile d’ajouter au fur et à mesure ses sources dans Research Rabbit afin de visualiser la couverture de notre revue des écrits.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Outils d'intelligence artificielle</span>"
    ]
  },
  {
    "objectID": "chapitre_8.html#quelle-est-la-place-du-chercheur-maintenant",
    "href": "chapitre_8.html#quelle-est-la-place-du-chercheur-maintenant",
    "title": "\n8  Outils d’intelligence artificielle\n",
    "section": "\n8.4 Quelle est la place du chercheur maintenant?",
    "text": "8.4 Quelle est la place du chercheur maintenant?\nAvec l’avènement de l’IA, il est tout à fait raisonnable de se demander quelle est la place du chercheur aujourd’hui. L’avenir du chercheur est-il en danger? Pourrait-on assister au développement des sciences sociales sans chercheur humain derrière? Si tel est le cas, est-ce que ça ne constituerait pas un paradoxe important? Est-ce que la machine est mieux placée pour comprendre la réalité du monde sociale, ainsi que ses mécanismes, que l’humain? D’une part, certains pensent que l’IA risque de générer des « laboratoires autonomes » (Hanchen Wang, Tianfan Fu, Yuanqi Du, Wenhao Gao, Kexin Huang, et al., 2023, pp. 55). Il n’est pas difficile d’imaginer un monde où tout le processus scientifique, de la conception jusqu’à la communication, serait fait par l’IA. Le chercheur perdrait ainsi sa profession, et se limiterait à n’être qu’une partie de l’auditoire vers qui les résultats sont présentés.\nBien que nous n’en sommes pas encore là, il est important de réfléchir aux différents enjeux qui se poseraient dans une telle situation. Par exemple, étant donné que l’IA est, pour l’instant, très opaque dans tout le processus qui le mène de l’intrant vers le résultat, comment pourrait-on s’assurer que la machine a pris toutes les précautions nécessaires pour respecter les différents enjeux éthiques? A-t-elle eu le consentement libre et éclairé de tous les participants? De plus, quel est le niveau de confiance que nous pouvons avoir envers des résultats dont on ne connait pas le processus qui y a mené? Sur cette dernière question, l’une des caractéristiques fondamentales de la science est la reproductibilité des protocoles scientifiques (Bourgeois, 2021; King et al., 2021). Toutes les recherches doivent présenter, d’une manière très précise, comment les données ont choisi, comment elles ont été collectées et comment elles ont été analysées. Le terme transparence est très important, et résume l’esprit de toute communication scientifique. Or, c’est une limite importante de l’IA en ce moment: nous n’avons pas accès aux processus qui mènent de l’intrant à l’extrant (Hanchen Wang, Tianfan Fu, Yuanqi Du, Wenhao Gao, Kexin Huang, et al., 2023, pp. 56). Cette opacité nous empêche d’évaluer correctement la validité d’un protocole scientifique qui serait réalisée par l’IA. La conséquence logique de cette situation est de toujours rester vigilant et de questionner constamment les informations fournies par le robot conversationnel. L’utilisation exclusive de tel logiciel, sans se référer à des sources scientifiques qui ont été publiées par des revues scientifiques ou des éditeurs scientifiques, ne devrait jamais être une option. Il n’est pas seulement question d’intégrité et d’éthique, mais de toute la conception de ce que constitue un savoir scientifique. L’utilisation de ChatGPT, par exemple, pour produire un savoir quelconque met au défi nos conceptions épistémologiques. Générer des textes entiers avec l’aide de l’IA ne devrait donc pas être considéré.\nComme nous le voyons, l’avènement de l’IA en recherche amène des questions et des réflexions épistémologiques3 et méthodologiques4 importantes. Ces questions sont cruciales et doivent être abordées le plus rapidement possible. En tant que chercheur, nous devons nous questionner par rapport à l’utilisation de ces nouvelles technologies. Il faut être proactif et initier les réflexions sur la place du chercheur maintenant.\nEn ce sens, il faut élargir notre perspective et dépasser la question quant à savoir si la profession de chercheur va disparaître ou non. En fait, il faut se questionner par rapport au rôle du chercheur. Qu’est-ce qu’il devient à l’ère de l’intelligence artificielle? Comment se transforme-t-il? Pour l’instant, il est encore difficile de répondre et d’anticiper efficacement ce qui arrivera. Il n’en reste pas moins pour autant qu’initier la réflexion est nécessaire. Encore une fois, les universités sont des lieux privilégiés pour avoir ce genre de réflexion, tant venant des étudiants que des enseignants.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Outils d'intelligence artificielle</span>"
    ]
  },
  {
    "objectID": "chapitre_8.html#lia-en-sciences-sociales",
    "href": "chapitre_8.html#lia-en-sciences-sociales",
    "title": "\n8  Outils d’intelligence artificielle\n",
    "section": "\n8.5 L’IA en sciences sociales",
    "text": "8.5 L’IA en sciences sociales\nMalgré que l’utilisation de l’IA en sciences sociales soit relativement récente, il y a déjà quelques recherches qui se sont penchées sur son utilisation dans un contexte scientifique. Tout d’abord, la recherche de Peterson et al. (2021), qui s’intéresse à comprendre comment les individus prennent des décisions, utilise l’IA afin de traiter une importante quantité de donnée rapidement. Leur base de données est environ trente fois plus importante que celles des études précédentes. De plus, ils ont programmé différentes théories afin de vérifier laquelle correspondait le mieux aux patterns présents dans les données. L’utilisation de l’IA dans cette recherche est très intéressante puisqu’elle permet de tester des théories existantes sur un vaste ensemble de données, qui auraient pris beaucoup plus de temps si cela avait été réalisé « manuellement ».\nEnsuite, la recherche de Park et al. (2023) utilise l’IA pour créer des “generative agents” qui interagissent entre eux reproduisant des comportements individuels et collectifs humains. Leur objectif et d’en faire des proxys1 pour étudier le comportement humain. Leur modèle prend la forme d’une simulation interactive, similaire au jeu vidéo Sims. Bien que ce ne soit pas encore au point, cette application de l’IA permettrait de tester des prototypes de systèmes sociaux ainsi que des théories (Park et al., 2023).\nSimilairement, la recherche de Argyle et al. (2023) utilise ChatGPT comme proxy pour étudier l’opinion publique certains sous-groupes sociaux. Leur objectif est de démontrer que ChatGPT peut être utilisé, avec un bon niveau de confiance, pour explorer et tester des hypothèses qui seraient coûteuses si c’était fait avec des sujets humains. En effet, le déploiement d’un sondage est toujours une sorte pari; ils sont en général relativement coûteux, et il est difficile de prévoir si les résultats obtenus seront significatifs. ChatGPT permettrait donc de faire un prétest afin d’améliorer et de corriger un questionnaire avant de le déployer sur des sujets humains.\nMalgré ces avantages, il est important de souligner quelques limites quant à l’utilisation de l’IA en sciences sociales. La limite la plus importante est que l’IA ne remplace en aucun cas un être humain. Étant des chercheurs en sciences sociales et sciences humaines, nous dénaturerions nos disciplines si l’on se limitait à l’IA pour répondre à nos questions. Par conséquent, un test réalisé avec l’IA ne pourra jamais avoir le même niveau de confiance qu’une recherche réalisée avec des humains. Il est donc important de limiter l’utilisation de l’IA à des fins exploratoires. Une autre limite importante, mentionnée par Park et al. (2023) dans leur recherche, est que l’IA peut être sujette à des hallucinations. En d’autres termes, l’IA peut fabriquer des informations de toute pièce (Weise & Metz, 2023). Cela pose un sérieux problème quant à la fiabilité des informations générées par l’IA. C’est pour cette raison, notamment, que nous devons toujours rester vigilants. Les conséquences d’attribuer une valeur scientifique à des informations qui seraient fausses seraient graves. La science ne vise pas à construire une compréhension fictive de la réalité. Une fausse compréhension des interactions et des dynamiques sociales pourrait avoir des conséquences vraiment importantes sur le bien-être de nos sociétés. Restons vigilants.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Outils d'intelligence artificielle</span>"
    ]
  },
  {
    "objectID": "chapitre_8.html#conclusion",
    "href": "chapitre_8.html#conclusion",
    "title": "\n8  Outils d’intelligence artificielle\n",
    "section": "\n8.6 Conclusion",
    "text": "8.6 Conclusion\nEn guise de conclusion, nous souhaitons lancer une dernière réflexion un peu plus philosophique, mais tout aussi importante: le transhumanisme, «[…] un mouvement international, culturel et intellectuel, prônant l’usage des sciences et des techniques dans le but d’améliorer la condition humaine, notamment par l’augmentation des capacités physiques et mentales des êtres humains » (Forestier & Ansermet, 2021). La question principale qui se pose est: est-ce vraiment raisonnable d’augmenter les capacités humaines au-delà de leur limite biologique? Surtout, que deviendront les sciences sociales et humaines si le principal sujet d’étude, soit l’humain, n’est plus tout à fait lui-même? Peut-on faire des sciences sociales sur des sujets qui sont que partiellement humain? Ce qui rend les sciences sociales aussi intéressantes et pertinentes c’est peut-être, justement, parce que l’humain n’a pas d’essence. Pour reprendre les mots de Sartre (1996, pp. 26), « l’existence précède l’essence ». En d’autres termes, et comme Sartre l’explique, l’humain n’existe pas pour remplir une fonction prédéterminée, contrairement à un crayon qui a été conçu pour remplir la tâche spécifique d’écrire. C’est dans cette liberté, et c’est par l’expérience, que l’humain se construit et se définit. Notre existence en tant que scientifique du monde social et humain est possible que grâce à cette condition fondamentale : l’absence d’une essence qui précède l’existence. Sinon, à quoi bon étudier le monde social s’il a une fonction prédéterminée et fixe, dans lequel les humains n’auraient aucune agentivité?\nCependant, avec l’arrivée de l’IA et ce désir de constamment repousser les limites humaines, ne sommes-nous pas en train de prouver à Sartre qu’il a tort? En fait, l’humain se serait imposé une essence, soit celle d’être une pièce indispensable pour faire fonctionner les rouages du système capitaliste. Face à la conception de la « croissance infinie » qui est entretenue par ce système, l’être humain a besoin de quelque chose pour « briser » ses capacités qui elles sont limitées : « […] un remodelage technoscientifique et biomédical des corps et des vies, dans leur matérialité biologique même, afin d’adapter les individus au régime capitaliste globalisé de l’accélération. » (Dévédec, 2021, pp. 100). L’IA sera-t-elle une pièce de plus vers la réalisation de cet idéal transhumaniste?\nLe propos ici n’est pas d’encourager les lecteurs à ne pas utiliser l’IA. En fait, nous souhaitons tout simplement appeler à une certaine prudence. Le risque que cette technologie nous pose est d’en devenir dépendant, voir trop (Park et al., 2023). Bien qu’elle offre de nombreux avantages, elle a aussi le piège d’offrir beaucoup de raccourcis et de nuire à plusieurs de nos capacités intellectuelles et physiques. Il faut donc développer un jugement critique dans notre utilisation de l’IA. Se poser des questions sur notre utilisation personnelle de ces outils constitue, dès aujourd’hui, le fondement des chercheurs en sciences sociales numériques.\nToutefois, à moins que la recherche porte directement sur ChatGPT, nous déconseillons fortement d’utiliser uniquement ce que le robot conversationnel fournit comme réponse. Reprenons l’exemple du totalitarisme. Dans ce cas, bien que la définition fournie soit relativement adéquate, nous recommandons d’aller consulter des sources académiques afin de trianguler la définition générée, d’une part, et surtout de présenter une définition qui est reconnue par les pairs scientifiques. Pour ce faire, il est possible d’utiliser ChatGPT. Nous pouvons lui demander de nous fournir 5 livres qui portent sur le sujet. À partir de ces recommandations, nous pouvons nous référer directement à ces ouvrages et débuter notre revue des écrits. Surtout, à moins que ce ne soit que pour vous faire une idée du contenu, n’utilisez pas ChatGPT pour résumer un livre et utiliser le résumé pour votre travail ! Cette pratique constitue une forme de plagiat. Aller consulter les ouvrages directement plutôt que d’utiliser les définitions fournies par ChatGPT fait partie des bonnes pratiques. Développer un esprit de synthèse est fondamental pour chaque étudiant.e universitaire, ainsi que pour les futurs chercheur.euse.s. Commencez dès maintenant à développer ces capacités plutôt que de demander à ChatGPT de le faire à votre place.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Outils d'intelligence artificielle</span>"
    ]
  },
  {
    "objectID": "chapitre_8.html#utilisation-du-package-openai",
    "href": "chapitre_8.html#utilisation-du-package-openai",
    "title": "\n8  Outils d’intelligence artificielle\n",
    "section": "\n8.7 Utilisation du package OpenAI",
    "text": "8.7 Utilisation du package OpenAI\n\n8.7.1 Installation et chargement du package\n\ninstall.packages(\"openai\") ## au besoin\nlibrary(openai)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Outils d'intelligence artificielle</span>"
    ]
  },
  {
    "objectID": "chapitre_8.html#configuration-de-lapi",
    "href": "chapitre_8.html#configuration-de-lapi",
    "title": "\n8  Outils d’intelligence artificielle\n",
    "section": "\n8.8 Configuration de l’API",
    "text": "8.8 Configuration de l’API\nProcurez vous une clé API sur le site d’OpenAI. Soyez conscient que vous aurez besoin d’une carte de crédit pour vous inscrire et que l’utilisation de l’API est payante. Renseignez-vous sur les modèles disponibles et leurs frais d’utilisation. En date de la publication du livre, le modèle de tarification d’OpenAi est de charger un prix spécifique par 1000 tokens. Le prix des Tokens en entrée est moins élevé que celui des tokens en sortie.\nLorsque vous aurez votre clé API, utilisez le package usethis pour la configurer dans votre environnement R.\n\ninstall.packages(\"usethis\") ## au besoin\nusethis::edit_r_environ()\n\nAjoutez la ligne suivante à votre fichier .Renviron.\n\nOPENAI_API_KEY=inserez-votre-cle-api-ici-sans-guillemets",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Outils d'intelligence artificielle</span>"
    ]
  },
  {
    "objectID": "chapitre_8.html#utilisation-de-lapi",
    "href": "chapitre_8.html#utilisation-de-lapi",
    "title": "\n8  Outils d’intelligence artificielle\n",
    "section": "\n8.9 Utilisation de l’API",
    "text": "8.9 Utilisation de l’API\nLa fonction principale du package openai est create_chat_completion(). Elle prend en entrée le modèle que vous souhaitez utiliser ainsi que le message que vous souhaitez envoyer au modèle en format list. Voici un modèle d’utilisation de la fonction:\n\nchat_prompt &lt;- create_chat_completion(\n    model = \"gpt-3.5-turbo\",\n    messages = list(\n        list(\n            \"role\" = \"system\",\n            \"content\" = \"You are a helpful assistant.\"\n        ),\n        list(\n            \"role\" = \"user\",\n            \"content\" = \"Please do the following:\")\n        )\n    )\n\nLe résultat de votre requête sera contenu dans l’objet chat_prompt formatté en JSON. Vous pouvez accéder aux variables de la même façon qu’un dataframe normal. Le contenu de la réponse sera dans chat_prompt$choices$content.\nUtiliser chatgpt de cette façon ouvre plein de possibilités. Appliquer des instructions sur un ensemble d’observations à l’aide de boucles, utiliser des fonctions pour générer des messages et les appliquer à travers d’autres API, analyser des sites webs en temps réel en scraping avec des paquets tels rvest, etc. Ce sera à vous de réfléchir aux possibilités que vous souhaitez explorer.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Outils d'intelligence artificielle</span>"
    ]
  },
  {
    "objectID": "chapitre_8.html#notes",
    "href": "chapitre_8.html#notes",
    "title": "\n8  Outils d’intelligence artificielle\n",
    "section": "\n8.10 Notes",
    "text": "8.10 Notes\n\nIl est possible d’accéder aux statistiques d’utilisation de token dans chat_prompt$usage$prompt_tokens et chat_prompt$usage$completion_tokens. Vous pouvez donc calculer le coût de votre requête en fonction du modèle que vous utilisez.\nNe pas oublier d’inclure .Renviron dans votre gitignore pour ne pas vous faire voler votre clé API.\nIl est possible de créer des images avec la fonction create_image(“Inserez votre texte ici”)\nIl est possible d’effectuer du speech-to-text avec la fonction create_transcription() et create_translation()\nPlus de documentation est disponible au https://irudnyts.github.io/openai/\nPlus de fonctionalités sont disponibles en python mais le package R est suffisant pour la plupart des utilisations.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Outils d'intelligence artificielle</span>"
    ]
  },
  {
    "objectID": "chapitre_8.html#annexe-1",
    "href": "chapitre_8.html#annexe-1",
    "title": "\n8  Outils d’intelligence artificielle\n",
    "section": "\n8.11 Annexe 1",
    "text": "8.11 Annexe 1\nBonnes pratiques d’utilisation Harvard. 2023. « Guidelines for using ChatGPT and other Generative AI tools at Harvard ». https://provost.harvard.edu/guidelines-using-chatgpt-and-other-generative-ai-tools-harvard\nMIT. 2023. « Advice and responses from faculty on ChatGTP and A.I.-assisted writing ». https://cmsw.mit.edu/advice-and-responses-from-faculty-on-chatgpt-and-a-i-assisted-writing/",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Outils d'intelligence artificielle</span>"
    ]
  },
  {
    "objectID": "chapitre_8.html#annexe-2",
    "href": "chapitre_8.html#annexe-2",
    "title": "\n8  Outils d’intelligence artificielle\n",
    "section": "\n8.12 Annexe 2",
    "text": "8.12 Annexe 2\nQ : Qu’est-ce que le totalitarisme? R : Le totalitarisme est un système politique et idéologique caractérisé par un contrôle absolu et centralisé du gouvernement sur tous les aspects de la vie publique et privée d’une société. Dans un régime totalitaire, le gouvernement exerce un pouvoir autoritaire et oppressif, limitant sévèrement les libertés individuelles, supprimant les droits de l’homme, et éliminant ou réprimant toute opposition ou critique.\nBonnes pratiques d’utilisation Harvard. 2023. « Guidelines for using ChatGPT and other Generative AI tools at Harvard ». https://provost.harvard.edu/guidelines-using-chatgpt-and-other-generative-ai-tools-harvard\nMIT. 2023. « Advice and responses from faculty on ChatGTP and A.I.-assisted writing ». https://cmsw.mit.edu/advice-and-responses-from-faculty-on-chatgpt-and-a-i-assisted-writing/",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Outils d'intelligence artificielle</span>"
    ]
  },
  {
    "objectID": "chapitre_8.html#annexe-2-1",
    "href": "chapitre_8.html#annexe-2-1",
    "title": "\n8  Outils d’intelligence artificielle\n",
    "section": "\n8.13 Annexe 2",
    "text": "8.13 Annexe 2\nQ : Qu’est-ce que le totalitarisme? R : Le totalitarisme est un système politique et idéologique caractérisé par un contrôle absolu et centralisé du gouvernement sur tous les aspects de la vie publique et privée d’une société. Dans un régime totalitaire, le gouvernement exerce un pouvoir autoritaire et oppressif, limitant sévèrement les libertés individuelles, supprimant les droits de l’homme, et éliminant ou réprimant toute opposition ou critique.\nLes caractéristiques clés du totalitarisme comprennent :\n\nContrôle gouvernemental absolu : Le gouvernement exerce un contrôle total sur tous les aspects de la vie, y compris l’économie, la culture, l’éducation, les médias, la religion et les activités sociales.\nIdéologie dominante : Le régime totalitaire est basé sur une idéologie spécifique qui est imposée à la population. Cette idéologie est souvent promue comme la seule vérité et toute forme de pensée dissidente est sévèrement réprimée.\nCulte de la personnalité : Les dirigeants du régime totalitaire sont souvent présentés comme des figures quasi-divines ou héroïques, et un culte de la personnalité est créé autour d’eux pour renforcer leur autorité.\nRépression politique : Toute forme d’opposition politique est réprimée de manière brutale. Les opposants sont souvent emprisonnés, torturés, voire exécutés. La surveillance et la dénonciation sont courantes pour empêcher toute critique du régime.\nPropagande intensive : Le gouvernement contrôle les médias et utilise la propagande pour manipuler l’opinion publique, répandre sa vision du monde et justifier ses actions.\nAbsence de droits individuels : Les droits individuels tels que la liberté d’expression, la liberté de la presse, le droit de réunion et d’association sont souvent supprimés au profit de la suprématie de l’État.\nContrôle de l’éducation : L’éducation est utilisée pour propager l’idéologie du régime et façonner la mentalité des citoyens conformément à ses objectifs.\nUtilisation de la terreur : La terreur et l’intimidation sont utilisées pour maintenir le contrôle sur la population. Les purges et les arrestations arbitraires sont fréquentes pour maintenir un climat de peur.\n\nDes exemples historiques de régimes totalitaires incluent l’Allemagne nazie sous Adolf Hitler, l’Union soviétique sous Joseph Staline, et la Chine sous Mao Zedong. Le totalitarisme est généralement considéré comme une forme extrême et oppressive de gouvernement, en contraste avec les systèmes démocratiques qui mettent l’accent sur les libertés individuelles, la séparation des pouvoirs et la participation citoyenne.\n{&lt;&lt; pagebreak &gt;&gt;}",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Outils d'intelligence artificielle</span>"
    ]
  },
  {
    "objectID": "chapitre_8.html#défis-et-enjeux-éthiques-de-lia-focus-sur-chatgpt",
    "href": "chapitre_8.html#défis-et-enjeux-éthiques-de-lia-focus-sur-chatgpt",
    "title": "\n8  Outils d’intelligence artificielle\n",
    "section": "\n9.1 Défis et enjeux éthiques de l’IA, focus sur ChatGPT",
    "text": "9.1 Défis et enjeux éthiques de l’IA, focus sur ChatGPT\nEn tant qu’étudiant, professeur, professionnel ou chercheur, il faut se questionner par rapport à notre propre utilisation des différents outils de l’IA. Tout d’abord, il est important de comprendre qu’il y a plus de questions que de réponses pour l’instant. Face à ce constat, nous n’avons pas la prétention d’être en mesure de cibler toutes les questions qui émergent actuellement, et encore moins d’avoir les réponses. Cependant, cela ne justifie pas pour autant d’être passif. Nous devons essayer d’être réflexifs et critiques dans la limite de nos capacités et de nos connaissances. En ce sens, les étudiants et les enseignants doivent aussi être proactifs en entreprenant les démarches nécessaires ainsi qu’en s’engageant dans la réflexion.\nDans un premier temps, un bon usage de ces outils débute avec une bonne réflexion quant à leur utilisation. Par conséquent, les universités constituent des endroits privilégiés pour favoriser les discussions et les réflexions quant à l’utilisation de ces technologies. D’ailleurs, certaines universités se sont déjà dotées de lignes directrices quant à l’utilisation de robots conversationnels et de l’IA générative5. Nous sommes d’avis que chaque université aurait intérêt à se doter de tel document, afin de fournir les ressources nécessaires aux étudiants ainsi qu’aux membres du corps professoral dans leur utilisation de ces outils. L’accompagnement et l’encadrement dans l’exploration et l’utilisation de l’IA nous paraissent être une bonne stratégie à adopter afin de permettre le développement de bonnes pratiques.\nActuellement, un enjeu majeur, surtout avec les robots conversationnels, est le plagiat. Notre but ici est de présenter les différentes ressources qui s’offrent aux lecteurs pour qu’ils puissent développer les bonnes pratiques d’utilisation de ces outils tout en restant intègres. Pour ce faire, nous présenterons dans les paragraphes suivants les bonnes pratiques de citation selon l’American Psychological Association et The Chicago Manual of Style. Avant cela, il est important de spécifier que notre point de vue, et les propos tenus dans ce livre, ne remplace en aucun cas les règlements disciplinaires et/ou codes de conduite établis par une institution académique quelconque. Par conséquent, nous invitons fortement les lecteurs à consulter les sites web de ces associations, à se référer aux personnels appropriés pour toutes questions relatives à l’utilisation de texte généré par l’IA ainsi qu’à tout document relatif au plagiat produit par l’institution académique fréquentée. Passons maintenant à la présentation de ces manuels de style.\nL’American Psychological Association (APA) encourage les utilisateurs à être transparents quant à leur utilisation de logiciels tel que ChatGPT. Lorsqu’utilisés, les chercheurs devraient spécifier clairement qu’ils ont utilisé le logiciel, en plus de décrire comment ils ont utilisé le logiciel, quel prompt ont-ils utilisé et quel a été le résultat en plus de fournir des extraits textuels (McAdoo, 2023). Il est recommandé de documenter chaque utilisation. Se créer un document qui inclue la date d’utilisation, la question demandée ainsi que la réponse obtenue doit faire partie des bonnes pratiques de chacun. Ces éléments peuvent être ajoutés en annexe au besoin (McAdoo, 2023). Sans grande surprise, il est impératif de citer l’auteur lorsqu’on utilise des idées qui ne sont pas les nôtres. Dans le cas de robots conversationnels, nous devons citer le développeur (McAdoo, 2023). Par exemple, pour une citation de ChatGPT, il faudra référer à OpenAI, soit le développeur du logiciel.\nUtilisons un exemple concret afin d’illustrer le tout. Supposons que je m’intéresse au concept du totalitarisme, mais que je n’ai pas une compréhension claire de ce que ça signifie. Je pourrais utiliser ChatGPT pour me fournir une définition du concept. Si je souhaite l’inclure dans mon travail, je procèderais de la façon suivante : nous avons utilisé ChatGPT afin de nous donner une définition du totalitarisme. Pour ce faire, nous lui avons posé la question suivante : « Qu’est-ce que le totalitarisme? ». Le logiciel nous a fourni la définition suivante : « Le totalitarisme est un système politique et idéologique caractérisé par un contrôle absolu et centralisé du gouvernement sur tous les aspects de la vie publique et privée d’une société. Dans un régime totalitaire, le gouvernement exerce un pouvoir autoritaire et oppressif, limitant sévèrement les libertés individuelles, supprimant les droits de l’homme, et éliminant ou réprimant toute opposition ou critique. » (OpenAI 2023)\nEn bibliographie, la référence serait insérée comme suit, et ensuite j’irai insérer la question et la réponse complète en annexe6.\nOpenAI. (2023). ChatGPT (Version du 3 août 2023) [Large Language Model]. https://chat.openai.com/auth/login (exemple tiré de McAdoo 2023)\n\nQuant au manuel de style Chicago, il est recommandé de mentionner et d’expliquer que nous avons utilisé ChatGPT pour accomplir une certaine tâche dans notre texte. Toutefois, comme le lien généré lors de l’utilisation individuelle de ChatGPT n’est pas public et ne peut pas être consulté par les autres, il n’est pas recommandé d’insérer la référence en bibliographie.\nToutefois, à moins que la recherche porte directement sur ChatGPT, nous déconseillons fortement d’utiliser uniquement ce que le robot conversationnel fournit comme réponse. Reprenons l’exemple du totalitarisme. Dans ce cas, bien que la définition fournît soit relativement bonne, nous recommandons d’aller consulter des sources académiques afin de trianguler la définition qui a été générée, d’une part, et surtout de présenter une définition qui est reconnue par les pairs scientifiques. Toutefois, pour ce faire, il est possible d’utiliser ChatGPT. Nous pouvons lui demander de nous fournir 5 livres qui portent sur le sujet. À partir de ces recommandations, nous pouvons nous référer directement à ces ouvrages et débuter notre revue des écrits. Surtout, à moins que ce ne soit que pour vous faire une idée du contenue, n’utilisez pas ChatGPT pour résumer un livre et utiliser le résumé pour votre travail! Cette pratique constitue une forme de plagiat. Aller consulter les ouvrages directement plutôt que d’utiliser les définitions fournies par ChatGPT fait partie des bonnes pratiques. De plus, développer un esprit de synthèse est fondamental pour chaque étudiant universitaire, ainsi que pour les futurs chercheurs. Commencez dès maintenant à vous pratiquer pour développer ces capacités. Ne demandez pas à ChatGPT de le faire à votre place.\n\n\n\n\nAlpaydin, E., & Bach, F. (2014). Introduction to Machine Learning (3e éd.). MIT Press. https://ebookcentral.proquest.com/lib/umontreal-ebooks/detail.action?docID=3339851\n\n\nArgyle, L. P., Busby, E. C., Fulda, N., Gubler, J. R., Rytting, C., & Wingate, D. (2023). Out of One, Many: Using Language Models Ot Simulate Human Samples. Political Analysis, 31(3), 337‑351. https://doi.org/10.1017/pan.2023.2\n\n\nBengio, Y. (2023, juillet 21). One of the \"Godfathers of AI\" Airs His Concerns. The Economist. https://www.economist.com/by-invitation/2023/07/21/one-of-the-godfathers-of-ai-airs-his-concerns\n\n\nBertolini, A. (2020). Artificial Intelligence and Civil Liability [Policy Department for Citizen's Rights and Constitutional Affairs]. European Union. https://www.europarl.europa.eu/RegData/etudes/STUD/2020/621926/IPOL_STU(2020)621926_EN.pdf\n\n\nBourgeois, I. (2021). Qu’est-Ce Que La Recherche Sociale? In Recherche Sociale. De La Problématique à La Collecte Des Données (7e éd., p. 1‑14). Presses de l’Université du Québec.\n\n\nBremmer, I., & Suleyman, M. (2023). The AI Power Paradox. Foreign Affairs, 102(5), 26‑43.\n\n\nDévédec, N. L. (2021). \"Sans Limites\": Une Critique Politique et Écologique Du Transhumanisme et de Son Monde. Cahiers Société, 3, 99‑122. https://doi.org/10.7202/1090180ar\n\n\nDevedzic, V. (2022). Identity of AI. Discover Artificial Intelligence, 2(23). https://doi.org/10.1007/s44163-022-00038-0\n\n\nForestier, F., & Ansermet, F. (2021). Le Transhumanisme. In La Dévoration Numérique (p. 19‑54). Odile Jacob. https://www.cairn.info/la-devoration-numerique--9782415000240-page-19.htm\n\n\nGlover, E. (2024, février 13). Machine Translation: How It Works and Tools to Choose From. https://builtin.com/artificial-intelligence/machine-translation\n\n\nHanchen Wang, Tianfan Fu, Yuanqi Du, Wenhao Gao, Kexin Huang, Ziming Liu, Payal Chandak, Shengchao Liu, Peter Van Katwyk, Andreea Deac, Anima Anandkumar, Karianne Bergen, Carla P. Gomes, Shirley Ho, Pushmeet Kohli, Joan Lasenby, Jure Leskovec, Tie-Yan Liu, Arjun Manrai, Debora Marks, Bharath Ramsundar, Le Song, Jimeng Sun, Jian Tang, Petar Veličković, Max Welling, Linfeng Zhang, Connor W. Coley, & Yoshua Bengio, & Marinka Zitnik. (2023). Scientific Discovery in the Age of Artificial Intelligence. Nature, 620, 47‑60. https://www.nature.com/articles/s41586-023-06221-2\n\n\nHarari, Y. N. (2023, avril 28). Yuval Noah Harari Argues That AI Has Hacked the Operating System of Human Civilisation. The Economist. https://www.economist.com/by-invitation/2023/04/28/yuval-noah-harari-argues-that-ai-has-hacked-the-operating-system-of-human-civilisation\n\n\nIBM. (2023a). What Are Neural Networks? | IBM. https://www.ibm.com/topics/neural-networks\n\n\nIBM. (2023b). What Is Artificial Intelligence (AI) ? | IBM. IBM. https://www.ibm.com/topics/artificial-intelligence\n\n\nKing, G., Keohane, R. O., & Verba, S. (2021). Designing Social Inquiry. Scientific Inference in Qualitative Research. (Nouvelle édition). Princeton University Press.\n\n\nKönig, P. D., Krafft, T. D., Schulz, W., & Zweig, K. A. (2022). Essence of AI. What Is AI? In and M. Cannarsa Cristina Poncibò (Éd.), The Cambridge Handbook of Artificial Intelligence (p. 18‑34). Cambridge University Press. https://doi.org/10.1017/9781009072168.005\n\n\nMcAdoo, T. (2023, avril 7). How to Cite ChatGPT. https://apastyle.apa.org. https://apastyle.apa.org/blog/how-to-cite-chatgpt\n\n\nMcCarthy, J. (2007). WHAT IS ARTIFICIAL INTELLIGENCE?\n\n\nPark, J. S., O’Brien, J. C., Cai, C. J., Morris, M. R., Liang, P., & Bernstein, M. S. (2023). Generative Agents: Interactive Simulacra of Human Behavior. arXiv. https://doi.org/10.48550/arXiv.2304.03442\n\n\nPeterson, J. C., Bourgin, D. D., Agrawal, M., Reichman, D., & Griffiths, T. L. (2021). Using Large-Scale Experiments and Machine Learning to Discover Theories of Human Decision-Making. Science, 372(6547), 1209‑1214. https://doi.org/10.1126/science.abe2629\n\n\nRoser, M. (2022, décembre 6). The Brief History of Artificial Intelligence: The World Has Changed Fast – What Might Be Next? Our World in Data. https://ourworldindata.org/brief-history-of-ai\n\n\nSartre, J.-P. (1996). L’existentialisme Est Un Humanisme. Gallimard.\n\n\nTabsharani, F. (2023, août). What Is Machine Translation? Definition from TechTarget. Enterprise AI. https://www.techtarget.com/searchenterpriseai/definition/machine-translation\n\n\nWang, P. (2019). On Defining Artificial Intelligence. Journal of Artificial General Intelligence, 10(2), 1‑37. https://doi.org/10.2478/jagi-2019-0002\n\n\nWeise, K., & Metz, C. (2023, mai 9). When A.I. Chatbots Hallucinate. The New York Times. https://www.nytimes.com/2023/05/01/business/ai-chatbots-hallucination.html",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Outils d'intelligence artificielle</span>"
    ]
  },
  {
    "objectID": "chapitre_8.html#footnotes",
    "href": "chapitre_8.html#footnotes",
    "title": "\n8  Outils d’intelligence artificielle\n",
    "section": "",
    "text": "Intelligence étant définit de la façon suivante : « L’intelligence est la partie informatique de la capacité à atteindre des objectifs dans le monde. On trouve différents types et degrés d’intelligence chez l’homme, chez de nombreux animaux et chez certaines machines. » (McCarthy, 2007, pp. 2)↩︎\nIl s’agit d’ouvrages généraux qui porte sur un sujet quelconque. Les éditeurs les plus connus sont notamment Oxford, SAGE et Routledge.↩︎\nL’épistémologie est l’une des branches de la philosophie des sciences qui s’intéresse au savoir et à la connaissance. De manière générale, et très simplifié, l’une des questions fondamentales de l’épistémologie et de se questionner quant à savoir ce qu’est un savoir qui serait scientifique.↩︎\nLa méthodologie fait référence à la branche de la philosophie des sciences qui s’intéresse aux outils de collecte et d’analyse de données.↩︎\nSur ce sujet, nous recommandons de consulter les ressources dans la section Bonnes pratiques d’utilisation de l’IA dans l’Annexe 1 du chapitre.↩︎\nRéférez-vous à l’Annexe 2 pour un exemple.↩︎",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Outils d'intelligence artificielle</span>"
    ]
  },
  {
    "objectID": "conclusion.html",
    "href": "conclusion.html",
    "title": "9  Kit de démarrage pour les sciences sociales numériques",
    "section": "",
    "text": "9.1 Introduction\nAlors que les chapitres précédents se sont consacrés à la présentation théorique et pratique des sciences sociales numériques, le présent chapitre s’efforcera à aider le lecteur à faire sens de la grande quantité d’information que contient l’ouvrage et à commencer sa propre démarche d’apprentissage numérique. À ce propos, le titre n’est pas anodin. Il est possible de voir ce chapitre comme l’endroit où débuter son apprentissage des nouveaux outils numériques présentés dans cet ouvrage.\nEn plus d’aider de lecteur à installer et à utiliser plusieurs des outils présentés précedemment, ce chapitre offre également des conseils afin d’éviter de communs pièges lors de l’apprentissage de nouveaux outils. Le corps du texte du présent chapitre est divisé en trois parties en lien avec le niveau de difficulté associés à l’apprentissage des différents outils numériques: débutant, intermédiaire et avancé. De plus, chaque partie termine par une liste de pièges à éviter et qui est associé au niveau d’apprentissage qui lui est propre.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Kit de démarrage pour les sciences sociales numériques</span>"
    ]
  },
  {
    "objectID": "conclusion.html#débutant",
    "href": "conclusion.html#débutant",
    "title": "9  Kit de démarrage pour les sciences sociales numériques",
    "section": "9.2 Débutant",
    "text": "9.2 Débutant\nCette section peut s’adresser à tous les lecteurs, mais elle vise particulièrement ceux et celles qui débutent leurs parcours dans le monde numérique. Elle se divisera en deux sous-sections portant chacune sur un type d’outils nécessaires à la pratique des sciences sociales numériques. La première partie couvre le langage de programmation R et l’environnement de programmation qui lui est associé, RStudio. Elle commence par présenter au lecteur comment télécharger R et RStudio correctement. Ensuite, elle offre différentes ressources afin de pouvoir apprendre à utiliser R et naviguer RStudio adéquatement. La seconde section guide le lecteur dans l’installation de , puis présente des ressources utiles à son utilisation.\n\n9.2.1 R et RStudio\nLe chapitre 4 du présent livre introduit le langage de programmation R, ses avantages, ses inconvénients et son utilité. Cette partie du livre se veut un complément à ce chapitre visant à aider le lecteur à se familiariser avec le langage R. La première étape pour mener à bien cette tâche est de le télécharger. R fonctionne sur une grande quantité de plateformes, notamment sur les différentes distributions de Windows, de macOS et de Linux. Pour le télécharger, il faut commencer par se rendre sur le Comprehensive R Archive Network. Il est fortement conseillé d’utiliser ce site puisqu’il est l’endroit principal où se trouve la plupart des choses liées à R. Il est aussi facile d’utilisation, très bien documenté et régulièrement mis à jour. Il est possible d’accéder le site à partir de l’adresse suivante : https://cran.r-project.org/. Dans le haut de la page, un lien pour chacun des trois systèmes d’exploitation principaux – Windows, macOS et Linux – redirige vers la page appropriée. Il suffit de cliquer sur la distribution présente sur l’ordinateur et l’installer.\nIl existe plusieurs ressources qu’un nouvel utilisateur de R peut consulter afin de se familiariser avec le langage de programmation. Comme pour de nombreuses autres choses, il est possible d’apprendre en faisant des exercises en ligne et en suivant des tutoriels. Les tutoriels sont une manière tout autant enrichissante que divertissante pour se familiariser avec certains outils du monde numérique, notamment le langage R. DataCamp est un des sites les plus populaires, mais aussi les plus complets et accessibles, à cette fin. Datacamp est une plateforme d’apprentissage en ligne proposant des exercices interactifs en ligne, axé principalement sur l’analyse et les données. La plateforme est facile à utiliser et contient une grande quantité de module sur les différents aspects du langage R. En date de 2023, selon le site de l’entreprise, DataCamp contient plus de 140 cours interactifs portant sur le langage R, en plus de contenir plus de 100 tutoriels variés. La plateforme a également un forum où il est possible d’interagir avec les autres utilisateurs et poser des questions. Un autre avantage de Datacamp est son accessibilité. En plus des cours accessibles gratuitement, Datacamp offre des réductions sur les abonnements pour les étudiants et les enseignants. Il est également possible pour les enseignants d’obtenir gratuitement un compte Datacamp Entreprise à des fins d’utilisation éducative. D’autres plateformes dans le même genre que DataCamp existent. Les alternatives les plus populaires sont CodeAcademy et Coursera. Bien qu’il n’y ait rien de mal à proprement parler à utiliser ces alternatives, nous conseillons DataCamp car cette plateforme apparaît être la meilleure pour l’apprentissage de nouveaux outils numériques destinés à la science des données en sciences sociales.\nEn plus de ces différentes ressources en ligne, plusieurs excellent ouvrages d’introduction au langage de programmation R sont disponibles. Les auteurs du présent ouvrage proposent trois ouvrages aux nouveaux utilisateurs. Le livre R For Data Science d’Hadley Wickham et de Garret Grolemund est un classique en la matière et est un excellent guide sur les différents éléments à apprendre pour bien maîtriser le langage de programmation R ainsi que son utilité en sciences sociales computationnelles. Publié pour la première fois en 2017, il a été réédité une seconde fois en 2023 et est disponible gratuitement en ligne à l’adresse suivante: https://r4ds.hadley.nz/. Un second ouvrage qui peut être utile est The Book of R: A First Course in Programming and Statistics de Tilman Davies. Le Book of R, comme certains l’appelle, est un guide complet et convivial pour les débutants en R. Contrairement à d’autres ressources du même genre, il ne demande aucune expérience en programmation et à peine quelques connaissances de base en mathématiques afin de commencer à apprendre à utiliser R efficacement pour l’analyse statistique. Finalement, le troisième ouvrage, Beyond Spreadsheets with R: A beginner’s guide to R and RStudio de Jonathan Caroll, montre comment prendre des données brutes et les transformer pour les utiliser dans des calculs, des tableaux, des graphiques, etc. Le livre a pour but d’aider le lecteur à bâtir des bases solides afin de lui permettre d’analyser et visualiser des données de toutes sortes à l’aide de R. Un avantage qu’a cet ouvrage sur les autres est qu’il est également un guide d’apprentissage pour RStudio. Ce livre, ainsi que celui de Tilman Davies, sont disponibles sur Amazon et autres plateformes de vente de livres.\nEn ce qui a trait à RStudio, outre que le livre de Tilman Davies susmentionné, il existe plusieurs ressources en ligne pouvant aider les utilisateurs débutants. DataCamp a un long tutoriel dédié à apprendre à utiliser l’environnement de programmation RStudio. Le site web de RStudio a également une section sur les bases de l’environnement de programmation. Plusieurs institutions offrent également de courts tutoriels par le biais de pages webs ou de vidéos accessibles sur des plateformes telles que Youtube. Autant pour R que pour RStudio, une grande quantité de ressources d’aide sont disponibles en ligne. Des forums tels que Stack Overflow et la section discussion de GitHub peuvent être très utiles pour avoir une réponse rapide à une question technique.\n\n\n9.2.2 Les alternatives à Word : les langages de balisage\nLe chapitre 5 du présent ouvrage introduit les langages de balisage et Markdown, leurs historiques ainsi que leurs avantages et inconvénients. Cette partie du livre se veut un complément au chapitre 5 visant à aider le lecteur à se familiariser avec les principaux langages de balisage utilisés en sciences sociales numériques. La première étape pour afin d’utiliser les langages de balisage et Markdown est de les télécharger. Bien que LaTeX peuvent être téléchargé à différents endroits, celui qui est généralement considéré comme étant officiel est le Comprehensive TEX Archive Network (CTAN). Le CTAN est disponible à l’adresse suivante : https://www.ctan.org/. Le CTAN est le lieu central pour tout ce qui touche . CTAN compte actuellement 6483 packages, auxquels ont contribués 2946 usagers. La plupart des packages sont gratuits et peuvent être téléchargés et utilisés immédiatement. Les deux distributions TeX les plus couramment utilisées sont TEX Live et MiKTeX. Bien que leurs avantages aient été relativement différents dans le passé, en 2023, un nouvel usager ne verrait probablement pas la différence. Les deux distributions peuvent être téléchargées à partir du site Web du CTAN et utilisées rapidement. Elles sont supportés sur tous les versions principales de Linux, MacOS et Windows.\nPlusieurs ressources pour peuvent se trouver en ligne. The LaTeX Project est une excellente source d’information sur le langage de balisage LaTeX. Cette ressource est disponible à l’adresse suivante : https://www.latex-project.org/. Elle contient une grande quantité de documentation à l’usage de nouveaux usagers, des nouvelles sur les mises à jours ainsi qu’une liste de publications portant sur et son utilisation. Le site Web contient également plusieurs liens utiles vers GitHub ainsi que des informations pertinentes sur l’historique du langage. D’autres ressources sous formes de livres et d’articles existent et peuvent être très utiles aux nouveaux usagers de . Le livre Learning LATEX par David Griffiths et collègues, publié en 1997, tient encore la route aujourd’hui. On peut y apprendre les bases du langages qui n’ont pas changé depuis des décennies. En 2017, un autre livre important pour les nouveaux usagers est paru. LaTeX in 24 Hours: A Practical Guide for Scientific Writing, écrit par Dilip Datta, offre un aperçu de LaTeX aux académiques peu d’expérience technique préalable. Le livre présente aux lecteurs des exercices et des exemples simples et compréhensibles pour se familiariser rapidement avec le langage. Une grande quantité d’autres ressources sont disponibles sur le Web.\nComme noté au chapitre 5, Markdown est un langage de balisage servant à ajouter des éléments de formatage à des documents en texte brut. Il n’a pas à être téléchargé, il est natif à la plupart des systèmes d’opérations régulièrement utilisés. Afin de commencer à l’utiliser, il suffit d’ajouter des éléments de formatage Markdown à un fichier texte brut à l’aide d’un éditeur de texte. Il est également possible d’utiliser l’une des nombreuses applications Markdown pour les systèmes d’exploitation macOS, Windows, Linux, iOS et Android. Il existe également plusieurs applications Web spécialement conçues pour écrire en Markdown. L’environnement de programmation RStudio, susmentionné ainsi que présenté au chapitre 4, est un excellent endroit pour écrire en Markdown. RStudio permet également à l’utilisateur d’écrire en RMarkdown ainsi qu’en Quarto.\nComme , Markdown est un langage de balisage qui existe depuis longtemps et dont les bases n’ont pas particulièrement changées dans les dernières décennies. Ainsi, il existe une panoplie de ressources en ligne aidant les nouveaux usagers à se familiariser avec le langage. Le créateur de Markdown, John Gruber, a un site Web contenant les bases du langage Markdown. Ce dernier peut être trouvé à l’adresse suivante : https://daringfireball.net/projects/markdown/. Le site Web Markdown Tutorial, comme son nom l’indique, est un site Web open source qui permet d’essayer Markdown dans le navigateur Web. Il est disponible à l’adresse suivante : https://www.markdowntutorial.com/. En format livre, le livre The Markdown Guide par Matt Cone est une courte mais complète introduction aux bases de Markdown. De la mise en forme à la publication, ce livre contient une grande quantité d’information et de ressources qui peuvent être même utiles aux usagers avancés. Comme pour , une grande quantité d’autres ressources sont facilement accessibles sur le Web.\n\n\n9.2.3 Pièges pour usagers débutants\nBeaucoup de nouvelles informations ont été présentées jusqu’à présent dans ce livre. Il est normal de se sentir dépassé et de ne pas tout comprendre. En fait, il aurait été surprenant qu’un lecteur qui débute l’aventure numérique ait tout compris. L’important est de garder une attitude propice à l’apprentissage et se rappeler que rien de ceci n’est inatteignable. C’est au tout début du parcours que se trouve le premier des pièges pour débutants : croire qu’il sera trop difficile d’apprendre, que c’est un objectif impossible à atteindre. Même les auteurs de ce livre ont, un jour, commencés par faire Hello World! dans la console de RStudio. Le premier piège est souvent lié à un autre piège qui frappe les codeurs débutants : la peur de demander de l’aide. Il faut garder à l’esprit qu’une grande quantité des utilisateurs des outils présentés dans le présent livre sont passés par l’incertitude du début et la crainte du jugement des autres. N’ayez pas peur de poser vos questions, c’est comme cela qu’on apprend.\nUne autre catégorie de pièges pour débutants pour les débutants concerne la pratique des connaissances nouvellement acquises. Les pièges pour débutants de cette catégorie sont au nombre de trois. Tout d’abord, on retrouve la croyance qu’il est possible d’apprendre sans pratiquer. Bien que cela puisse être possible pour quelques personnes ayant une mémoire phénoménale, la réalité est qu’il sera difficile pour le lecteur moyen de retenir l’information contenue dans ce livre et dans les exercices sans pratiquer les nouvelles notions. Le second piège de cette catégorie est lié à ce dernier point : DataCamp – où il y a des indices et du code déjà écrit – ne forme pas à lui seul des codeurs. Il faut faire attention à ne pas rester pris dans une boucle infinie de tutoriels. Faire des tests avec des projets personnels aide à assimiler les nouvelles connaissances en plus d’être plus intéressant. Le troisième pièges pour débutants de cette catégorie est de ne pas être constant dans ses apprentissages. Avec les exercices comme Datacamp, il est facile d’apprendre très rapidement. Toutefois, les apprentissages peuvent se perdre aussi rapidement qu'ils ont été acquis. Il est donc important de suivre une certaine continuité et même parfois de refaire certains exercices afin de se rafraichir la mémoire pour s’assurer de bien comprendre les connaissances de base.\nLe dernier pièges pour débutants est le suivant : ne pas construire des bases solides avant d’aller plus loin. Plusieurs nouveaux codeurs, excités par les nouveaux outils qu’ils apprennent, oublient qu’il est primordial de bien comprendre les éléments de base de la programmation et de la gestion de données avant de se lancer dans des projets plus complexes. Bien qu’il ne soit pas requis de connaître la mécanique pour conduire une automobile, il est tout de même parfois utile – voir nécessaire – de comprendre comment entretenir celle-ci.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Kit de démarrage pour les sciences sociales numériques</span>"
    ]
  },
  {
    "objectID": "conclusion.html#intermédiaire",
    "href": "conclusion.html#intermédiaire",
    "title": "9  Kit de démarrage pour les sciences sociales numériques",
    "section": "9.3 Intermédiaire",
    "text": "9.3 Intermédiaire\nTout comme la section précédente, cette section peut tout à fait être utile à tous les lecteurs. Cependent, elle vise particulièrement ceux et celles qui ont commencé leurs parcours dans le monde numérique, mais qui cherchent à complémenter leur parcours d’outils qui leur facilitera la vie. Cette section se divise en deux sous-sections portant chacune sur un type d’outils nécessaires à la pratique des sciences sociales numériques. La première partie couvre des ressources de gestion bibliographique. Elle commence par présenter au lecteur comment télécharger correctement les différents outils. Ensuite, elle offre différentes ressources afin de pouvoir apprendre les utiliser adéquatement. La seconde section guide le lecteur l’apprentissage de la visualisation graphique en R, puis présente des ressources utiles à sa pratique.\n\n9.3.1 La gestion des références\nLe chapitre 6 du présent livre porte sur la gestion des références. Il présente deux ressources de gestion bibliographique largement utilisés : Zotero et BibLaTex. Cette partie du livre se veut un complément au chapitre 6. La première étape pour afin d’utiliser deux outils de gestion des références susmentionnés est de les télécharger. En ce que concerne Zotero, celui-ci peut être téléchargé à partir du site Web officiel de l’outil à l’adresse suivante : https://www.zotero.org/download/. Le site Web de Zotero contient une grande quantité de documentation pouvant aidant les différents niveaux d’utilisateurs. Ladite documentation aide notamment à apprendre à créer des bibliographies, comment travailler en collaboration et les différents plug-ins et add-ons qui peuvent être utilisés. Parmi ceux-ci, on retrouve notamment Better BibTex – présenté au chapitre 6 – qui aide grandement la gestion de données bibliographiques pour ceux utilisant Zotero et un langage de balisage tel que ou Markdown. Better BibTex peut être téléchargé à l’adresse suivante : https://retorque.re/zotero-better-bibtex/installation/. Le site Web de Better BibTex contient également une foule de documentation aisant l’utilisation de l’outil.\nLa littérature académique sur les différents outils aidant à la gestion des données bibliographiques indiquent que beaucoup des professionnels de différents milieux utilisent Zotero. Il est aussi possible de constater que plusieurs préfèrent Zotero à d’autres options connues telles que EndNotes, RefWorks et Mendeley. Behera et Meher (2022) notent 13 avantages de Zotero sur sa compétition. Parmi ceux-ci, on retrouve notamment la capacité de Zotero à supporter une grande quantité de formats d’écriture, son caractère open source et gratuit, son dévelopement constant par de nombreux chercheurs assurant sa qualité, en plus de son utilité pour le travail collaboratif. Ivey et Crum (2018) comparent les quatre options les plus populaires pour la gestion des données bibliographiques : Zotero, EndNotes, RefWorks et Mendeley. Ils notent pour leur part que Zotero était l’outil le plus précis pour la capture et la transformation de données Web en notices bibliographiques. Selon eux, Zotero créerait les notices bibilographiques les plus exactes. Parmi les options populaires grautuites Zotero et Mendeley, Gilmour et CobusKuo (2011) concluent que Zotero est la meilleure. Les auteurs notent notamment la précision des bibliographiques extractées et le peu d’erreurs produites par l’outil. Winslow et al. (2016) montrent, pour leur part, que Zotero peut aussi être utilisé à des fins pédagogiques. L’outil peut aider les chercheurs avec la littérature sur un sujet en plus d’avoir un impact concret sur les pratiques scientifiques.\nPour sa part, BibLaTeX n’a pas besoin d’être téléchargé puisque c’est un package qui vient avec essentiellement toutes les principales distributions TeX. Il ne suffit que d’utiliser la commande \\usepackage{biblatex} pour y avoir accès. C’est une des trois alternatives populaires afin de citer avec LaTeX, les autres étant natbib et bibtex. Biblatex est généralement considéré comme étant l’option moderne pour traiter les données bibliographiques. Plusieurs apprécient grandement son interface simple et flexible. BibLaTeX supporte aussi mieux des langages autres que l’anglais en comparaison avec les deux autres options.\nLe susmentionné CTAN contient une grande quantité de documentation portant sur BibLaTeX à l’adresse suivante : https://www.ctan.org/pkg/biblatex. De plus, Philip Kime, Moritz Wemheuer et Philipp Lehman ont mis en ligne un excellent guide intitulé « The biblatex Package » portant sur le package. Les auteurs ont compilé en 357 pages toutes les possiblités du package avec des exemples précis. Le document contient un guide pour les usagers de plus de 100 pages, en plus d’un historique des versions du package depuis 2012. Le document est à jour pour l’année 2023, et il est constamment mis à jour par les auteurs.\n\n\n9.3.2 Visualisation graphique en R\nLe chapitre 7 du présent ouvrage porte sur la visualisation graphique en R, les différentes options pour visualiser des données et une discussion concrète de la manière de faire avec base R, lattice et gpglot2. Pour plusieurs raisons présentées aux chapitre 7, ggplot2 est présentement considéré comme étant la meilleure alternative de visualisation graphique avec R en sciences sociales numériques. Comme BibLaTeX, ggplot2 n’a pas besoin d’être directement téléchargé à partir du Web. Il peut être téléchargé seul avec la fonction R install.packages ou avec le super-package tidyverse. Il ne suffit que le l’appeler avec la fonction library pour y avoir accès une fois que cela est fait.\nOutre le contenu du chapitre 7, une grande quantité de ressources est disponible en ligne afin de guider les utilisateurs de R dans leurs démarches de visualisation graphique. Youtube, StackOverflow et les autres sites Webs contenant des tutoriels ou de l’aide à la programmation sont remplis de guides pouvant être utiles. Toutefois, nous considérons que certaines ressources sont plus utiles que d’autres afin de bien comprendre les bases de ggplot2. Le susmentionné livre R For Data Science d’Hadley Wickham et de Garret Grolemund contient une importante section sur la création de graphiques avec ggplot2 en R. Cette section du livre contient également des exercices pour le lecteur. Hadley Wickham a beaucoup travaillé sur ce sujet. Il a écrit plusieurs livres et articles sur le langage de programmation R et la visualisation graphique. Parmi lesdits écrits, l’article de Wickham (2010) est une ressource édifiante pour le compréhension de la grammar of graphics, à la base du projet ggplot. Wickham et collègues ont également écrit ggplot2: Elegant Graphics for Data Analysis (3e) qui porte également sur la philosophie derrière la création et l’utilisation de ggplot2. D’autres ouvrages, plus pratiques, ont été publié sur la visualisation graphique en R avec ggplot2. C’est notamment le cas du livre de Robert Kabacoff sur l’apprentissage de la visualisation graphique avec ggplot2 « Modern Data Visualization with R ». Il est disponible en ligne à l’adresse suivante : https://rkabacoff.github.io/datavis/. Il couvre une grande quantité d’analyses statistiques possibles à faire en R et les meilleures manières de les présenter visuellement. Chaque type de graphique est accompagné de plusieurs exemples et d’une base de données. Finalement, DataCamp, la plateforme d’apprentissage mentionnée précédemment dans le présent chapitre, contient plusieurs tutoriels permettant à de nouveaux utilisateurs de se pratiquer avec ggplot2. DataCamp contient trois cours complets, pour 12 heures de tutoriels, sur la visualisation en R avec ggplot2, allant du niveau de débutant jusqu’au niveau avancé.\n\n\n9.3.3 Pièges pour usagers intermédiaires :\nÀ la suite des différents exercices et lectures complètés dans le cadre de cette familiarisation aux sciences sociales numériques, le lecteur doit s’assurer d’éviter certains pièges qui se dressent sur le chemin des chercheurs de niveau intermédiaire. Le premier d’entre eux est vouloir apprendre plusieurs langages et n’en maîtriser aucun. Plusieurs chercheurs, lorsqu’ils commencent à maîtriser de nouveaux outils, s’emballent et souhaitent en apprendre davantage. C’est une bonne chose, mais il faut faire attention à ne pas apprendre que quelques éléments de plusieurs langages de programmation, et plutôt en maîtriser un. Comme le dit un diction populaire, « qui trop embrasse mal étreint ».\nUn second pièges pour usagers intermédiaires auquel de jeunes chercheurs sont la proie est coder en n’utilisant pas un style et une planification cohérente et constante. En n’adoptant pas un style standard – ou en n’utilisant pas le plus souvent le même style – il peut devenir difficle pour les autres et pour soi-même de se retrouver dans le code. Cela peut causer d’importants problèmes de compréhension ou des problèmes techniques. Il est rare qu’un même code ne serve qu’une seule fois. Il est donc de viser à ce que le code qu’on produit soit compréhensible, transférable et – idéalement – optimisé. Un autre pièges pour usagers intermédiaires s’inscrivant dans la lignée du précédent est écrire du code mais ne pas le commenter. Commenter son code contribue grandement à la transférabilité et la pérennité de son travail. Bien que la fonction d’une section de code peut sembler évidente pour son créateur le jour où elle est produite, elle ne le sera pas nécessairement pour d’autres ou pour lui-même dans le futur.\nLe troisième pièges pour usagers intermédiaires concerne l’utilisation des packages R. De nombreux packages r sont disponibles sur Internet. Dans certaines situations, l’utilisation de ceux-ci peut représenter un gain de temps et résoudre certains problèmes spécifiques. Toutefois, pour des tâches relativement simples, utiliser un package r risque d’ajouter une complexité inutile. En effet, comprendre un package R et l’adapter en fonction de son projet peut être long et laborieux. Il est donc souvent beaucoup plus efficace d’écrire son propre code plutôt que d’utiliser un package R.\nLe dernier piège se dressant sur le chemin d’un chercheur de niveau intermédiaire est de croire qu’il a suffisamment de connaissances et ne pas sortir de sa zone de confort. L’apprentissage de techniques plus complexes demande de sortir de sa zone de confort et de se confronter à l’inconnu. Cela demande également d’accepter qu’on ne connait pas tout et qu’il y aura des échecs et des frustrations. C’est ainsi qu’un chercheur intermédiaire peut dépasser ses limites et devenir un chercheur de niveau avancé.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Kit de démarrage pour les sciences sociales numériques</span>"
    ]
  },
  {
    "objectID": "conclusion.html#avancé",
    "href": "conclusion.html#avancé",
    "title": "9  Kit de démarrage pour les sciences sociales numériques",
    "section": "9.4 Avancé",
    "text": "9.4 Avancé\n\n9.4.1 Le travail collaboratif\nLe chapitre 8 du présent ouvrage présente principalement trois types d’outils complémentaires pour le travail collaboratif : les outils de communications, les outils de gestion de versions et les outils d’entreposage de données. Cette section est complémentaire au chapitre 8 qui présente les différents outils et leurs plusieurs avantages et inconvénients. Elle vous présentera des façons d’en apprendre plus sur ces trois types d’outils et de commencer à les utiliser.\nL’outil de communication priorisé par les auteurs du chapitre 8 est Slack, une plateforme de communication utilisée dans le monde professionnel et académique où se trouvent différents salons de conversations et qui possède une tonne de fonctionnalités telles que les appels de groupes et le partage de documents. Gofine et Clark (2017) notent que Slack est un outil spécialement utile pour la communiaction, la planification et le partage de document en milieu académique. En ce qui concerne la documentation existente, le site Web de Slack contient plusieurs pages portant sur les différentes options de l’application ainsi que des liens vers des vidéos réalisées par leur équipe afin d’aider les utilisateurs à utiliser l’outil de manière efficace. La chaîne Youtube de la compagnie contient plusieurs vidéos aidant les nouveaux usagers à naviguer l’application. Du côté livre, le court ouvrage de Jonathan Miller Getting Started with Slack: A Quick Start Guide for Everyone, disponible sur le Web en format Kindle, est une bonne introduction à l’utilisation de Slack. L’auteur présente différentes techniques afin d’optimiser les communications d’équipe et les bonnes pratiques en terme d’utilisation de l’outil.\nEn ce qui a trait aux outils de gestion de versions, Git est le logiciel priorisé. Git est souvent utilisé à partir de GitHub, la plateforme Web principale pour l’outil. Le chapitre 8 présente Git et GitHub ensemble puisqu’ils sont utilisés de manière complémentaire par de nombreux usagers. Pour beaucoup d’utilisateurs, Git est la façon dont ils intéragissent avec le site Web GitHub, où se trouve leur données, à partir de la ligne de commande de leur ordinateur. D’autres téléchargent directement leurs fichiers à partir du Web et utilisent Git à partir de l’interface GitHub. Bien que certains utilisent Git mais pas GitHub, nous pensons que pour commencer, il est souhaiter d’utiliser les deux outils ensemble. Outre le contenu du chapitre 8, afin de commencer à utiliser Git et GitHub, il est possible de consulter le site Web de GitHub, qui contient beaucoup de documentation, et sur lequel il faut d’ailleurs se créer un compte. Plus d’une dizaine de livres sur Git et GitHub sont accessibles sur le Web. Après les avoir consulté, aucun d’entre eux ne semblent particulièrement pertinent à recommander ici. Rien ne semble battre l’abondance de ressources disponible sur le site de GitHub. Il contient même plusieurs dizaines de tutoriels afin d’en apprendre davantage sur les différentes commandes Git et les façons d’utiliser GitHub. Il est possible de trouver cela à l’adresse suivante : https://skills.github.com/. Consulter les différentes pages de documentation sur GitHub et commencer à utiliser l’outil semble être la meilleure manière d’apprendre.\nFinalement, pour ce qui concerne les outils d’entreposage de données, les options proposées au chapitre 8 sont les plateformes Dropbox et Amazon Web Services (AWS). Commencer à utiliser Dropbox est assez intuitif. C’est similaire à l’arborescence de fichier d’un ordinateur commun, mais en ligne. Et puisque Dropbox peut être téléchargé et installé comme d’autres applications sur les différentes versions de Windows, de MacOS et de Linux, il est possible de synchroniser un dossier Dropbox en local avec son Dropbox en ligne. La seule chose qu’il faut pour utiliser Dropbox, c’est de se créer un compte. Il existe des forfaits payants pour avoir accès a plus d’espace de stockage, mais à la base, c’est gratuit. L’application peut être téléchargé sur le site Web de Dropbox. En ce qui concerne AWS, il existe plusieurs solutions et autant de forfaits qui y sont associés. Le site de AWS a énormément de documentation sur les différents services offerts et les fonctionalités de l’outil. Ils ont leur guide d’apprentissage et plus de 100 tutoriels. Leur documentation est très complète et il y a peu de raisons de recommander un des quelques livres en ligne qui existent et qui sont essentiellement des copiés-collés de leur site Web. AWS a aussi un chatbot qui peut répondre à vos question en temps réel et il apparaît assez efficace.\n\n\n9.4.2 Outils d’intelligence artificielle\nLe chapitre 9 porte sur les différents outils liés à l’utilisation de l’intelligence artificielle. Plus spécifiquement, il présente le site d’OpenAI, qui contient notamment le fameux ChatGPT. Une grande quantité de publications, autant académiques que non académiques, sont parues dans les dernières années sur les différentes facettes de l’intelligence artificielle. La présente section fait état de quelques ressources utiles choisies pour leur pertinence et leur utilité dans l’apprentissage des outils d’intelligence artificielle d’OpenAI.\nLe site Web de la compagnie OpenAI contient une grande quantité d’information sur l’utilisation de leurs différents outils. Leur site Web contient notamment un index des différents articles portant sur leurs produits. Il est possible de consulter ledit index à l’adresse suivante : https://openai.com/research. Tous les ouvrages disponibles ne sont pas nécessairement publiés dans des journaux revues par les pairs. Il faut faire attention avec les sources qu’on utilise qui sont disponibles gratuitement en ligne et dont les auteurs n’ont potentiellement pas eu à rendre de compte à des pairs avant leur publication.\nL’ouvrage ChatGPT for Higher Education and Professional Development: A Guide to Conversational AI de Stephen Atlas est intéressant puisqu’il discute des différents mythes entourant ChatGPT avant de se lancer dans comment l’utiliser à différentes fins. Il offre une vision édifiante de son utilisation dans le monde universitaire et répond à de nombreuses questions fréquemment posées. Le livre de Sinan Ozdemir intitulé Quick Start Guide to Large Language Models: Strategies and Best Practices for Using ChatGPT and Other LLMs est aussi considéré comme un bon outil pour apprendre comment fonctionne ChatGPT. Il offre aux lecteurs une grande quantité d’information utiles et touche également notamment aux meilleures pratiques à utiliser lors de l’utilisation d’outils tels que ChatGPT. Il présente également se qui se trouve derrière de tels outils et comment en tirer le plus possible. Enfin, plusieurs publications récentes traitent de trucs et astuces afin de bien commencer à utiliser. C’est notamment le cas de Lubiana et al. (2023) qui présente 10 choses à considérer lors de l’utilisation des récentes versions de ChatGPT, et de Patton et al. (2023) qui écrivent sur les opportunités et les défis de ChatGPT en sciences sociales numériques.\n\n\n9.4.3 Pièges pour usagers avancés\nL’un des pièges importants à éviter lorsque le chercheur se retrouve à un niveau avancé est la peur de partager son code. Ceci est spécialement vrai pour ceux pour qui l’apprentissage c’est fait en silo. Estimant leur code comme étant une propriété intellectuelle, plusieurs chercheurs développent cette réticence et refusent de partager le fruit de leur labeur. Toutefois, partager son code comporte de nombreux avantages, non seulement pour les autres membres de la communauté, mais également pour le chercheur lui-même. D’un côté, cela permet de recevoir des rétroactions de la part d’autres chercheurs et développeurs. Cette collaboration peut donc grandement contribuer à l’amélioration de son code. De plus, partager son code représente une opportunité d’apprentissage pour les autres membres de la communauté qui peuvent s’en inspirer pour développer leurs compétences ou même le réutiliser dans leur propre projet. Cette transparence et cette collaboration sont donc avantageuses pour tous les partis.\nLe deuxième piège pour usagers avancés duquel le chercheur avancé doit se méfier est de laisser le parfait devenir l’ennemi du bien. Certains chercheurs ont parfois tendance à être perfectionnistes et à perdre du temps et de l’énergie sur des détails mineurs qui n’ont, en fin de compte, aucune retombée majeure sur la qualité globale du projet, comme chercher à optimiser son code de manière excessive. Se soucier de la qualité de son travail est essentiel, mais le chercheur avancé doit également apprendre à savoir quand s’arrêter.\nAprès avoir consacré de nombreuses heures et travaillé d’arrache-pied pour acquérir des connaissances avancées en codage, le chercheur a de quoi être fière. Toutefois, il doit se méfier de l’ultime pièges pour usagers avancés : manquer d’empathie et de compréhension envers les nouveaux utilisateurs. Certains chercheurs de niveau avancé peuvent oublier qu’ils ont déjà été, eux aussi, des débutants. Il faut éviter de prendre pour acquis certaines connaissances de base qui peuvent sembler très simple pour un chercheur avancé, mais très complexe pour un débutant. Soutenir les nouveaux utilisateurs dans leur apprentissage avec patients et empathie permet une meilleure transmission des connaissances.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Kit de démarrage pour les sciences sociales numériques</span>"
    ]
  },
  {
    "objectID": "conclusion.html#conclusion",
    "href": "conclusion.html#conclusion",
    "title": "9  Kit de démarrage pour les sciences sociales numériques",
    "section": "9.5 Conclusion",
    "text": "9.5 Conclusion\nLe but du présent chapitre était d’offrir des informations additionnelles aux chapitres précédents dans le but de faciliter l’apprentissage des différents outils de travail en sciences sociales numériques présentés. Nous avons ici mis l’accent sur deux choses afin d’aider le lecteur. Premièrement, nous avons offert plusieurs ressources à consulter afin d’accéder et d’apprendre à utiliser les outils mis de l’avant. Les différents outils ont été classé selon la difficulté perçue et relative de leur apprentissage. Nous avons classé les outils ainsi puisque c’est généralement l’ordre dans laquelle les practiciens des sciences sociales numériques les apprennent. Afin de faciliter l’expérience d’apprentissage des lecteurs, nous avons pré-sélectionné certaines lectures considérées pertinentes dans le but d’éviter aux lecteurs une surchage d’information. Nous avons choisi des ressources qui sont facilement accessibles en ligne et qui sont gratuites pour la plupart.\nEnsuite, à la fin de chaque section, nous avons présenté les différents pièges associés aux divers niveaux d’apprentissage. Notre expérience indique que plusieurs comportements et attitudes sont liés à certains stades d’apprentissage. Évidemment, certains peuvent survenir plus tôt ou tard que d’autres. L’important est d’être au courant des mauvais plis qu’il est possible d’adopter et de les adresser en amont. Plusieurs des pièges susmentionnés suivent de nombreux profesionnels pendant longtemps et compliquent leur travail individuel et collaboratif. Un practicien des sciences sociales numériques avertit en vaut deux.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Kit de démarrage pour les sciences sociales numériques</span>"
    ]
  },
  {
    "objectID": "annexe_1.html",
    "href": "annexe_1.html",
    "title": "10  L’ordinateur",
    "section": "",
    "text": "10.1 Les composants d’un ordinateur",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>L'ordinateur</span>"
    ]
  },
  {
    "objectID": "annexe_1.html#les-composants-dun-ordinateur",
    "href": "annexe_1.html#les-composants-dun-ordinateur",
    "title": "10  L’ordinateur",
    "section": "",
    "text": "10.1.1 La mémoire vive (RAM)\nLa mémoire vive (RAM) est une composante essentielle de l’ordinateur. Elle permet de stocker temporairement les données nécessaires au fonctionnement de l’ordinateur. Plus la mémoire vive est importante, plus l’ordinateur peut stocker de données simultanément, ce qui permet non seulement d’accélérer son fonctionnement mais aussi de pouvoir manipuler des fichiers plus volumineux. Si l’ordinateur n’a pas assez de mémoire vive, il devra stocker des données sur le disque dur, ce qui est beaucoup plus lent. Lorsque vous chargez des objets dans R, ils sont envoyés dans la mémoire vive. Si vous gérez de grandes quantités de données, il est suggéréé d’avoir une mémoire vive conséquente pour effectuer des opérations rapidement.\nIl est recommandé de choisir un ordinateur doté d’une quantité de mémoire vive suffisante pour vos tâches. Certaines tâches apparemment anodines nécessitent beaucoup de mémoire vive. Par exemple, avoir de nombreux onglets ouverts dans votre navigateur internet peut consommer beaucoup de mémoire vive. Si vous avez l’habitude de garder vos onglets ouverts, soyez conscient que cela peut ralentir votre ordinateur.\nSur Windows, vous pouvez voir la quantité de mémoire vive utilisée en appuyant sur Ctrl + Alt + Suppr pour ouvrir le gestionnaire des tâches. Sur MacOS et Linux, vous pouvez utiliser le logiciel htop, disponible à l’adresse https://htop.dev/downloads.html, dans le terminal.\nLors de la rédaction de cette annexe, ChatGPT recommandait d’avoir au moins 16 Go de mémoire vive pour un ordinateur de recherche et au minimum 8 Go.\n\n\n10.1.2 Le processeur (CPU)\nLe processeur (CPU) est le cerveau de l’ordinateur. Il est responsable de l’exécution des programmes et des calculs. Plus le processeur est puissant, plus l’ordinateur peut effectuer des calculs rapidement. Cela est particulièrement le cas pour les chercheurs qui réalisent des calculs complexes. Si le processeur n’est pas suffisamment puissant, les calculs prendront beaucoup de temps à s’exécuter.\nPar exemple, l’analyse textuelle de grands corpus, comme l’examen de discours ou de publications sur les médias sociaux en sciences sociales numériques, nécessite un processeur capable de gérer de vastes quantités de données textuelles. De même, l’entraînement de modèles de machine learning, qui est crucial pour développer des prédictions ou des classifications basées sur des données historiques, bénéficie grandement d’un processeur rapide. Les chercheurs en sciences sociales travaillent également souvent avec de grandes bases de données démographiques ou économiques, et l’exécution de boucles sur ces ensembles de données pour des analyses statistiques ou économétriques peut être très gourmande en ressources.\nUn bon processeur permettra d’effectuer ces tâches rapidement. La puissance d’un processeur se mesure en gigahertz (GHz). Plus le processeur a une fréquence élevée en gigahertz, plus il est puissant. Il est aussi pertinent de considérer le nombre de cœurs du processeur. Les cœurs d’un processeur sont des unités de calcul indépendantes. Plus un processeur a de cœurs, plus il peut réaliser de tâches simultanément. Il est intéressant de savoir qu’il est possible de paralléliser des tâches sur plusieurs cœurs de processeur, ce qui permet d’accélérer leur exécution. Toutefois, tous les logiciels ne parallélisent pas les tâches automatiquement. En R, vous devez télécharger des packages spécifiques pour paralléliser vos tâches. La parallélisation peut réduire le temps de calcul de plusieurs ordres de grandeur. Il est stratégique de choisir un processeur puissant pour réaliser des tâches complexes. Encore une fois, il est possible d’utiliser htop pour observer l’utilisation des cœurs de votre processeur.\nLes deux principaux fabricants de processeurs sont Intel et AMD. Lors de la rédaction de cette annexe, les deux manufacturiers offraient des processeurs de qualité. Il est également important de considérer les processeurs Apple avec leur architecture propre, connue sous le nom d’Apple Silicon, qui utilisent une architecture ARM différente des architectures x86 d’Intel et AMD. Ces processeurs, tels que le M1 et M2, sont efficaces pour les applications d’analyse de données grâce à leur efficacité énergétique et leur intégration étroite avec le matériel et le logiciel macOS. Toutefois, la sélection du processeur peut varier selon les préférences personnelles, les exigences spécifiques des tâches à accomplir, et le budget. Chaque type possède ses avantages.\nPour les processeurs Intel, ceux de la série i7 sont les plus puissants. Les processeurs de la série i5 sont également de bonne qualité. Les processeurs de la série i3 sont moins puissants. Pour les processeurs AMD, ceux de la série Ryzen sont de bonne qualité, tandis que ceux de la série Athlon sont moins puissants. Idéalement, il serait recommandé d’avoir un processeur i7 ou Ryzen pour un ordinateur de recherche mais n’importe quel processeur intel ou AMD pas trop vieux peut convenir.\n\n\n10.1.3 L’espace de stockage (HDD ou SSD)\nL’espace de stockage est un autre composant clé de l’ordinateur. Il permet de stocker les données de manière permanente. Il existe deux types de stockage : le disque dur (HDD) et le disque à état solide (SSD). Le disque dur est un disque magnétique qui stocke les données sur des plateaux. Il est moins cher que le disque à état solide, mais également plus lent. Si votre ordinateur est équipé d’un disque dur, envisagez de le remplacer par un SSD pour améliorer significativement la vitesse d’opération de votre ordinateur.\nLe SSD, quant à lui, est un disque électronique qui stocke les données sur des puces. Plus coûteux que le disque dur, il offre cependant une vitesse nettement supérieure. Il est donc recommandé de choisir un disque à état solide pour stocker vos données, ce qui permettra à l’ordinateur de démarrer plus rapidement et d’ouvrir les programmes plus vite. De plus, le disque à état solide est plus fiable que le disque dur, car il n’a pas de pièces mobiles, réduisant ainsi les risques de panne.\nIl est primordial de disposer d’un espace de stockage suffisant pour conserver vos données. Lors de la rédaction de cette annexe, ChatGPT recommendait d’avoir au moins 256 Go d’espace de stockage pour un ordinateur de recherche. Il peut être tentant d’acheter des ordinateurs avec un espace de stockage limité pour économiser de l’argent. Cependant, il est important de se rappeler que l’espace de stockage est essentielle et que les fabricants intègrent souvent le disque dur à la carte mère, rendant impossible l’ajout ultérieur de stockage supplémentaire. Il est donc primordial de choisir un ordinateur avec un espace de stockage adéquat dès l’achat.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>L'ordinateur</span>"
    ]
  },
  {
    "objectID": "annexe_1.html#acheter-un-ordinateur",
    "href": "annexe_1.html#acheter-un-ordinateur",
    "title": "10  L’ordinateur",
    "section": "10.2 Acheter un ordinateur",
    "text": "10.2 Acheter un ordinateur\nIl est judicieux de bien choisir son ordinateur. Pour cela, il est recommandé de faire des recherches préalables. MacOS est un choix populaire parmi les chercheurs, car il est stable et fiable. Tous les logiciels recommandés dans ce livre sont disponibles sur MacOS. Les ordinateurs proposés par Apple sont d’excellente qualité et ont généralement une longue durée de vie, ce qui en fait un bon investissement. Cependant, bien qu’offrant un excellent rapport qualité-prix, les ordinateurs Apple se situent dans une gamme de prix élevée. Si vous disposez d’un budget plus limité, il est possible de se tourner vers les ordinateurs d’occasion. Ces derniers sont souvent moins chers que les modèles neufs et peuvent également offrir un excellent rapport qualité-prix.\nPlusieurs entreprises se débarrassent régulièrement de leur parc informatique, qui est ensuite racheté par des compagnies spécialisées dans la remise à neuf et la revente de ces équipements. Ces ordinateurs sont souvent de bonne qualité et proposent un excellent rapport qualité-prix. Il est possible de trouver des ordinateurs d’occasion de qualité sur des sites comme eBay ou Kijiji. Lors de la rédaction de cette annexe, il était possible de trouver un Thinkpad T480 avec 16 Go de mémoire vive, un SSD de 256 Go et un processeur i7 d’Intel pour environ 250-300 dollars canadiens.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>L'ordinateur</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Alpaydin, E., & Bach, F. (2014). Introduction to Machine\nLearning (3e ed.). MIT Press. https://ebookcentral.proquest.com/lib/umontreal-ebooks/detail.action?docID=3339851\n\n\nArel-Bundock, V. (2022). Modelsummary: Data and\nModel Summaries in R. https://www.jstatsoft.org/article/view/v103i01\n\n\nArgyle, L. P., Busby, E. C., Fulda, N., Gubler, J. R., Rytting, C.,\n& Wingate, D. (2023). Out of One, Many:\nUsing Language Models ot Simulate Human\nSamples. Political Analysis, 31(3), 337–351. https://doi.org/10.1017/pan.2023.2\n\n\nBengio, Y. (2023, July 21). One of the \"godfathers of AI\"\nairs his concerns. The Economist. https://www.economist.com/by-invitation/2023/07/21/one-of-the-godfathers-of-ai-airs-his-concerns\n\n\nBéraud, C. (2007). Le logiciel libre, une cause nationale, une\nopportunité pour le Québec (p. 20). FACIL. https://facil.qc.ca/files/2008-11-06_Assnat_0.pdf\n\n\nBertolini, A. (2020). Artificial Intelligence and\nCivil Liability [Policy Department for Citizen's\nRights and Constitutional Affairs]. European Union. https://www.europarl.europa.eu/RegData/etudes/STUD/2020/621926/IPOL_STU(2020)621926_EN.pdf\n\n\nBessen, J. (2002). What Good Is Free Software? In R. W.\nHahn (Ed.), Government Policy toward Open Source\nSoftware (pp. 12–33). Brookings Institution Press. https://www.jstor.org/stable/10.7864/j.ctvbd8kmv.5\n\n\nBourgeois, I. (2021). Qu’est-ce que la recherche sociale? In\nRecherche sociale. De la problématique à la collecte\ndes données (7e ed., pp. 1–14). Presses de l’Université du Québec.\n\n\nBrady, H. E., & Collier, D. (Eds.). (2010). Rethinking\nSocial Inquiry. Diverse Tools, Shared\nStandards (2nd ed.). Rowman & Littlefield Publishers.\n\n\nBremmer, I., & Suleyman, M. (2023). The AI Power\nParadox. Foreign Affairs, 102(5), 26–43.\n\n\nBroca, S. (2013). Utopie du lociel libre. Du bricolage\ninformatique à la réinvention sociale. Le passage clandestin.\n\n\nChakravorty, N., Sharma, C. S., Molla, K. A., & Pattanaik, J. K.\n(2022). Open Science: Challenges,\nPossible Solutions and the Way Forward.\nProceedings of the Indian National Science Academy,\n88(3), 456–471. https://doi.org/10.1007/s43538-022-00104-2\n\n\nChiware, E. R. T., & Skelly, L. (2023). Overcoming\nChallenges to Open Research Practices –\nA Perspective From the Global South: A\nCommentary on “(Why) Are Open Research\nPractices the Future for the Study of\nLanguage Learning?” Language Learning.\n\n\nCouture, S. (2014). Les logiciels libres, un an plus tard.\nInstitut de recherche et d’informations socioéconomiques. https://iris-recherche.qc.ca/blogue/secteur-public-et-communautaire/les-logiciels-libres-un-an-plus-tard/\n\n\nDévédec, N. L. (2021). \"Sans limites\": Une critique\npolitique et écologique du transhumanisme et de son monde. Cahiers\nSociété, 3, 99–122. https://doi.org/10.7202/1090180ar\n\n\nDevedzic, V. (2022). Identity of AI. Discover\nArtificial Intelligence, 2(23). https://doi.org/10.1007/s44163-022-00038-0\n\n\nForestier, F., & Ansermet, F. (2021). Le transhumanisme. In La\nDévoration Numérique (pp. 19–54). Odile Jacob. https://www.cairn.info/la-devoration-numerique--9782415000240-page-19.htm\n\n\nGaudeul, A. (2007). Do Open Source Developers Respond to\nCompetition? The LATEX Case Study. Review\nof Network Economics, 6(2). https://doi.org/10.2202/1446-9022.1119\n\n\nGlover, E. (2024, February 13). Machine Translation:\nHow It Works and Tools to Choose\nFrom. https://builtin.com/artificial-intelligence/machine-translation\n\n\nGreussing, E., Kuballa, S., Taddicken, M., Schulze, M., Mielke, C.,\n& Haux, R. (2020). Drivers and Obstacles of Open\nAccess Publishing. A Qualitative Investigation of\nIndividual and Institutional Factors.\nFrontiers in Communication, 5, 587465. https://doi.org/10.3389/fcomm.2020.587465\n\n\nHanchen Wang, Tianfan Fu, Yuanqi Du, Wenhao Gao, Kexin Huang, Ziming\nLiu, Payal Chandak, Shengchao Liu, Peter Van Katwyk, Andreea Deac, Anima\nAnandkumar, Karianne Bergen, Carla P. Gomes, Shirley Ho, Pushmeet Kohli,\nJoan Lasenby, Jure Leskovec, Tie-Yan Liu, Arjun Manrai, Debora Marks,\nBharath Ramsundar, Le Song, Jimeng Sun, Jian Tang, Petar Veličković, Max\nWelling, Linfeng Zhang, Connor W. Coley, & Yoshua Bengio, &\nMarinka Zitnik. (2023). Scientific discovery in the age of artificial\nintelligence. Nature, 620, 47–60. https://www.nature.com/articles/s41586-023-06221-2\n\n\nHarari, Y. N. (2023, April 28). Yuval Noah Harari argues\nthat AI has hacked the operating system of human\ncivilisation. The Economist. https://www.economist.com/by-invitation/2023/04/28/yuval-noah-harari-argues-that-ai-has-hacked-the-operating-system-of-human-civilisation\n\n\nIBM. (2023a). What are Neural Networks? |\nIBM. https://www.ibm.com/topics/neural-networks\n\n\nIBM. (2023b). What is Artificial Intelligence\n(AI) ? | IBM. IBM. https://www.ibm.com/topics/artificial-intelligence\n\n\nJanssen, M. A. (2017). The Practice of Archiving\nModel Code of Agent-Based Models. Journal of\nArtificial Societies and Social Simulation, 20(1), 2.\n\n\nJanssen, M. A., Pritchard, C., & Lee, A. (2020). On code sharing and\nmodel documentation of published individual and agent-based models.\nEnvironmental Modelling & Software, 134, 104873.\nhttps://doi.org/10.1016/j.envsoft.2020.104873\n\n\nJust, J. (2013, March 25). Les distributions - Groupe\nfrancophone des Utilisateurs de TeX,\nLaTeX et logiciels compagnons. https://www.gutenberg-asso.fr/Les-distributions\n\n\nKabacoff, R. (2022). R in action: Data analysis and graphics with\nR and Tidyverse (Third edition). Manning\nPublications.\n\n\nKing, G., Keohane, R. O., & Verba, S. (2021). Designing\nSocial Inquiry. Scientific Inference in\nQualitative Research. (Nouvelle édition). Princeton\nUniversity Press.\n\n\nKnauff, M., & Nejasmic, J. (2014). An Efficiency\nComparison of Document Preparation Systems Used in\nAcademic Research and Development. PLoS\nONE, 9(12), e115069. https://doi.org/10.1371/journal.pone.0115069\n\n\nKönig, P. D., Krafft, T. D., Schulz, W., & Zweig, K. A. (2022).\nEssence of AI. What Is AI? In and M. Cannarsa\nCristina Poncibò (Ed.), The Cambridge Handbook of\nArtificial Intelligence (pp. 18–34). Cambridge\nUniversity Press. https://doi.org/10.1017/9781009072168.005\n\n\nLianTze, L. (2023). ModèleCV. https://www.overleaf.com/latex/templates/a-customised-curve-cv/mvmbhkwsnmwv\n\n\nMarres, N. (2017). Digital Sociology. The\nReinvention of Social Research. Polity.\n\n\nMcAdoo, T. (2023, April 7). How to cite ChatGPT.\nhttps://apastyle.apa.org. https://apastyle.apa.org/blog/how-to-cite-chatgpt\n\n\nMcCarthy, J. (2007). WHAT IS ARTIFICIAL\nINTELLIGENCE?\n\n\nModèles (2023). https://fr.overleaf.com/latex/templates\n\n\nMuenchen, R. A. (2011). R for SAS and SPSS\nusers (2nd ed). Springer.\n\n\nOpen Source Initiative. (2006, July 7). The Open Source\nDefinition. Open Source Initiative. https://opensource.org/osd/\n\n\nPark, J. S., O’Brien, J. C., Cai, C. J., Morris, M. R., Liang, P., &\nBernstein, M. S. (2023). Generative Agents:\nInteractive Simulacra of Human Behavior.\narXiv. https://doi.org/10.48550/arXiv.2304.03442\n\n\nPaura, L., & Arhipova, I. (2012). Advantages and\nDisadvantages of Professional and Free\nSoftware for Teaching Statistics. Information\nTechnology and Management Science, 15(1). https://doi.org/10.2478/v10313-012-0001-z\n\n\nPeterson, J. C., Bourgin, D. D., Agrawal, M., Reichman, D., &\nGriffiths, T. L. (2021). Using Large-Scale Experiments and\nMachine Learning to Discover Theories of\nHuman Decision-Making. Science,\n372(6547), 1209–1214. https://doi.org/10.1126/science.abe2629\n\n\nPowell, A., Johnson, R., & Herbert, R. (n.d.). Achieving an\nEquitable Transition to Open Access for\nResearchers in Lower and Middle-Income\nCountries.\n\n\nPrzeworski, A., & Teune, H. (1970). The logic of comparative\nsocial inquiry. John Wiley & Sons, Ltd.\n\n\nRoser, M. (2022, December 6). The Brief History of\nArtificial Intelligence: The World Has Changed\nFast – What Might Be Next? Our World in Data.\nhttps://ourworldindata.org/brief-history-of-ai\n\n\nRoux, E. (2013). Yet Another Invoice Template.\nOverleaf. https://www.overleaf.com/latex/templates/yet-another-invoice-template/ykjwmwqqjhgh\n\n\nSantillán-Anguiano, E. I., & González-Machado, E. C. (2023).\nAdvantages of a Free Software Culture for Qualitative\nResearchers in the Social Sciences.\nInternational Journal of Qualitative Research, 3(1),\n97–103. https://www.ojs.literacyinstitute.org/index.php/ijqr/article/view/841\n\n\nSartre, J.-P. (1996). L’existentialisme est un humanisme.\nGallimard.\n\n\nSerwadda, D., Ndebele, P., Grabowski, M. K., Bajunirwe, F., &\nWanyenze, R. K. (2018). Open data sharing and the Global\nSouth—Who benefits? Science,\n359(6376), 642–643. https://doi.org/10.1126/science.aap8395\n\n\nSmith, B. L. (2002). The Future of Software:\nEnabling the Marketplace to\nDecide. In R. W. Hahn (Ed.), Government\nPolicy toward Open Source Software (pp.\n69–86). Brookings Institution Press. https://www.jstor.org/stable/10.7864/j.ctvbd8kmv.8\n\n\nStallman, R. (1986). GNU’s Bulletin.\nhttps://www.gnu.org/bulletins/bull1.txt\n\n\nStallman, R. (2022). En quoi l’open source perd de vue l’éthique du\nlogiciel libre - Projet GNU - Free Software\nFoundation. Système d’exploitation GNU. https://www.gnu.org/philosophy/open-source-misses-the-point.html\n\n\nSystème d’exploitation GNU. (2023). Catégories de logiciels libres\net non libres - Projet GNU - Free Software\nFoundation. Système d’exploitation GNU. https://www.gnu.org/philosophy/categories.html#\n\n\nTabsharani, F. (2023, August). What is Machine\nTranslation? Definition from\nTechTarget. Enterprise AI. https://www.techtarget.com/searchenterpriseai/definition/machine-translation\n\n\nTippmann, S. (2015). Programming tools: Adventures with\nR. Nature, 517(7532), 109–110. https://doi.org/10.1038/517109a\n\n\nWang, P. (2019). On Defining Artificial Intelligence.\nJournal of Artificial General Intelligence, 10(2),\n1–37. https://doi.org/10.2478/jagi-2019-0002\n\n\nWeise, K., & Metz, C. (2023, May 9). When\nA.I. Chatbots Hallucinate.\nThe New York Times. https://www.nytimes.com/2023/05/01/business/ai-chatbots-hallucination.html\n\n\nWickham, H. (2009). Ggplot2: Elegant Graphics for\nData Analysis. Springer New York. https://doi.org/10.1007/978-0-387-98141-3\n\n\nWickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L., François,\nR., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen,\nT., Miller, E., Bache, S., Müller, K., Ooms, J., Robinson, D., Seidel,\nD., Spinu, V., … Yutani, H. (2019). Welcome to the\nTidyverse. Journal of Open Source Software,\n4(43), 1686. https://doi.org/10.21105/joss.01686\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for\ndata science: Import, tidy, transform, visualize, and model data\n(Second edition). O’Reilly.\n\n\nWilliams, S., Stallman, R. M., & Masutti, C. (2010). Richard\nStallman et la révolution du logiciel libre - Une biographie\nautorisée. Eyrolles. https://iso.framadvd.org/standard/content2011/ubuntu/Data/Documents/pdf/framabooks/framabook6_stallman_v1_gnu-fdl.pdf\n\n\nWow! Ten million users! (n.d.). Retrieved March 9,\n2024, from https://www.overleaf.com/blog/wow-ten-million-users",
    "crumbs": [
      "References"
    ]
  }
]
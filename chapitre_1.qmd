---
author: "Jozef Rivest et Catherine Ouellet"
---

# Le logiciel libre et le code source ouvert {#sec-chap1}

<!-- # Vers une science numérique plus transparante: l'apport du logiciel libre et du code ouvert dans les sciences sociales {#sec-chap1 .unnumbered} -->

Ce chapitre ne présentera pas un outil en soi. Il vise à initier les lecteurs et les lectrices à la philosophie du logiciel libre et surtout de situer ces réflexions dans le contexte de la recherche en sciences sociales. En fait, l'outil ici est plutôt de l'ordre réflexif que concret. À la fin de ce chapitre, les lecteurs et lectrices seront en meilleures positions afin de situer les outils qui seront présentés dans le grand univers des locigiels libres et payants. Ils et elles pourront comprendre les motivations derrière le développement et l'utilisation de tels logiciels. Sans vouloir divulgâcher quoi que ce soit, la création et l'utilisation de logiciels libres dépassent le simple calcul coûts et bénéfices utilitaires, gratuit contre payant. Tout cela s'inscrit dans des réflexions philosophiques, éthiques et épistémologiques plus grandes qui continuent, à ce jour, d'influencer les développeurs et les utilisateurs. Nous verrons tout au long de ce chapitre que certaines de ces motivations rejoignent la méthode scientifique, qui est au coeur de notre quête de savoir et de compréhension du monde sociale [@king_etal21]. Ainsi, ce chapitre jette la base réflexive qui est derrière les choix des outils numériques présentés dans ce livre, où nous avons tenté de joindre les avantages des logiciels libres avec certains qui sont payants dans le but de créer un environnement de travail à la fois individuel et collaboratif. Avant d'aller plus en profondeur, une certaine distinction mérite d'être faite, qui permettra d'éviter certaines confusions quant au but de ce livre et à la terminologie utilisée. 

Il est donc important de faire une première distinction entre une méthode, dite méthodologique, et un outil numérique. La méthodologie est le champ de la philosophie des sciences qui s'intéresse à l'étude des méthodes scientifiques ou techniques. Celles-ci visent à collecter et à analyser des données, suivant les impératifs scientifiques, et qui ont pour but de contribuer au savoir et à la connaissance. Il faut faire attention puisque parfois, dans certains livres ou dans certains articles, il est possible que les auteurs ou les autrices parlent des méthodes qu'ils et elles ont utilisées comme étant des *outils*. D'un point de vue méthodologique, lié à la philosophie des sciences, il est approprié d'utiliser ce genre de vocabulaire. Ainsi, la régression linéaire, le *clustering*, les entretiens semi-dirigés et l'analyse de contenu sont des méthodes. En revanche, les outils dits numériques qui sont présentés dans ce livre ne sont pas des méthodes scientifiques. Des outils numériques comme `R`, Dropbox ou GitHub ne sont pas des méthodes. Ils sont des outils qui permettent de structurer sa pensée, d'organiser son espace et son environnement de travail, et d'implémenter son protocole de recherche afin de collecter et d'analyser des données et d'en dériver des conclusions. Il n'est donc pas approprié de considérer qu'un outil numérique est synonyme de méthode.

Ce livre, et par extension ce chapitre, ne vise pas à présenter des *outils méthodologiques* - compris ici comme étant des outils qui permettent de *désigner*, d'exécuter et d'évaluer une recherche [@brady_collier10]. Ils visent plutôt à présenter des *outils numériques* qui, comme mentionnés dans le paragraphe précédent, permettent de *structurer sa pensée, d'organiser son espace de travail et d'implémenter certaines méthodes*. Cette distinction est importante pour le reste de ce livre, et surtout pour la compréhension de son contenu. Les lecteurs et les lectrices, au fil des pages, acquerront des compétences et du savoir à propos des outils numériques. Celles-ci leur permettront de développer un nouveau langage à partir duquel ils et elles pourront réfléchir et penser leur recherche, et surtout interagir avec les autres personnes dans leurs champs; avec qui ils et elles pourront plus aisément collaborer en organisant leur environnement de travail; avec qui ils et elles pourront partager des documents et leurs résultats.

Pour atteindre ces objectifs, il est important de commencer pas la base - comprendre d'où vient le logiciel libre et qu'est-ce que c'est. Le logiciel libre à une place importante dans les outils numériques, sans parler de l'influence qu'il a eue et qu'il continue d'avoir aujourd'hui. Afin de bien comprendre ce dont il est question, nous présenterons, dans un premier temps, l'historique de cette philosophie et de ce mouvement afin de le situer temporellement. De cette façon, nous pourrons mieux comprendre ses motivations et ses revendications, mais aussi ses influences actuelles. Ensuite, nous distinguerons le logiciel payant du logiciel libre, pour ensuite aborder la différence entre le logiciel libre et le code ouvert. Après coup, nous aborderons en quoi ces réflexions sont intéressantes et importantes pour les sciences sociales à l'ère du numérique, ainsi que les avantages et les inconvénients qui y sont liés. À partir de cette section, nous pourrons montrer comment les outils numériques s'inscrivent dans chacune des grandes étapes de la recherche - avant, pendant et après. Finalement, avec ces quelques notions en poche, nous présenterons les différents critères sur lesquels nous nous sommes appuyés pour sélectionner les différents outils qui sont présentés dans ce livre. Ces critères sont nés de la jonction entre la philosophie du logiciel libre et l'expérience de recherche en tant que chaire, dont avec la participation de collaborateurs externes.

## Logiciels Libres

### Le monde du libre

*« Vous n'avez pas à suivre une recette avec précision. Vous pouvez laisser de côté certains ingrédients. Ajouter quelques champignons parce que vous en raffolez. Mettre moins de sel, car votre médecin vous le conseille --- peu importe. De surcroît, logiciels et recettes sont faciles à partager. En donnant une recette à un invité, un cuisinier n'y perd que du temps et le coût du papier sur lequel il l'inscrit. Partager un logiciel nécessite encore moins, habituellement quelques clics de souris et un minimum d'électricité. Dans tous les cas, la personne qui donne l'information y gagne deux choses : davantage d'amitié et la possibilité de récupérer en retour d'autres recettes intéressantes. »* - Richard Stallman [@williams_etal10]

Cette analogie illustre bien trois concepts au cœur de la philosophie de Richard Stallman, souvent considéré comme le père fondateur du logiciel libre : liberté, égalité, fraternité. Les utilisateurs de ces logiciels sont libres, égaux, et doivent s'encourager mutuellement à contribuer à la communauté. Ainsi, un logiciel libre est généralement le fruit d'une collaboration entre développeurs qui peuvent provenir des quatre coins du globe. Au centre de ce mouvement se trouve une réflexion éthique, dont les militants font compagne depuis le début des années 1980, à propos de la liberté des utilisateurs. La Free Software Foundation (FSF), fondée par Richard Stallman en 1985, définit rapidement le logiciel «libre» \[free\] comme étant garant de quatre libertés fondamentales de l'utilisateur: la liberté d'utiliser le logiciel sans restrictions, la liberté de le copier, la liberté de l'étudier, puis la liberté de le modifier pour l'adapter à ses besoins et le redistribuer[^chapitre_1-1]. Il s'agit ainsi d'un logiciel dont le code source[^chapitre_1-2] est disponible, afin de permettre aux internautes de l'utiliser tel quel ou de le modifier à leur guise. L'accès au code source devient essentiel afin de permettre à l'utilisateur de savoir ce que le programme fait réellement. Seulement de cette façon, l'utilisateur peut *contrôler* le logiciel, plutôt que de se faire contrôler par ce dernier [@stallman86].

[^chapitre_1-1]: La redistribution doit évidemment respecter certaines conditions précises, dont l'enfreint peut mener à des condamnations \[http://www.softwarefreedom.org/resources/2008/shareware.html\]

[^chapitre_1-2]: Pour rester dans les analogies culinaires, le code source est au logiciel ce que la recette est à un plat: elle indique les actions à effectuer, une par une, pour arriver à un résultat précis. Encore une fois, ce dernier peut-être adapté, modifié, bonifié.

### Émergence et sémantique du *libre*

Plusieurs situent les débuts du mouvement du logiciel libre avec la création de la licence publique générale GNU, en 1983, à partir de laquelle va se développer une multitude de programmes libres. Parmi les plus populaires, on retrouve notamment le navigateur Firefox, la suite bureautique OpenOffice et l'emblématique système d'exploitation Linux, qui se développe d'ailleurs à partir de la licence GNU[^chapitre_1-3]. Aujourd'hui, il s'agit d'un véritable phénomène sociétal: des milliers d'entreprises, d'organisations à but non lucratif, d'institutions ou encore de particuliers adoptent ces logiciels, dont la culture globale et les valeurs (entraide, collaboration, partage) s'arriment avec le virage technologique de plusieurs entreprises. Les logiciels libres ont différents usages, en passant par la conception Web, la gestion de contenu, les systèmes d'exploitation, la bureautique, entre autres. Ils permettent donc de répondre à plusieurs types de besoins numériques et informatiques.

[^chapitre_1-3]: Pour une liste plus exhaustive, les lecteurs et lectrices peuvent aller consulter le répertoire du gouvernement du Canada: https://code.open.canada.ca/fr/logiciels-libres.html#

Attention, le logiciel libre est avant tout une philosophie, voire un mouvement de société. C'est une façon de concevoir la communauté du logiciel, où le respect de la liberté de l'utilisateur est un impératif éthique [@williams_etal10]. Par conséquent, le terme libre, *free* en anglais, porte à confusion. Celui-ci ne signifie pas qu'un logiciel libre est nécessairement gratuit. Certes, plusieurs sont effectivement téléchargeables gratuitement. Toutefois, il est aussi possible de (re)distribuer des logiciels libres payants. Par ailleurs, aucun logiciel libre n'est réellement « gratuit » dans la mesure où son déploiement et son utilisation nécessitent généralement différents coûts, dont les degrés sont variables en fonction des compétences et de l'infrastructure dont disposent les utilisateurs (coût d'apprentissage, coûts d'entretien, etc.). Enfin, il est important de garder en tête que les logiciels libres possèdent eux aussi une licence - cette dernière est d'ailleurs garante des libertés que confèrent les logiciels libres aux utilisateurs.

La grande liberté que ce type de logiciel offre favorise notamment la collaboration entre les utilisateurs, et ce, à une échelle pouvant être internationale. Les interactions entre les chercheurs créent une dynamique d'« innovation ascendante » et d'entraide [@couture14]. En d'autres termes, l'accessibilité et la collaboration favorisent le développement et l'amélioration de ces logiciels. Selon certains, et comparativement aux logiciels privés, les logiciels libres ont un niveau plus élevé d'innovation [@smith02]. Contrairement aux logiciels propriétaires, ceux qui se développent de manière privée et fermée, les logiciels libres permettent à tous les utilisateurs de participer au développement. Ceux-ci partagent ensuite leurs améliorations, ce qui stimule à son tour de nouvelles initiatives. De plus, il est raisonnable de penser que l'utilité des améliorations, ainsi que l'utilisation qui en est faite par les utilisateurs, permet de générer un savoir collaboratif [@couture20].

Il y a aussi certains avantages économiques, dont un faible coût d'acquisition et de renouvellement pour les particuliers. Cet avantage individuel génère plusieurs externalités positives. Tout d'abord, certains logiciels statistiques ainsi que certains programmes informatiques coûtent plusieurs centaines, voire des milliers de dollars, et dans certains cas doivent être renouvelés annuellement. Cela augmente les coûts associés à l'utilisation du logiciel et par conséquent limite son accessibilité. Comparativement, pour les logiciels libres, la licence d'acquisition coûte bien souvent moins cher, et aucun renouvellement de licence n'est demandé dans la plupart des cas. L'argent sauvé des licences peut alors être investi dans le développement du logiciel libre [@beraud07]. De plus, étant donné que les chercheurs doivent souvent faire face à des contraintes budgétaires, les logiciels libres deviennent des outils intéressants afin de minimiser les coûts de la recherche [@yu_munoz-justicia22]. Il s'agit d'un avantage encore plus important et intéressant pour les chercheurs dans les pays du Sud global [@santillan-anguiano_gonzalez-machado23]. L'accessibilité de ces ressources permet donc de réduire l'écart dans la production scientifique entre les pays du Sud et ceux du Nord. De plus, elle permet à tous de bénéficier d'outils pédagogiques accessibles, ce qui favorise l'acquisition ainsi que le développement de compétences méthodologiques.

Dans le cadre d'une formation universitaire, il peut être pertinent d'enseigner aux étudiants à se servir de logiciel statistique ou d'analyse de texte. L'acquisition de ces compétences peut être précieux tant pour ceux et celles qui souhaitent se diriger vers le milieu académique, que pour ceux et celles qui visent le marché professionnel. D'ailleurs sur le site web de la banque d'emplois du gouvernement du Canada, les conditions d'emplois sont en ce moment[^chapitre_1-4] très bonnes, et une pénurie de main-d'œuvre est anticipée, entre 2022-2031, dans les emplois en analyse de données. Ces compétences sont d'autant plus précieuses aujourd'hui, dans le monde de données dans lequel nous vivons.

[^chapitre_1-4]: En date d'écrire ces lignes, avril 2024.

Il est important de souligner que la transition vers les logiciels libres ne doit pas se faire seulement sur des bases économiques, mais dans une perspective globale de changement de culture. Changer pour des raisons purement économiques viendrait à violer l'essence même de la philosophie du logiciel libre, qui se veut surtout être un esprit de collaboration et de transparence. Par conséquent, il est important d'incorporer aussi les valeurs et la philosophie dans notre utilisation. Amélioration constante, entraide, savoir partagé et plusieurs milliers de contributeurs [@couture14], ces éléments résument très bien la philosophie du logiciel libre.

### Illustrations

Considérons quelques exemples de logiciels libres et de logiciels payants afin de mettre en relief les trois éléments présentés ci-haut: 1) la liberté de l'utilisation et de la contribution, 2) les coûts d'acquisition et 3) les compétences acquises et développées. Dans les chapitres suivants, des outils numériques tels que `R`, SPSS, STATA, qui permettent de mener des analyses statistiques, ou encore la suite Office, Quarto, LaTeX, qui permettent de formater un document écrit, seront présentés. Cette section ne remplace en aucun cas une lecture approfondie et détaillée des chapitres suivants. Au besoin, nous recommandons fortement aux lecteurs et aux lectrices de se référer au reste du livre. En ce qui concerne le premier trio, `R` est le seul logiciel libre du groupe. Il est accessible gratuitement à partir du site web de CRAN, et une grande communauté d'utilisateurs contribue activement à son développement. Par exemple, la compagnie Posit est derrière le développement de `RStudio`, Quarto et Positron[^chapitre_1-5] qui sont toutes des extensions à code ouvert de `R`. Ensuite, plusieurs utilisateurs ont développé des librairies avec des commandes et des fonctions supplémentaires, qui sont gratuites et dont le code est disponible sur des plateformes comme GitHub.

[^chapitre_1-5]: Un nouvel IDE, qui est toujours en cours de développement, qui souhaite offrir une interface optimisée pour `R` et Python construit sur VS Code

Contrairement à `R`, des logiciels comme SPSS et STATA, qui sont des logiciels propriétaires, nécessitent une licence privée afin de pouvoir les utiliser. L'achat d'une licence doit aussi être situé avec ses propres besoins puisque, dans le cas de SPSS, les licences ne donnent pas toutes accès aux mêmes fonctionnalités. Ainsi, la licence de base ne donne pas accès à l'utilisation de la régression, alors que la licence Premium le permet. De plus, la licence doit être renouvelée tous les ans, et les prix varient entre 1 700\$ et 5 194\$ pour la licence web à un seul utilisateur. En ce qui concerne STATA, la logique est similaire à celle de SPSS. Différents types de licence sont offerts avec des fonctionnalités supplémentaires, notamment en termes de rapidité de l'exécution des fonctions et de la capacité à traiter une large quantité d'observations. Les licences annuelles éducationnelles, donc pour les étudiants, se situent entre 126\$ et 506\$ par année. Autrement, le prix varie en 1 248\$ et 1 950\$ par année. De plus, SPSS et STATA sont développés uniquement par les compagnies IBM et par StataCorp respectivement. Bien qu'ils n'offrent pas la même flexibilité que `R` et que les utilisateurs ne peuvent pas contribuer au développement au même titre que `R`, ils offrent d'importantes ressources pour les utilisateurs, notamment par l'entremise d'un service à la clientèle, de documentations et de formation web, par exemple. Ainsi, les utilisateurs sont "pris en charge" directement par la compagnie afin de leur fournir de l'aide et du support.

En ce qui concerne les langages de balisage, LaTeX ou Quarto peuvent être utilisés gratuitement sur des interfaces comme `RStudio` ou VS Code. Ils offrent donc une grande flexibilité étant compatible avec plusieurs interfaces. Ainsi, une fois que les compétences avec le langage ont été développées, il est facile de les transposer d'une interface à une autre. À l'inverse, la suite Office offre ses propres interfaces qui sont plutôt intuitives, mais qui contraignent l'utilisateur à des fonctions prédéfinies. De plus, le coût d'acquisition d'une licence de la suite Office varie entre 79\$ et 109\$ par année. Similairement à STATA et SPSS, Microsoft offre plusieurs ressources directement sur leur site web pour les utilisateurs. Ainsi, un certain "encadrement" est offert par la compagnie.

Deux derniers éléments sont importants d'être soulevés. Il ne faut pas penser que les logiciels libres sont dénués de support et de documentations. La plupart des logiciels libres, et des extensions comme les librairies sur `R`, offrent beaucoup de documentations, et plusieurs forums d'utilisateurs partagent leurs problèmes et leurs solutions. De plus, certains tutoriels sont disponibles sur YouTube ou sur des plateformes comme Datacamp et CodeAcademy. Ainsi, les utilisateurs ne sont pas totalement laissés à eux-mêmes. De plus, plusieurs universités offrent des licences pour des logiciels, comme Office ou SPSS, aux étudiants et aux étudiantes pour éviter que ceux-ci aient à débourser d'importantes sommes supplémentaires afin d'acquérir ces logiciels.

### Logiciel libre et code ouvert

Parallèlement au logiciel libre, il y a aussi le code ouvert, ou *open source*. A priori, la dénomination du logiciel libre et celle du *code ouvert* semblent suggérer qu'il s'agit de synonymes. Dans les deux cas, le lecteur pourrait croire que l'on fait référence à des logiciels, par exemple, qui sont exempts de restrictions d'utilisations et auxquelles les utilisateurs peuvent participer au développement. Cependant, il y a une distinction importante entre les deux.

Bien que les deux renvoient sensiblement aux mêmes types de logiciels, les tenants de ces approches ne partagent pas la même perspective. Comme @stallman22 l'explique, le logiciel libre est d'abord et avant tout un mouvement qui fait « campagne pour la liberté des utilisateurs de l'informatique ». Le code ouvert, quant à lui, met l'accent sur les avantages pratiques, plutôt que de militer pour des principes.

Le terme *code ouvert* sera introduit seulement en 1998 afin de clarifier l'ambiguïté dans la dénomination « logiciel libre » [^chapitre_1-6], *free software* en anglais, afin de spécifier que le code source était accessible, et non pas que le logiciel était « gratuit » [@ballhausen19]. De plus, les logiciels à code ouvert doivent respecter un certain nombre de critères quant à la distribution de leurs logiciels [@opensourceinitiative06].

[^chapitre_1-6]: Soit ceux qui ont été conçus suivant les principes philosophiques et « moraux » qui sous-tendent ce mouvement.

Rappelons tout d'abord que le logiciel libre se définit sur la base de quatre libertés: 1) liberté d'utiliser le programme comme désiré; 2) liberté d'étudier le fonctionnement du programme et de le modifier pour ses propres besoins; 3) liberté de redistribuer des copies; 4) liberté de distribuer des copies de la version « améliorer » du programme pour ses pairs [@ballhausen19]. Concernant le *code ouvert*, tout logiciel qui souhaite être inclus sous cette appellation doit respecter dix critères: 1) Redistribution gratuite; 2) doit inclure le code source; 3) doit permettre les modifications et les travaux dérivés; 4) l'intégrité du code source; 5) ne doit pas discriminer des personnes et/ou groupes; 6) ne doit pas restreindre personne dans l'utilisation du logiciel pour un domaine d'activité; 7) distribution d'une licence pour l'utilisation; 8) la licence ne doit pas être spécifique pour un produit; 9) la licence ne doit pas placer de restriction sur d'autres programmes; 10) la licence doit être technologiquement neutre[^chapitre_1-7] [@opensourceinitiative06].

[^chapitre_1-7]: Pour plus d'informations sur ces caractéristiques, nous encourageons les lecteurs à se référer au lien web de @opensourceinitiative06. Ils y trouveront un contenu détaillé pour chacune des caractéristiques susmentionnées.

Il est aussi utile de les distinguer des logiciels « non libres », soit les logiciels propriétaires: « Son utilisation, sa redistribution ou sa modification sont interdites, ou exigent une autorisation spécifique, ou sont tellement restreintes qu'en pratique vous ne pouvez pas le faire librement » [@systemedexploitationgnu23]. Par contraste, la licence libre confère des droits de propriétaire. L'utilisateur a le droit d'installer le logiciel sur autant d'ordinateurs que désiré, le modifier selon ses besoins et le distribuer avec ou sans ses modifications. Il peut même demander d'être payé pour distribuer des copies, avec ou sans ses modifications.

Le logiciel libre et le *code ouvert* ont certaines similitudes puisqu'ils adhèrent tous les deux à la même vision du logiciel, ainsi que de son accessibilité. Toutefois, il est important tout de même de les distinguer puisqu'ils ont des origines différentes, et qu'ils mènent à certaines pratiques qui sont différentes. La prochaine section utilise un cas concret afin d'expliquer l'effet du libre, et l'utilité que cela peut avoir.

## Les sciences sociales à l'ère du numérique: les enseignements de la philosophie du logiciel libre

En quoi est-ce que ces deux concepts, issus du monde de l'informatique, sont-ils intéressants et/ou important pour les sciences sociales ? Pour répondre à cette question, il est important de retourner à la base, soit de se questionner sur ce que constitue la recherche scientifique dans les sciences sociales.

Dans leur célèbre ouvrage *Designing Social Inquiry*, @king_etal21[^chapitre_1-8] propose quatre critères qui définissent la recherche dite scientifique: 1) le but est l'inférence; 2) les procédures sont publiques; 3) les conclusions sont incertaines; 4) le contenu est la méthode. La philosophie du code ouvert et les avantages pratiques du logiciel libre s'arriment parfaitement avec plusieurs de ces critères.

[^chapitre_1-8]: Ce livre est aussi connu sous l'acronyme *KKV*, en référence à la première lettre du nom de famille de chacun des auteurs.

Penchons-nous sur le critère de la transparence des procédures et celui de la méthode comme étant le contenu. Plusieurs outils numériques rendent possibles le partage et l'accès public des données et de la méthode utilisée. Certains de ces outils seront d'ailleurs abordés dans les chapitres suivants. L'accès aux données et aux procédures d'analyse est un impératif scientifique. Comme nous l'aborderons un peu plus loin, il y a toujours des concessions à faire lors des investigations scientifiques. Par conséquent, un meilleur accès aux procédures et aux données utilisées permet de cibler plus facilement les limites de certaines recherches et de les combler lors de recherche ultérieure. De plus, l'arrivée des données massives ouvre de nouvelles portes, mais surtout de nouveaux défis relatifs à la validité interne et externe ainsi qu'au type de données récoltées et à la validité écologique. Le livre de @marres17 est très intéressant à ce sujet. Face au constat que la vie sociale se trouve affecter par les changements numériques, il nous faut en tant que chercheur du monde social réfléchir à notre façon de comprendre les changements qui s'opèrent. Ainsi, face à ces défis, une des solutions se trouve notamment dans un meilleur partage et dans une meilleure accessibilité aux données et aux procédures.

Il est possible de faire certains liens avec les deux autres critères de @king_etal21. Premièrement, comme le but de la science est l'inférence, soit tenter d'expliquer des phénomènes sociaux qui s'inscrivent dans des catégories plus larges que nos observations directes[^chapitre_1-9], il est important que nos conclusions soient soumises au plus grand nombre possible et pas uniquement au comité éditorial d'une revue scientifique. D'une part, la validité de nos résultats a un potentiel politique important. Plusieurs décisions peuvent être prises sur la base des connaissances et de la compréhension des dynamiques sociales. Il est donc important que les résultats de recherche qui informent ces décisions soient le plus rigoureux possible, et qu'ils aient été soumis à l'examen critique par le plus grand nombre d'individus. D'autre part, et comme @king_etal21 le font remarquer, les conclusions sont toujours incertaines. L'examen critique et la reproduction des protocoles sont donc une nécessité dans ce contexte d'incertitude constant. La science ne cherche pas à être dogmatique. Au contraire, l'incertitude caractérise bien la science. Les résultats sont toujours incertains, et ce que la recherche vise à faire c'est de renforcer notre niveau de confiance envers certaines explications tout en écartant les explications alternatives. Comme plusieurs de ces phénomènes ne sont pas homogènes et qu'ils ne sont pas immuables, nous devons constamment revoir les explications et notre compréhension de ces dynamiques.

[^chapitre_1-9]: Par exemple, les mouvements sociaux, le comportement électoral, les guerres et les révolutions, et bien plus.

Dans la même lancée, l'ouvrage *Rethinking Social Inquiry* [@brady_collier10], une réponse à @king_etal21, partage, en partie, cette définition de la recherche scientifique. Pour les auteurs, les scientifiques du monde social possèdent plusieurs outils qui leur permettent de *designer*, *d'exécuter* et *d'évaluer* une recherche. Ces outils sont des procédures et des pratiques employées par les chercheurs des traditions quantitatives et qualitatives. Ils ont aussi des techniques analytiques qui leur permettent de *développer des preuves qui sont convaincantes*[^chapitre_1-10].

[^chapitre_1-10]: L'objectif des auteurs est de permettre le dialogue et la réconciliation entre les tenants des deux principales traditions méthodologiques: les quantitativistes et les qualitativistes. D'où leur vision de la science comme se devant de développer des preuves qui seront considérées comme convaincantes par les chercheurs de ces deux traditions.

Chacun de ces outils a toutefois ses forces et ses faiblesses. Inspiré de @przeworski_teune70, @brady_collier10 parlent ainsi de *compromis*. Selon eux, la pertinence d'un outil méthodologique dépend de la question de recherche, du but de la recherche et de son contexte. Le choix d'un outil, sur cette base, entraîne des compromis qui empêchent d'atteindre tous les buts analytiques simultanément. Même lorsqu'il y a adéquation entre la question et la méthode, plusieurs autres embuches peuvent entraîner ces compromis, comme la disponibilité des données par exemple, qui limitent par la suite la qualité et la précision des résultats, ce qui explique, en partie, l'incertitude envers les conclusions.

Il est intéressant de concevoir la réalité sociale comme étant un prisme ayant un nombre infini de face. Chacune de ces faces correspond à une compréhension partielle de la réalité. Pour y avoir accès, nous devons utiliser une méthode de collecte et d'analyse de données, informées par une question de recherche et/ou par la théorie[^chapitre_1-11]. Étant donné que chaque outil méthodologique à ses limites et que nous devons constamment faire des compromis, notre compréhension de la réalité n'est que partielle une fois la recherche complétée. De plus, il ne faut pas oublier que la compréhension que nous avons de cette face reste incertaine.

[^chapitre_1-11]: Nous préférons formuler la phrase ici en stipulant que le choix d'une méthode de recherche peut être informé par la théorie et notre question de recherche simultanément, mais peut aussi être fait seulement à partir d'une question de recherche. Cela fait référence à deux processus de recherche différents soit la méthode hypothético-inductive, et celle déductive.

En sommes, les enseignements de la philosophie du code ouvert, les avantages pratiques du logiciel libre et les outils qui en découlent ont le potentiel de permettre non seulement une plus grande transparence des protocoles scientifiques, mais aussi un plus grand partage du savoir, et ce, du début de la recherche jusqu'à la publication des résultats.

## Inconvénients et défis

Jusqu'à présent, nous avons surtout présenté des avantages liés aux logiciels libres. Toutefois, il n'y a pas que des points positifs, et ne pas aborder certaines limites serait malhonnête.

### La courbe d'apprentissage

Dans leur texte, @paura_arhipova12 soulèvent une critique faite envers certains logiciels libres, notamment envers `R`. Le problème principal d'enseigner les statistiques avec des logiciels libres est qu'ils peuvent être compliqués à apprendre ainsi qu'à utiliser; par conséquent, les étudiants passeraient plus de temps à tenter de résoudre les erreurs de programmation plutôt que d'apprendre les statistiques[^chapitre_1-12]. Il est vrai que ces logiciels demandent un investissement en temps, afin d'être en mesure de mener ses propres analyses statistiques. Par exemple, `R` demande l'apprentissage d'un langage de programmation afin de pouvoir utiliser le logiciel à son plein potentiel. De plus, la syntaxe de certaines librairies demande aussi un certain temps d'adaptation. À titre de comparaison, le logiciel SPSS offre une interface beaucoup plus intuitive que `R`, dans lequel l'utilisateur peut simplement cliquer sur les différents menus dans la barre d'outils afin de sélectionner les analyses qu'il ou elle souhaite faire. SPSS présente ses résultats dans des tableaux qui sont clairs et lisibles, contrairement à `R` où plusieurs fonctions présentent les résultats directement dans la console, sous un format moins "esthétique". De plus, la plupart des logiciels payants viennent avec un certain service à la clientèle. En d'autres termes, lorsque les utilisateurs rencontrent des problèmes techniques, ils peuvent se référer au manuel d'utilisateur ou bien par l'entremise de l’assistance technique qui est offerte par la compagnie. À l'opposé, la plupart des logiciels libres ne sont pas accompagnés d'un service à la clientèle. Les utilisateurs doivent donc se "débrouiller" par eux-mêmes lorsqu'ils rencontrent des difficultés et des problèmes.

[^chapitre_1-12]: Sur cet enjeu, nous conseillons aux lecteurs et lectrices de lire le chapitre 2 sur les langages de programmation ainsi que le chapitre 8 sur l'intelligence artificielle. Plusieurs trucs et astuces seront présentés dans ces chapitres.

Toutefois, lorsque l'on compare le coût d'apprentissage avec les bénéfices tirés, il est plus difficile de soutenir qu'il s'agit uniquement d'un désavantage. Dans un premier temps, la syntaxe de programmation de `R` n'est pas parmi les plus complexes à apprendre, et elle s'intègre très bien avec certaines extensions, dont Quarto ou RMarkdown, qui offrent de multiples possibilités pour transmettre le résultat de ses recherches, que ce soit par l'entremise d'un rapport, d'un article scientifique, un site web ou même un blogue. Surtout, la logique derrière la syntaxe de base de `R` et celle d'une nouvelle librairie reste sensiblement inchangée. Par conséquent, lorsque nous avons une bonne compréhension du fonctionnement de base de `R`, l'apprentissage d'une nouvelle librairie se fait relativement rapidement. Certaine, comme `dplyr` du `tidyverse` facilite grandement la manipulation des données comparativement aux commandes de base. Dans un deuxième temps, en comparant le coût, soit d'apprendre le langage de `R`, avec les bénéfices, de mener ses propres analyses de données et de formater les résultats pour les présenter, il est assez clair que tous ceux et celles qui souhaitent, de près ou de loin, travailler avec des données quantitatives, les bénéfices dépassent largement le coût. D'autant plus que ces compétences s'inscrivent dans la longue durée, alors que l'apprentissage est plutôt de courte à moyenne durée. Dans un troisième temps, bien que certains logiciels offrent des alternatives plus intuitives, elles n'offrent pas la même flexibilité que la plupart des logiciels libres offrent. Pour résumer, bien que l'apprentissage d'un langage de programmation demande un investissement en temps, les bénéfices générés par ces nouvelles compétences dépassent le coût initial. Finalement, bien que les logiciels libres n'offrent pas de service à la clientèle, il existe bien souvent des forums d'utilisateurs sur le web où il est possible de trouver des réponses à ses questions et/ou de poser ses questions. Par conséquent, bien qu'il ne s'agit pas d'un service directement offert par l'outil numérique en question, il est toujours possible de trouver du support et de l'aide par l'entremise de la communauté d'utilisateur.

### Problème de transparence

L'arrivée des sciences informatiques a fait émerger des problèmes de reproductibilité des protocoles scientifiques [@janssen17]. Le problème principal est relatif à l'accès au code utilisé par les chercheurs. Par exemple, il est possible de réaliser des analyses statistiques avec `R` sans partager le code utilisé, ce qui limite la transparence du processus scientifique. Dans cette situation, il est difficile de savoir si des erreurs de codage ont été commises, volontairement ou involontairement, affectant ainsi les résultats partagés.

Afin de remédier à ce problème, certains outils tels que GitHub[^chapitre_1-13] participent à la transparence des résultats scientifiques [@fortunato_galassi21]. Ce logiciel permet aux chercheurs de partager leur code afin qu'il puisse être accessible pour tous. Il est important de mentionner ici que l'installation et la configuration de GitHub peuvent s'avérer difficiles pour ceux et celles qui ne sont pas initiés à l'informatique. Cela constitue une certaine barrière dans son utilisation. Toutefois, nous souhaitons tout de même présenter l'utilité de ce logiciel puisqu'il permet de rendre les processus ainsi que les résultats de recherche plus transparents. Par exemple, si l'on réalise une analyse statistique de la relation entre l'économie et le vote, nous pourrions partager l'ensemble du code que nous avons utilisé sur GitHub. D'une part cela permettrait aux utilisateurs de vérifier si les résultats sont honnêtes, et d'autre part de réutiliser le code pour mener leurs propres analyses.

[^chapitre_1-13]: une plateforme publique *code ouvert* sur laquelle nous pouvons héberger et partager notre code.

Cependant, le partage du code reste encore majoritairement volontaire. @janssen_etal20 soutiennent que plus d'effort et d'actions concertés doivent être mis en place afin d'améliorer l'accessibilité aux codes. Toujours selon ces auteurs, les journaux scientifiques pourraient exiger que les auteurs rendent leur code public lors du processus de publication. D'ailleurs, les résultats d'une expérience sur les facteurs qui influencent les chercheurs à partager leur code démontrent que les initiatives individuelles ne seront pas suffisantes pour une augmentation du partage du code [@krahmer_etal23]. Par conséquent, rendre le code accessible devrait devenir un standard institutionnalisé.

### Appropration capitaliste

Dans ce cas-ci, il s'agit plutôt d'un défi auquel le logiciel libre est confronté plutôt qu'une critique quant aux limites de son utilisation. En fait, l'accès au code source ainsi que la liberté et la possibilité de contribuer au développement du logiciel constitue un avantage intéressant pour les compagnies privées. Par conséquent, nous avons assisté à une intégration partielle du logiciel libre dans la logique capitaliste [@broca13; @bessen02]. Certaines compagnies profiteraient des utilisateurs comme une main-d'œuvre gratuite afin de bonifier leur logiciel, ce qui permet, dans certains cas, de générer des revenus commerciaux dont l'entreprise est la seule bénéficiaire [@couture20]. Attention, il ne faut pas penser que toutes les compagnies agissent de manière prédatrice. Le but ici est de souligner que certaines pratiques commerciales trouble l'essence du mouvement du logiciel libre, qui se veut davantage être un outil de collaboration accessible, plutôt qu'un moyen pour générer des profits. Il est important de garder en tête les valeurs et la philosophie qui a donné lieu à ce mouvement.

## La chronologie de la recherche

Malgré ces limites et ces défis, nous pensons que les différents outils numériques ont leur place en sciences sociales, et qu'ils s'inscrivent parfaitement à chaque étape de la recherche. Bien que le partage soit encore majoritairement sur une base volontaire, adopter cette pratique dès maintenant est important pour s'engager vers une science plus ouverte et transparente. Quant à cette dernière caractéristique, il ne faut pas croire que le partage des résultats se limite à une conférence ou à une publication scientifique. Bien au contraire, tout chercheur qui souhaite être le plus transparent doit s'engager dans ce processus dès la conception de sa recherche.

Avant de présenter différents outils qui existent pour cela, il faut préciser en quoi la transparence et l'accessibilité sont bénéfiques pour tous. D'une part, et comme nous l'avons présentée dans la section précédente, la transparence est une caractéristique fondamentale de toute recherche qui se veut scientifique. Elle est aussi liée à l'intégrité du chercheur. Il est impératif de faire état du processus qui mène à notre conclusion, de la sélection de nos données jusqu'à l'analyse. C'est de cette façon que nous pouvons juger de la validité et de la fiabilité des inférences, et surtout de ses limites. D'autre part, la transparence favorise aussi l'apprentissage [@king_etal21]. De rendre publique et accessible, à l'aide des outils numériques, les données, le code et la ou les méthodes utilisées permet de contribuer non seulement aux débats méthodologiques, mais aussi permet à d'autres chercheurs d'apprendre sur l'utilité et l'utilisation de ces méthodes.

### Avant la recherche

Au fil des prochains chapitres, les lecteurs et lectrices apprendront une nouvelle langue. Au même titre qu'une langue comme le français, l'anglais ou le japonais, ce langage permet de communiquer, et surtout de réfléchir. De nouveaux concepts, une façon de penser et de réfléchir à leur recherche, et surtout à son organisation. C'est au travers de la langue que nous pouvons réfléchir. Ainsi, à l'aide de ces termes, les lecteurs et les lectrices seront outillés pour concevoir leur recherche et leur organisation avant même de l'entamer. De la visualiser dans toute son ampleur, de cibler leurs besoins en fonction de leur but et de leurs intérêts et ainsi organiser leur environnement de travail en conséquence.

De plus, motivée par cet objectif inhérent à la science, la transparence exige du chercheur un engagement dès les premières étapes de sa recherche. Tout d'abord, il ou elle peut déjà établir son *workflow* en créant son dépôt GitHub dans lequel il rendra accessibles son code et ses données. Plus d'informations seront présentées dans le chapitre 3. Ensuite, une fois le *design* de recherche[^chapitre_1-14] fait, le ou la chercheur peut le préenregistrer sur le site web de *Open Science Framework*[^chapitre_1-15]. L'objectif de ce site web est que les chercheurs puissent faire état de leurs hypothèses avant la collecte et l'analyse des données afin d'éviter toute manipulation malhonnête *post hoc*. Il s'agit d'un mécanisme qui se veut contraignant afin que les chercheurs s'en tiennent à ce qu'ils ou elles avaient prévu de mener comme recherche.

[^chapitre_1-14]: Généralement, un design de recherche comprend les éléments suivants: Introduction, revue des écrits, problématiques, une question de recherche, un cadre théorique, des hypothèses ainsi qu'une section sur la méthode et les données utilisées.

[^chapitre_1-15]: Lien vers le site web: https://osf.io

### Pendant la recherche

Une fois la recherche débutée, plusieurs outils s'offrent pour une gestion efficace du flux de travail. Plusieurs d'entre eux seront présentés dans les chapitres suivants. Ces outils permettent notamment de sauvegarder les données et l'avancement du projet sur des serveurs externes (le *cloud*), comme Dropbox, afin d'éviter de tout perdre en cas de problème. D'autres permettent de produire le matériel nécessaire pour l'analyse de nos données, tel que R. Certains permet aussi de partager avec des collaborateurs l'avancement de notre projet et les scripts de nos analyses, comme Git et GitHub. D'autres permettent de structurer notre texte pour la production d'un article scientifique ou d'un chapitre de livre, comme Overleaf et Quarto. Ils permettent notamment d'ajouter des tableaux et des graphiques tirés directement des analyses, le tout dans un format respectant les exigences matérielles pour la publication.

Nous ne voulons pas sous-entendre qu'il n'y a pas de limites à tous ces outils. Chaque chapitre de ce livre présentera les points positifs et négatifs des outils qui y seront abordés.

### Après la recherche

Une fois l'article écrit et publié, les auteurs peuvent décider de rendre accessible le matériel produit et utilisé en version gratuite sur le web. Il s'agit du *open science*, ou de la *science ouverte* [@chakravorty_etal22].

Cela permet de rendre non seulement les publications accessibles à tous sur internet gratuitement, mais aussi les données utilisées, par exemple, pour la réalisation de l'étude. Ces données peuvent ensuite être réutilisées par d'autres chercheurs. Il s'agit d'avantages très important, et surtout très prometteur. D'une part, un plus grand accès au savoir scientifique aux décideurs publics permettra de prendre des décisions qui s'appuient sur la science, et idéalement, sur une pluralité de sources scientifiques afin de pouvoir évaluer adéquatement les effets positifs et négatifs. <!--D'autre part, la société civile a tout à gagner d'avoir un meilleur accès aux publications scientifiques.--> Finalement, la réutilisation des données peut réduire considérablement les coûts de la recherche. Bien souvent, la production des données peut engendrer des coûts importants. Par exemple, la production d'un sondage peut coûter plusieurs milliers de dollars, et les données sont bien souvent utilisées qu'une seule fois <!-- Trouver des articles sur ça -->. Le partage des données de manière gratuite permet à des chercheurs qui n'ont pas toujours les moyens de financer un sondage d'avoir accès à des données. En somme, il s'agit de décloisonner le savoir des milieux académiques. Ce qui vaut non seulement pour les publications, mais aussi pour les données et les protocoles de recherche.

Toutefois, le libre accès reste confronté à certains défis. D'une part, il y a un transfert de la charge financière qui se fait parfois vers les chercheurs et les universités. Afin que les publications soient accessibles en libre accès, les chercheurs et les universités doivent souvent payer des sommes importantes. Cela soulève plusieurs questions quant aux capacités des universités du Sud global et pour les chercheurs hors universités<!--À VOIR, PEUVENT-ILS PUBLIER DANS LES REVUES SCIENTIFIQUES ? -->, par exemple, de pouvoir assumer la charge financière qui est liée à la publication en accès libre [@greussing_etal20; @powell_etal]. D'autre part, bien que plusieurs pensent que les données ouvertes et la science ouverte puissent contribuer à réduire les inégalités dans la production du savoir entre le Nord et le Sud, certains restent sceptiques quant à ce scénario. En fait, les données ouvertes permettent de réduire les coûts d'accès aux données, mais ne réduisent pas les coûts de production pour autant. Par conséquent, un scénario évoqué par @serwadda_etal18 est un retour à la recherche parachute[^chapitre_1-16]. En d'autres termes, les chercheurs du Sud resteraient des acteurs de second plan, et qui pour étudier leur propre société, devraient utiliser des données de chercheurs du Nord qui auraient été produits sans la participation des chercheurs locaux. Finalement, il y a aussi des enjeux quant à la confidentialité des répondants et des utilisateurs @chiware_skelly23. Plusieurs individus, comme dans le cas d'entretiens ou d'un sondage, vont accepter de participer à l'enquête parce que leurs réponses seront anonymisées et qu'elles ne seront pas partagées publiquement. Tous ces éléments soulèvent d'importantes réflexions éthiques quant aux bonnes pratiques à développer dans le cadre de la science ouverte. La science ouverte à un avenir très prometteur et peut générer des retombées positives, à conditions quelle s'intéresse aux différents défis auxquels elle est confrontée.

[^chapitre_1-16]: La recherche parachute est une « pratique extractive par laquelle des chercheurs - généralement issus de pays dotés de ressources élevées - effectuent des recherches et extraient des données et des échantillons de régions ou de populations non autochtones, généralement des contextes ou des pays à faibles ressources, sans reconnaître de manière appropriée l'importance de l'infrastructure et de l'expertise locales. Ce faisant, les chercheurs étrangers ne parviennent pas à établir des collaborations équitables et à long terme avec des partenaires locaux. » [@odeny_bosurgi22]

## Critères de sélection

Au cours des prochains chapitres, plusieurs outils seront présentés. Étant donné que le but de l'ouvrage n'est pas uniquement d'offrir une perspective sur le monde du numérique, mais surtout d'offrir des conseils pratiques aux lectrices et lecteurs, certains choix ont dû être faits dans la sélection des outils. Bien que ces choix soient arbitraires, ils sont tout de même informés par certains critères. Au moment d'écrire ces lignes, peu de littérature existe sur le sujet. Par conséquent, l'élaboration de ces critères s'est faite de manière inductive, soit à partir de l'expérience des auteurs. Ils sont aussi informés par des considérations pratiques, tels que la popularité de l'utilisation par une communauté et par un champ d'études. Pour être pleinement transparent, la grande majorité des autrices et auteurs de ce livre sont issues de la science politique.

Malgré cela, nous pensons tout de même que ces critères sont pertinents et informatifs pour les autres disciplines des sciences sociales. Par le fait même, nous souhaitons introduire le débat avec les autres champs. Nous sommes convaincus que ce dialogue sera riche et fructueux. Pour l'instant, tenons-nous-en aux six critères ci-dessous. Tous les outils présentés dans ce livre ne respectent pas nécessairement parfaitement ces critères. Certaines considérations pratiques limitent le plein respect de ces critères. Surtout, bien que le logiciel libre ait été mis de l'avant tout au long de ce chapitre, ce ne sont pas tous les outils numériques présentés dans ce livre qui sont des logiciels libres. Certes, la philosophie du logiciel libre a influencé la sélection et l'utilisation de ces outils, avant même la rédaction de ce livre. Cependant, face à des contraintes pratiques, certains logiciels payants sont utilisés et seront présentés. Bien évidemment, les logiciels libres ne sont pas absolus. Ils peuvent cloisonner les chercheurs entre les utilisateurs et les non-utilisateurs de ces logiciels. Un tel scénario est loin d'être souhaitable. En aucun cas ils ne devraient limiter la collaboration scientifique.

Les lectrices et lecteurs sont encouragés à réfléchir à propos de leur propre besoin afin de déterminer quel.s outil.s elles et ils devraient utiliser. Par exemple, si dans leur communauté, les gens utilisent Python plutôt que R, alors nous recommandons d'utiliser Python. En d'autres termes, les critères et les outils de ce livre ne visent pas un dogmatisme, et un rejet total de tous les autres outils qui ne sont pas couverts dans ce livre. Il est important d'évaluer ses besoins afin de choisir quels outils devraient être utilisés.

### Accessibilité (Gratuit ou peu dispendieux)

L'accessibilité au plus grand nombre de ces outils est importante pour l'atteinte d'une science plus inclusive, et qui respecte les moyens de chacun. L'accès à des outils de qualité ne devrait pas être caché des verrous d'accès payants.

Cette accessibilité est aussi importante pour deux autres raisons. La première, comme le livre vise à donner des connaissances pratiques dans l'utilisation de ces outils numériques, il est important que les lecteurs et lectrices aient facilement accès à ce qui sera présenté. Cela permettra de reproduire au fur et à mesure de la lecture les différentes étapes et pratiques qui sont présentées. La deuxième, est un corolaire du premier, une fois ces compétences acquises, les lecteurs et lectrices pourront facilement les réutiliser pour réaliser les diverses tâches qu'ils et elles ont besoin d'accomplir.

### Existence d'une communauté d'utilisateurs

Ensuite, nous avons considéré l'existence d'une communauté d'utilisateur pour les différents outils qui sont présentés dans ce livre. Ces communautés permettent une grande collaboration entre les différents utilisateurs, et servent souvent de forum d'aide lorsque des problèmes surviennent. Par conséquent, les lecteurs et lectrices auront accès à plusieurs forums d'aide sur internet, au besoin, pour la plupart des outils qui sont présentés dans ce livre. Ainsi, au besoin, ils et elles auront accès à des ressources supplémentaires en ligne lorsqu'une question ou un problème surviendra.

Il se peut que certains logiciels libres n'aient pas un guide d'utilisateur qui soit fourni avec le téléchargement du logiciel. Parfois, cela peut être difficile pour ceux et celles qui souhaitent apprendre à utiliser certains de ces outils de se retrouver et de répondre aux questions qui surviennent. C'est pour ces raisons que nous avons considéré l'existence d'une communauté d'utilisateurs, et l'existence de forum d'aide sur le web. Par exemple, pour toutes les questions liées au code, nous pouvons aller sur le site web de *Stack Overflow*, qui est un important forum d'échange, et sur lequel nous pourrons trouver plusieurs informations et réponses à nos questions.

### Popularité dans le champ

Nous avons choisi certains outils sur d'autres notamment à cause de leur popularité dans le champ et en sciences sociales. Par exemple, en sciences sociales, pour les analyses quantitatives, c'est le logiciel R qui est prédominant aujourd'hui. Non seulement dans son utilisation, mais aussi dans les formations offertes, comme dans le cadre de l'école d'été de la *Inter-university Consortium for Political and Social Research* (ICPSR). Par conséquent, il s'agit d'une considération pratique. Dans le monde du numérique et de la programmation, certains de ces outils deviennent une forme de langage. Ainsi, la maîtrise de ce langage permet de dialoguer avec les autres chercheurs de notre champ, ce qui favorise les débats et la recherche collaborative, par exemple.

### Compatibilité avec d'autres outils

Plusieurs des outils que nous présentons sont issus de notre expérience de recherche. Nous utilisons plusieurs d'entre eux notamment parce qu'ils permettent une certaine synergie dans le processus de la recherche. Ainsi, ils s'intègrent bien les uns avec les autres et permettent une connectivité. Par exemple, Zotero pour la gestion de sa bibliographie et Quarto pour l'écriture de sa recherche se combinent et permettent ainsi de sauver beaucoup de temps dans l'écriture et la gestion des références. Cette intégration des différents outils est importante puisqu'elle favorise non seulement la productivité et une optimisation individuelle, mais aussi collaborative.

### Transparence et réplicabilité

D'autres outils qui sont présentés visent à rendre accessibles les résultats de recherche au plus grand nombre. C'est notamment le cas de GitHub, qui sera présenté dans ce livre. Ces plateformes d'entreposage permettent d'héberger des données et des bribes de code, ce qui favorise la reproduction et la transparence des recherches. Ces éléments sont importants pour la science en général, tout en s'inscrivant dans cet objectif de science ouverte.

Cela favorise aussi l'apprentissage des gens qui souhaitent apprendre à réaliser certaines analyses. Il est possible de trouver beaucoup d'extrait de code sur ces plateformes, que nous pouvons tout simplement copier-coller dans nos propres analyses. Ce faisant, nous pouvons apprendre comment réaliser certaines tâches et performer certaines analyses grâce à ces bribes. Il y a donc d'importantes externalités positives qui sont produites en rendant accessible une partie de nos efforts de recherche.

### Adaptabilité et flexibilité

Nous avons voulu présenter des outils qui ont la plus grande flexibilité et adaptabilité possible. Nous souhaitons que tous et toutes puissent trouver des outils qui puissent être adaptés à leurs besoins, immédiats comme futurs. Cette adaptabilité est importante surtout lorsqu'on considère l'investissement en temps qui est nécessaire pour la maîtrise de ces outils. Il est donc important que cet apprentissage ne soit pas à recommencer au complet chaque fois que nos besoins changent. Certes, il se peut que certains approfondissements soient à faire dans le temps. Cependant, ceux-ci devraient être minimes lorsque nous avons de bonnes bases. La logique de plusieurs de ces outils reste inchangée, il s'agit bien souvent d'apprendre une nouvelle commande, ce qui n'est pas très coûteux en temps lorsqu'on connaît le :fonctionnement de l'outil. De plus, plusieurs de ces outils permettent d'avoir un plus grand contrôle sur la production et le formatage du texte et de graphiques, par exemple. Cette flexibilité est un grand avantage lors de la rédaction et de l'analyse des données.

## Conclusion

En guise de conclusion nous souhaitons mettre l'accent sur un apprentissage important qui se fait de manière implicite dans l'acquisition de ces compétences pratiques: réfléchir de manière scientifique. À la lecture de ce livre, les lecteurs et lectrices auront fait des acquis très importants, et seront mieux outillés pour réfléchir, organiser et produire leurs recherches, peu importe qu'elle soit orientée vers le milieu académique ou professionnel. Nous pouvons décliner le tout en trois principaux arguments.

Le premier concerne les gains à long terme. Nous avons déjà exposé, en partie, cet argument dans la section des critères. Les outils que nous présentons dans ce livre sont, pour la plupart, très versatiles. Nous pouvons réaliser beaucoup de tâches avec ceux-ci. Bien qu'ils soient, pour certains, coûteux en temps dans leur apprentissage, leurs bénéfices dépassent largement leur coût. Le chapitre 7, à propos des langages de balisage, approfondira ce point davantage, et expliquera pourquoi l'apprentissage d'un langage comme \LaTeX à ses bénéfices, en comparaison avec Microsoft Word.

Le deuxième concerne la synergie entre tous ces outils. Comme nous l'avons brièvement expliqué dans les critères de sélection, l'apprentissage de ces différents outils favorise le développement d'une synergie entre les différentes étapes et besoin d'une recherche; notamment dans le développement de sa capacité à récolter, à entreposer, à partager, à analyser et à publier ses données ainsi que ses résultats de recherche.

Le troisième concerne le développement de sa « pensée de chercheur ». Comprendre et maîtriser certains de ces outils permet de se doter de capacités réflexives qui pourront être mobilisées dès les premiers moments de la recherche, soit ceux de la conceptualisation. Dès qu'un intérêt de recherche se développe nous pourrons déjà réfléchir à propos de sa faisabilité, et de quelle manière pourrais-je récolter et analyser des données qui me permettront de répondre à ma question. Cela permet aussi de découvrir de nouvelles méthodes d'analyses de données. Simplement par ces étapes préliminaires, nous gagnons beaucoup de temps et d'itérations simplement par la capacité que nous avons à pouvoir penser une recherche qui pourra être réalisée dans la mesure du possible. De plus, ces acquis contribuent au développement de son jugement critique et d'analyse, fort utile lorsqu'on lit des articles et des ouvrages scientifiques. De cette façon, nous sommes en meilleure position afin de mieux comprendre, d'analyser et de critiquer ce que les autres chercheurs ont fait dans le cadre de leurs recherches.

```{=html}
<!-- 
Ce chapitre à voulu mettre de l'avant le logiciel libre afin d'initier les lecteurs et lectrices à ce monde. Le but n'était pas de présenter de manière exhaustive tout ce champ. Plutôt, nous avons préféré nous limiter aux bases de compréhension, ainsi qu'à quelques exemples. Par conséquent, nous souhaitions qu'à la lecture du chapitre, les lecteurs et lectrices soient mieux outillés pour comprendre et réfléchir par rapport à ce monde, et ainsi insérer ces réflexions dans leurs démarches scientifiques. Générer des idées et des débats nous paraît bien plus promoteur pour l'avenir que d'apprendre par coeur.

En guise de conclusion, nous souhaitons résumer ce chapitre tout en situant ces différents éléments dans les sciences sociales à l'ère du numérique. Le livre de @marres17 est très intéressant à ce sujet. Face au constat que la vie sociale se trouve affectée par les changements numériques, il nous faut en tant que chercheur du monde social réfléchir à notre façon de comprendre les changements qui sont entrain de s'opérer. Bien que ces réflexions ratissent large [^9], nous nous concentrons ici sur la dimension méthodologique.

[^9]: Allant de nos postulats ontologiques, épistémologiques et méthodologiques.

Comme nous l'avons présenté ci-haut, les bas coûts associés à l'utilisation ainsi que la facilité du partage avec la communauté nous semble être deux avantages importants pour l'avenir des sciences sociales numériques. Notamment parce qu'ils ont le potentiel d'améliorer la transparence des protocoles scientifiques. Dans *Designing Social Inquiery*, l'un des livres les plus influents en science politique depuis les trente dernières années, les auteurs définissent quatre caractéristiques que chaque recherche doit posséder afin d'être considérée comme scientifique. L'une d'elles, est que la *procédure doit être publique*: "La recherche scientifique utilise des méthodes explicites, codifiées et publiques afin de générer et analyser des données sur lesquelles la fiabilité peut ensuite être déterminer" [@king_etal21, 6]. Chaque individu qui souhaite contribuer à la connaissance et à la compréhension globale que nous avons de la réalité sociale doit garder en tête cette caractéristique fondamentale. Comme nous l'avons exposé, le partage du code devient un impératif pour assurer la transparence, la réplicabilité ainsi que la qualité des recherches.

## À VOIR 

Pour résumer, les logiciels libres permettent donc une plus grande égalité dans l'accès aux nouvelles technologies, puisqu'ils ont dans la majorité des cas, des coûts d'acquisition nettement moindre. (Oui et non, l'acquisition financière est une chose, mais il y a d'autres barrières à l'utilisation tel que l'apprentissage à faire pour apprendre un language de programmation, l'achat de matériel informatique, etc. ) Cependant, considérant cela, donner l'exemple de l'étude qui montre que c'est beaucoup plus économique, même si l'on doit compter les coûts de formation, le soutien technique, l'entretien et la maintenance. [@couture14; @karjalainen10].


-->
```
````{=html}
<!--

## Cas d'étude: `R`

Afin d'illustrer le tout plus concrètement, nous utiliserons ici le cas du logiciel `R`. Il s'agit d'un logiciel statistique que tous les utilisateurs peuvent télécharger gratuitement, et dans lequel aucun achat supplémentaire est nécessaire pour avoir accès à des fonctionnalités additionnels. Bien que ce logiciel soit déjà riche en fonctions et commandes, plusieurs utilisateurs ont développé des *packages*, des libraries externes, afin de bonifier les fonctions de base [@arel-bundock21]. Utilisons un cas d'étude afin de démontrer l'apport des librairies externes. Par exemple, je souhaite savoir la probabilité de survie à bord du Titanic en fonction du genre. Je pourrais résumer mon intérêt avec sous la notation suivante: $P(Y = Survie | X = Femme)$. En d'autres termes, la probabilité de survie étant donné que nous soyons une femme. Pour ce faire, je dois utiliser l'ensemble de données `Titanic`, disponible en format csv. Je dois donc installer et télécharger la librairie `readr` afin que `R` puisse importer et lire les données. Ensuite je vais utiliser la commande `table`, inclue dans les commandes de base de `R`, afin de produire un tableau croisé entre les variables femme et survie.

``` r
install.packages("readr")
```

```{r message=FALSE, error=FALSE, eval=FALSE}
library(readr) 

dat <- read_csv("data/titanic.csv")

table(dat$survie, dat$femme) 

```

Comme nous le voyons ici, la librairie `readr`, développé par plusieurs individus[^5], nous a permis d'importer l'ensemble de données à propos des passagers du Titanic. Toutefois, le format du tableau n'est pas très esthétique. Pour remédier à ce problème, nous pouvons installer et utiliser la librarie `modelsummary` qui nous permettra de créer rapidement des tableaux croisés plus esthétique, et qui contiendrons davantage d'informations, facilitant la lecture et notre compréhension de la relation qui nous intéresse.

[^5]: Pour avoir la liste complète des contributeurs, les lecteurs peuvent utiliser la commande `?readr` dans `R`, ou bien consulter le lien suivant https://readr.tidyverse.org

``` r
install.packages("modelsummary")
```

```r 
library(modelsummary)

Tableau_2.1 <- datasummary_crosstab(survie ~ femme, data = dat, title = ' ') 

Tableau_2.1
```

Comme nous le voyons, la commande `datasummary_crosstab()` permet facilement de créer des tableaux non seulement plus esthétiques, mais aussi plus informatif. C'est très utile si l'on souhaite incorporer des tableaux dans notre rapport finale, surtout que cette commande nous permet d'exporter les tableaux sous diffèrents format (.docx, `LaTeX`, .qmd, etc.)

Ces deux librairies que nous venons de présenter en exemple, ne sont que deux des 19 897 disponibles pour `R`. Elles illustrent très bien la contribution que les utilisateurs peuvent faire au logiciel. Surtout, ces *add on* ont été développés de manière bénévole. Les contributeurs le font par "passion", et pour en faire profiter la collectivité d'utilisateurs.

Les logiciels libres permettent aux utilisateurs de jouir d'une plus grande liberté dans leur utilisation, ce qui génère des externalités positives puisque ces gens peuvent créer de nouvelles commandes ou fonction et en faire bénéficier toute la collectivité. L'exemple que nous avons utilisé avec `R` ici reflète très bien cet avantage. La prochaine section de ce chapitre se penche plus en profondeur sur les autres avantages ainsi que sur les inconvénients de ces logiciels.

-->
````

{{< pagebreak >}}